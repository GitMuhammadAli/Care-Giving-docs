# The Complete DevOps & Server Administration Guide
## From Zero to Production-Ready Infrastructure

**Enhanced Edition with Free Cloud Deployment Options**

Including: Oracle Cloud Free Tier, Vercel, Netlify, Railway, Render & More

Updated: January 2026

---

# Table of Contents

**Part 1: Fundamentals**
1. [Introduction & Prerequisites](#chapter-1-introduction--prerequisites)
2. [Linux Fundamentals](#chapter-2-linux-fundamentals)
3. [SSH Mastery](#chapter-3-ssh-mastery)
4. [Networking Fundamentals](#chapter-4-networking-fundamentals)

**Part 2: Infrastructure**
5. [Firewall & Network Security](#chapter-5-firewall--network-security)
6. [Web Servers (Nginx)](#chapter-6-web-servers-nginx)
7. [Process Management](#chapter-7-process-management)

**Part 3: Data Layer**
8. [Databases](#chapter-8-databases)
9. [Redis & Caching](#chapter-9-redis--caching)

**Part 4: Deployment & Security**
10. [Deployment Strategies](#chapter-10-deployment-strategies)
11. [SSL/TLS & HTTPS](#chapter-11-ssltls--https)
12. [Monitoring & Logging](#chapter-12-monitoring--logging)
13. [Backup & Disaster Recovery](#chapter-13-backup--disaster-recovery)
14. [Security Hardening](#chapter-14-security-hardening)

**Part 5: Advanced Topics**
15. [Performance Tuning](#chapter-15-performance-tuning)
16. [Cloud Infrastructure (OCI)](#chapter-16-cloud-infrastructure-oci)
17. [Infrastructure as Code](#chapter-17-infrastructure-as-code)
18. [CI/CD Pipelines](#chapter-18-cicd-pipelines)
19. [Containers & Docker](#chapter-19-containers--docker)

**Part 6: Professional Practices**
20. [Professional Practices](#chapter-20-professional-practices)
21. [Capstone Projects](#chapter-21-capstone-projects)

**Part 7: Free Cloud & Complete Walkthroughs**
22. [Free Cloud Deployment Options](#chapter-22-free-cloud-deployment-options)
23. [Complete Deployment Walkthrough](#chapter-23-complete-deployment-walkthrough)
24. [Automated Deployment Scripts](#chapter-24-automated-deployment-scripts)
25. [Quick Reference](#chapter-25-quick-reference)

---

# PART 1: FUNDAMENTALS

---

# Chapter 1: Introduction & Prerequisites

## What is DevOps?

DevOps is a set of practices that combines software development (Dev) and IT operations (Ops). The goal is to shorten the development lifecycle while delivering features, fixes, and updates frequently.

### The DevOps Lifecycle

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    DEVOPS INFINITY LOOP                   â”‚
    â”‚                                                          â”‚
    â”‚     PLAN â†’ CODE â†’ BUILD â†’ TEST â†’ RELEASE â†’ DEPLOY       â”‚
    â”‚       â†‘                                         â†“        â”‚
    â”‚       â””â”€â”€â”€â”€ MONITOR â† OPERATE â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Learn This?

1. **Independence**: Deploy your own projects without waiting for "ops team"
2. **Debugging Power**: Understand why things fail in production
3. **Career Growth**: Full-stack + DevOps = highly valuable
4. **Cost Savings**: Optimize resources, use free tiers effectively
5. **Security Awareness**: Protect your applications properly

### Prerequisites

Before starting, you should have:
- Basic programming knowledge (JavaScript/Python preferred)
- A computer with internet access
- Willingness to break things and learn from errors
- Patience (servers don't forgive typos!)

---

# Chapter 2: Linux Fundamentals

## 2.1 Understanding Linux

Linux is an open-source operating system kernel. Distributions include Ubuntu, CentOS, Debian.

### Why Linux for Servers?

| Reason | Explanation |
|--------|-------------|
| Free | No licensing costs |
| Stable | Can run for years without reboot |
| Secure | Fewer vulnerabilities, quick patches |
| Efficient | Uses less resources than Windows |
| Community | Massive support and documentation |

### The Linux File System Hierarchy

```
/                       # Root - everything starts here
â”œâ”€â”€ bin/                # Essential user binaries (ls, cp, mv)
â”œâ”€â”€ boot/               # Boot loader files (kernel)
â”œâ”€â”€ dev/                # Device files (hardware as files)
â”œâ”€â”€ etc/                # Configuration files
â”‚   â”œâ”€â”€ nginx/          # Nginx configuration
â”‚   â”œâ”€â”€ ssh/            # SSH configuration
â”‚   â”œâ”€â”€ postgresql/     # PostgreSQL configuration
â”‚   â””â”€â”€ redis/          # Redis configuration
â”œâ”€â”€ home/               # User home directories
â”‚   â””â”€â”€ ubuntu/         # Your user's home
â”œâ”€â”€ var/                # Variable data
â”‚   â”œâ”€â”€ log/            # Log files
â”‚   â”œâ”€â”€ www/            # Web server files
â”‚   â””â”€â”€ lib/            # Application state data
â”œâ”€â”€ usr/                # User programs
â”‚   â”œâ”€â”€ bin/            # User binaries
â”‚   â””â”€â”€ local/          # Locally installed software
â””â”€â”€ tmp/                # Temporary files (cleared on reboot)
```

## 2.2 Essential Commands

### Navigation Commands

```bash
# Print Working Directory - where am I?
pwd
# Output: /home/ubuntu

# List files and directories
ls              # Basic list
ls -l           # Long format (permissions, size, date)
ls -la          # Include hidden files (starting with .)
ls -lah         # Human-readable sizes (KB, MB, GB)
ls -lt          # Sort by modification time

# Change Directory
cd /var/log     # Go to absolute path
cd log          # Go to relative path
cd ..           # Go up one level
cd ../..        # Go up two levels
cd ~            # Go to home directory
cd -            # Go to previous directory
```

### File Operations

```bash
# Create files and directories
touch filename.txt              # Create empty file
mkdir mydir                     # Create directory
mkdir -p parent/child/grandchild  # Create nested directories

# Copy files
cp source.txt destination.txt   # Copy file
cp -r source_dir dest_dir       # Copy directory recursively
cp -p file.txt backup.txt       # Preserve permissions and timestamps

# Move/Rename files
mv oldname.txt newname.txt      # Rename file
mv file.txt /path/to/dir/       # Move file

# Remove files - BE CAREFUL!
rm file.txt                     # Remove file
rm -r directory/                # Remove directory and contents
rm -rf directory/               # Force remove (DANGEROUS - no confirmation)
rm -i file.txt                  # Interactive (ask before delete)

# âš ï¸ CAUTION: rm -rf / will destroy your entire system!
# There is NO recycle bin in Linux command line
```

### Viewing File Contents

```bash
# Display entire file
cat file.txt                    # Print file to screen
cat file1.txt file2.txt         # Concatenate and print

# View with pagination
less file.txt                   # Page through file
# Controls: Space=next page, b=previous, /=search, q=quit

# View portions of file
head file.txt                   # First 10 lines
head -n 20 file.txt             # First 20 lines
tail file.txt                   # Last 10 lines
tail -n 20 file.txt             # Last 20 lines
tail -f file.txt                # Follow file (live updates) - GREAT FOR LOGS!

# Word/line count
wc file.txt                     # Lines, words, characters
wc -l file.txt                  # Lines only
```

### Searching and Filtering

```bash
# grep - Global Regular Expression Print
grep "error" logfile.txt        # Find lines containing "error"
grep -i "error" logfile.txt     # Case insensitive
grep -r "TODO" ./               # Recursive search in directory
grep -n "error" logfile.txt     # Show line numbers
grep -v "debug" logfile.txt     # Invert match (lines NOT containing)
grep -c "error" logfile.txt     # Count matches
grep -A 3 "error" file          # Show 3 lines After match
grep -B 3 "error" file          # Show 3 lines Before match

# find - Search for files
find /home -name "*.txt"        # Find by name
find /home -name "*.txt" -type f  # Files only
find /var/log -mtime -7         # Modified in last 7 days
find /home -size +100M          # Files larger than 100MB
find /tmp -name "*.log" -delete # Find and delete

# which - Find command location
which nginx                     # /usr/sbin/nginx
which node                      # /usr/bin/node
```

### File Permissions Deep Dive

```
Permission Structure:
-rwxr-xr-x  1  ubuntu  ubuntu  4096  Jan 15 10:30  script.sh
â”‚â””â”¬â”˜â””â”¬â”˜â””â”¬â”˜     â””â”€â”€â”¬â”€â”˜  â””â”€â”€â”¬â”€â”˜  â””â”€â”¬â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”˜
â”‚ â”‚  â”‚  â”‚         â”‚       â”‚      â”‚          â”‚            â”‚
â”‚ â”‚  â”‚  â”‚         â”‚       â”‚      â”‚          â”‚            â””â”€ Filename
â”‚ â”‚  â”‚  â”‚         â”‚       â”‚      â”‚          â””â”€ Modification time
â”‚ â”‚  â”‚  â”‚         â”‚       â”‚      â””â”€ Size in bytes
â”‚ â”‚  â”‚  â”‚         â”‚       â””â”€ Group owner
â”‚ â”‚  â”‚  â”‚         â””â”€ User owner
â”‚ â”‚  â”‚  â””â”€ Others permissions (r-x = read + execute)
â”‚ â”‚  â””â”€ Group permissions (r-x = read + execute)
â”‚ â””â”€ Owner permissions (rwx = read + write + execute)
â””â”€ File type (- = file, d = directory, l = link)

Permission Values:
r (read)    = 4
w (write)   = 2
x (execute) = 1

Common Permission Sets:
755 = rwxr-xr-x  (owner: full, others: read+execute) - Scripts, directories
644 = rw-r--r--  (owner: read+write, others: read only) - Regular files
700 = rwx------  (owner only, no access for others) - Private scripts
600 = rw-------  (owner read+write only) - SSH keys, .env files
```

```bash
# Change permissions
chmod 755 script.sh             # Set exact permissions
chmod +x script.sh              # Add execute permission
chmod -w file.txt               # Remove write permission
chmod -R 755 directory/         # Recursive permission change

# Change ownership
chown ubuntu:ubuntu file.txt    # Change user and group
chown -R ubuntu:ubuntu dir/     # Recursive ownership change
```

### Pipes and Redirection

```bash
# Pipes - output of one command becomes input of another
ls -la | grep ".txt"            # List files, filter for .txt
cat log.txt | grep error | wc -l  # Count error lines
ps aux | grep nginx             # Find nginx processes

# Output redirection
echo "hello" > file.txt         # Write to file (overwrites)
echo "world" >> file.txt        # Append to file
ls -la > listing.txt            # Save command output

# Error redirection
command 2> error.log            # Redirect errors only
command > output.txt 2>&1       # Redirect both stdout and stderr
command &> /dev/null            # Discard everything
```

### Text Processing

```bash
# sed - Stream Editor
sed 's/old/new/' file.txt       # Replace first occurrence per line
sed 's/old/new/g' file.txt      # Replace all occurrences
sed -i 's/old/new/g' file.txt   # Edit file in place

# awk - Pattern scanning and processing
awk '{print $1}' file.txt       # Print first column
awk -F: '{print $1}' /etc/passwd  # Use : as delimiter

# sort and uniq
sort file.txt                   # Alphabetical sort
sort -n file.txt                # Numerical sort
sort file.txt | uniq            # Remove duplicates
sort file.txt | uniq -c         # Count occurrences
```

### Archive and Compression

```bash
# tar - Tape Archive
tar -cvf archive.tar directory/   # Create archive
tar -xvf archive.tar              # Extract archive
tar -czvf archive.tar.gz dir/     # Create gzip compressed
tar -xzvf archive.tar.gz          # Extract gzip

# Individual compression
gzip file.txt                     # Compress (creates file.txt.gz)
gunzip file.txt.gz                # Decompress
zip archive.zip file1 file2       # Create zip
unzip archive.zip                 # Extract zip
```

## 2.3 Users and Groups

```bash
# User info
whoami                          # Print username
id                              # Print user and group IDs
id ubuntu                       # Info for specific user

# Create user
sudo adduser newuser            # Interactive user creation
sudo usermod -aG sudo newuser   # Add to sudo group

# Password management
sudo passwd username            # Set/change password

# Switch user
sudo -u postgres psql           # Run command as different user
sudo su                         # Switch to root
```

## 2.4 Process Management

```bash
# View processes
ps aux                          # All processes
ps aux | grep nginx             # Find specific process
top                             # Real-time view
htop                            # Better version (install: apt install htop)

# Kill processes
kill PID                        # Graceful termination (SIGTERM)
kill -9 PID                     # Force kill (SIGKILL)
killall nginx                   # Kill by name
pkill -f "node app.js"          # Kill by pattern

# Background processes
command &                       # Run in background
nohup command &                 # Run even after logout
jobs                            # List background jobs
fg %1                           # Bring job 1 to foreground
```

## 2.5 Package Management (Ubuntu/Debian)

```bash
sudo apt update                 # Refresh package lists
sudo apt upgrade                # Upgrade installed packages
sudo apt install nginx          # Install package
sudo apt install -y nginx       # Auto-yes to prompts
sudo apt remove nginx           # Remove package
sudo apt purge nginx            # Remove package and config
sudo apt autoremove             # Remove unused dependencies
apt search nginx                # Search for packages
apt show nginx                  # Package details
```

## 2.6 System Information

```bash
# System info
uname -a                        # All system info
hostnamectl                     # Hostname and OS info
cat /etc/os-release             # Distribution info

# Hardware info
lscpu                           # CPU info
free -h                         # Memory usage
df -h                           # Disk usage
du -sh /var/log                 # Directory size

# Uptime and load
uptime                          # Uptime and load average
# Load average: 1min, 5min, 15min
# Value of 1.0 = one CPU core fully utilized
```

## Practice Exercise: Log Analysis

```bash
# Create sample log
cat << 'EOF' > access.log
192.168.1.1 - - [15/Jan/2024:10:00:00] "GET /index.html HTTP/1.1" 200 1234
192.168.1.2 - - [15/Jan/2024:10:00:01] "GET /about.html HTTP/1.1" 200 5678
192.168.1.1 - - [15/Jan/2024:10:00:02] "GET /index.html HTTP/1.1" 200 1234
192.168.1.3 - - [15/Jan/2024:10:00:03] "GET /api/users HTTP/1.1" 500 234
192.168.1.1 - - [15/Jan/2024:10:00:04] "GET /contact.html HTTP/1.1" 404 0
EOF

# Top 10 IPs:
awk '{print $1}' access.log | sort | uniq -c | sort -rn | head -10

# Error count (5xx):
grep '" 5[0-9][0-9] ' access.log | wc -l

# Most accessed pages:
awk '{print $7}' access.log | sort | uniq -c | sort -rn | head -10
```

---

# Chapter 3: SSH Mastery

## 3.1 Understanding SSH

SSH (Secure Shell) is a cryptographic network protocol for secure communication between computers.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client     â”‚                    â”‚   Server     â”‚
â”‚  (Your PC)   â”‚                    â”‚  (VPS)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              â”‚   1. TCP Connect   â”‚              â”‚
â”‚              â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ Port 22      â”‚
â”‚              â”‚   2. Key Exchange  â”‚              â”‚
â”‚              â”‚ <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚              â”‚
â”‚              â”‚   3. Authenticationâ”‚              â”‚
â”‚              â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚              â”‚
â”‚              â”‚   4. Encrypted     â”‚              â”‚
â”‚   Terminal   â”‚ <=================>â”‚   Shell      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### SSH Key Pair Cryptography

```
Private Key (id_ed25519)          Public Key (id_ed25519.pub)
â”œâ”€â”€ NEVER share this              â”œâ”€â”€ Can share with anyone
â”œâ”€â”€ Stays on YOUR computer        â”œâ”€â”€ Goes on servers you want to access
â”œâ”€â”€ Like a physical key           â”œâ”€â”€ Like a lock
â””â”€â”€ Used to decrypt/sign          â””â”€â”€ Used to encrypt/verify
```

## 3.2 SSH Key Management

### Generating SSH Keys

```bash
# Modern recommended algorithm (Ed25519)
ssh-keygen -t ed25519 -C "your_email@example.com"

# RSA (older, still secure with 4096 bits)
ssh-keygen -t rsa -b 4096 -C "your_email@example.com"

# During generation:
# 1. Choose location (default: ~/.ssh/id_ed25519)
# 2. Enter passphrase (HIGHLY recommended for security)
```

### Key File Permissions (Critical!)

```bash
# SSH refuses to use keys with wrong permissions!
chmod 700 ~/.ssh                # Directory: owner only
chmod 600 ~/.ssh/id_ed25519     # Private key: owner read/write
chmod 644 ~/.ssh/id_ed25519.pub # Public key: readable
chmod 600 ~/.ssh/authorized_keys # Auth keys: owner read/write
chmod 600 ~/.ssh/config         # Config: owner read/write
```

### Copying Public Key to Server

```bash
# Method 1: ssh-copy-id (easiest)
ssh-copy-id -i ~/.ssh/id_ed25519.pub user@server_ip

# Method 2: Manual copy
cat ~/.ssh/id_ed25519.pub | ssh user@server_ip "mkdir -p ~/.ssh && chmod 700 ~/.ssh && cat >> ~/.ssh/authorized_keys && chmod 600 ~/.ssh/authorized_keys"
```

## 3.3 SSH Connection

```bash
# Basic connection
ssh ubuntu@192.168.1.100

# Connect with specific key
ssh -i ~/.ssh/my_key ubuntu@192.168.1.100

# Connect on different port
ssh -p 2222 ubuntu@192.168.1.100

# Debug connection issues
ssh -v ubuntu@192.168.1.100     # Verbose
ssh -vvv ubuntu@192.168.1.100   # Maximum verbosity
```

## 3.4 SSH Config File

Create `~/.ssh/config` for easier connections:

```bash
# ~/.ssh/config

# Default settings for all hosts
Host *
    AddKeysToAgent yes
    IdentitiesOnly yes
    ServerAliveInterval 60
    ServerAliveCountMax 3

# Oracle Cloud server
Host oracle
    HostName 129.154.xxx.xxx
    User ubuntu
    Port 22
    IdentityFile ~/.ssh/oracle_key

# Production server
Host prod
    HostName prod.mycompany.com
    User deploy
    Port 2222
    IdentityFile ~/.ssh/prod_key

# Development server
Host dev
    HostName 10.0.1.50
    User developer
    ProxyJump bastion
```

Now you can simply:
```bash
ssh oracle          # Instead of: ssh -i ~/.ssh/oracle_key ubuntu@129.154.xxx.xxx
ssh prod            # Instead of: ssh -p 2222 -i ~/.ssh/prod_key deploy@prod.mycompany.com
```

## 3.5 SSH Security Hardening

Edit `/etc/ssh/sshd_config` on server:

```bash
# Recommended security settings:

Port 2222                       # Change default port
PermitRootLogin no              # Disable root login
PasswordAuthentication no       # Key-only authentication
PubkeyAuthentication yes
MaxAuthTries 3
AllowUsers ubuntu deploy        # Only specific users
ClientAliveInterval 300
ClientAliveCountMax 2

# Disable risky features
X11Forwarding no
AllowAgentForwarding no
```

```bash
# Test configuration before restarting!
sudo sshd -t

# If test passes, restart SSH
sudo systemctl restart sshd

# âš ï¸ IMPORTANT: Keep your current session open and test with a new connection!
```

## 3.6 SSH File Transfer

### SCP (Secure Copy)

```bash
# Copy file to server
scp file.txt ubuntu@server:/home/ubuntu/

# Copy file from server
scp ubuntu@server:/var/log/nginx/access.log ./

# Copy directory recursively
scp -r ./myproject ubuntu@server:/var/www/

# Use SSH config alias
scp file.txt oracle:/home/ubuntu/
```

### Rsync (Better for Large Transfers)

```bash
# Sync directory to server
rsync -avz ./myproject/ ubuntu@server:/var/www/myproject/

# Flags explained:
# -a = archive mode (preserves permissions, timestamps, etc.)
# -v = verbose
# -z = compress during transfer
# -P = show progress and allow resume

# Exclude files
rsync -avz --exclude='node_modules' --exclude='.git' ./myproject/ server:/var/www/

# Dry run (show what would happen)
rsync -avz --dry-run ./myproject/ server:/var/www/myproject/
```

## 3.7 SSH Tunneling

```bash
# Local Port Forwarding - Access remote service locally
ssh -L 5432:localhost:5432 ubuntu@server
# Now connect to localhost:5432 to reach server's PostgreSQL

# Keep tunnel in background
ssh -fN -L 5432:localhost:5432 ubuntu@server
# -f = background
# -N = no remote command

# Dynamic Port Forwarding (SOCKS proxy)
ssh -D 1080 ubuntu@server
# Configure browser to use SOCKS proxy localhost:1080
```

---

# Chapter 4: Networking Fundamentals

## 4.1 IP Addresses

```
IPv4 Format: xxx.xxx.xxx.xxx (0-255 each octet)
Example: 192.168.1.100

Special IP Addresses:
127.0.0.1       = Localhost (your own machine)
0.0.0.0         = All interfaces / Any IP
255.255.255.255 = Broadcast address
10.x.x.x        = Private network (Class A)
172.16.x.x - 172.31.x.x = Private network (Class B)
192.168.x.x     = Private network (Class C)

CIDR Notation:
192.168.1.0/24  = 256 IPs (192.168.1.0 - 192.168.1.255)
/32 = 1 IP (single host)
/24 = 256 IPs (254 usable)
/16 = 65,536 IPs
/8  = 16,777,216 IPs
```

### Public vs Private IP

```
Private IP:                    Public IP:
â”œâ”€â”€ Used within networks       â”œâ”€â”€ Unique on the internet
â”œâ”€â”€ Not routable on internet   â”œâ”€â”€ Assigned by ISP
â”œâ”€â”€ Free to use                â”œâ”€â”€ Limited supply
â””â”€â”€ Examples: 10.x.x.x         â””â”€â”€ Example: 142.93.123.45
```

## 4.2 Ports

```
Port = Identifies specific service on a machine
Range: 0-65535

Common Ports:
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Port â”‚ Service        â”‚ Description                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 22   â”‚ SSH            â”‚ Secure Shell                â”‚
â”‚ 80   â”‚ HTTP           â”‚ Web traffic                 â”‚
â”‚ 443  â”‚ HTTPS          â”‚ Secure web traffic          â”‚
â”‚ 3000 â”‚ Node.js        â”‚ Development server (common) â”‚
â”‚ 3306 â”‚ MySQL          â”‚ MySQL database              â”‚
â”‚ 5432 â”‚ PostgreSQL     â”‚ PostgreSQL database         â”‚
â”‚ 6379 â”‚ Redis          â”‚ Redis cache                 â”‚
â”‚ 27017â”‚ MongoDB        â”‚ MongoDB database            â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Socket = IP + Port
Example: 192.168.1.100:3000
```

### Checking Open Ports

```bash
# ss (socket statistics) - modern tool
ss -tulpn
# -t = TCP, -u = UDP, -l = Listening, -p = Show process, -n = Numeric

# netstat (older, but widely available)
netstat -tulpn

# lsof (list open files)
sudo lsof -i :80        # What's using port 80?

# Test port connectivity
nc -zv server_ip 80     # netcat connection test
```

## 4.3 DNS (Domain Name System)

```
DNS = Phonebook of the internet
Converts: example.com â†’ 93.184.216.34

Record Types:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Record â”‚ Purpose                                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ A      â”‚ Maps domain to IPv4 address                                 â”‚
â”‚ AAAA   â”‚ Maps domain to IPv6 address                                 â”‚
â”‚ CNAME  â”‚ Alias to another domain                                     â”‚
â”‚ MX     â”‚ Mail server for domain                                      â”‚
â”‚ TXT    â”‚ Text records (verification, SPF, DKIM)                      â”‚
â”‚ NS     â”‚ Nameservers for domain                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DNS Commands

```bash
# Lookup domain
dig example.com                 # Detailed lookup
dig +short example.com          # Just the IP
dig example.com MX              # MX records
dig @8.8.8.8 example.com        # Query specific DNS server

# nslookup (older tool)
nslookup example.com

# Local hosts file (overrides DNS)
cat /etc/hosts
# Add entries: 192.168.1.100 myserver.local
```

## 4.4 Network Commands

```bash
# Connection testing
ping google.com                 # Test if host is reachable
ping -c 4 google.com            # 4 pings only
traceroute google.com           # Show path to destination

# HTTP testing
curl https://api.example.com/data
curl -I https://example.com     # Headers only
curl -X POST https://api.example.com -d '{"key":"value"}'
wget https://example.com/file.zip  # Download file

# Network interface info
ip addr                         # Network interfaces
ip route                        # Routing table
```

---

# PART 2: INFRASTRUCTURE

---

# Chapter 5: Firewall & Network Security

## 5.1 Understanding Firewalls

```
                        INTERNET
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   FIREWALL    â”‚
                    â”‚               â”‚
                    â”‚ Rules:        â”‚
                    â”‚ âœ“ Allow 22    â”‚
                    â”‚ âœ“ Allow 80    â”‚
                    â”‚ âœ“ Allow 443   â”‚
                    â”‚ âœ— Deny all    â”‚
                    â”‚   other       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    SERVER     â”‚
                    â”‚               â”‚
                    â”‚  SSH (22)     â”‚
                    â”‚  Nginx (80)   â”‚
                    â”‚  Redis (6379) â”‚ â† Not accessible from outside!
                    â”‚  DB (5432)    â”‚ â† Not accessible from outside!
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.2 UFW (Uncomplicated Firewall)

```bash
# Check status
sudo ufw status
sudo ufw status verbose
sudo ufw status numbered       # Show rules with numbers

# Enable/Disable
sudo ufw enable               # Turn on firewall
sudo ufw disable              # Turn off firewall

# Default policies
sudo ufw default deny incoming    # Deny all incoming (recommended)
sudo ufw default allow outgoing   # Allow all outgoing

# Allow ports
sudo ufw allow 22              # Allow SSH
sudo ufw allow 80              # Allow HTTP
sudo ufw allow 443             # Allow HTTPS
sudo ufw allow 3000            # Allow Node.js port

# Allow from specific IP
sudo ufw allow from 192.168.1.100
sudo ufw allow from 192.168.1.100 to any port 22

# Allow from subnet
sudo ufw allow from 192.168.1.0/24

# Delete rules
sudo ufw status numbered
sudo ufw delete 3

# Rate limiting (brute force protection)
sudo ufw limit ssh
```

## 5.3 fail2ban

fail2ban monitors log files and bans IPs that show malicious signs.

```bash
# Install
sudo apt install fail2ban -y

# Create configuration
cat << 'EOF' | sudo tee /etc/fail2ban/jail.local
[DEFAULT]
bantime = 1h
findtime = 10m
maxretry = 5
ignoreip = 127.0.0.1/8

[sshd]
enabled = true
port = ssh
filter = sshd
logpath = /var/log/auth.log
maxretry = 3
bantime = 24h
EOF

# Restart and enable
sudo systemctl restart fail2ban
sudo systemctl enable fail2ban

# Check status
sudo fail2ban-client status
sudo fail2ban-client status sshd

# Unban IP
sudo fail2ban-client set sshd unbanip 192.168.1.100
```

## 5.4 Oracle Cloud Security (Two Firewalls!)

Oracle Cloud has TWO layers of firewall. You must configure BOTH:

```bash
# Step 1: Cloud Security List (in Oracle Console)
# Networking â†’ VCN â†’ Security Lists â†’ Default Security List
# Add Ingress Rules:
# Source: 0.0.0.0/0, Protocol: TCP, Port: 80
# Source: 0.0.0.0/0, Protocol: TCP, Port: 443

# Step 2: OS Firewall (on the server via SSH)
# For Ubuntu:
sudo iptables -I INPUT -p tcp --dport 80 -j ACCEPT
sudo iptables -I INPUT -p tcp --dport 443 -j ACCEPT
sudo netfilter-persistent save

# Or use UFW:
sudo ufw allow 80
sudo ufw allow 443
```

---

# Chapter 6: Web Servers (Nginx)

## 6.1 Why Nginx?

```
Nginx advantages:
â”œâ”€â”€ High performance (10,000+ concurrent connections)
â”œâ”€â”€ Low memory footprint
â”œâ”€â”€ Reverse proxy capability
â”œâ”€â”€ Load balancing
â”œâ”€â”€ SSL/TLS termination
â”œâ”€â”€ Caching
â”œâ”€â”€ Gzip compression
â””â”€â”€ Rate limiting
```

## 6.2 Installation and Basic Commands

```bash
# Install
sudo apt install nginx -y

# Start and enable
sudo systemctl start nginx
sudo systemctl enable nginx

# Check status
sudo systemctl status nginx

# Test configuration (ALWAYS do this before reload!)
sudo nginx -t

# Reload (apply config changes without downtime)
sudo nginx -s reload

# Restart
sudo systemctl restart nginx
```

## 6.3 Configuration Structure

```
/etc/nginx/
â”œâ”€â”€ nginx.conf              # Main configuration
â”œâ”€â”€ sites-available/        # Available site configs
â”‚   â”œâ”€â”€ default             # Default site
â”‚   â””â”€â”€ mysite.conf         # Your site config
â”œâ”€â”€ sites-enabled/          # Active sites (symlinks)
â”‚   â””â”€â”€ default â†’ ../sites-available/default
â”œâ”€â”€ conf.d/                 # Additional configurations
â””â”€â”€ snippets/               # Reusable config snippets

/var/log/nginx/             # Log files
â”œâ”€â”€ access.log              # Request logs
â””â”€â”€ error.log               # Error logs
```

## 6.4 Static Site Configuration

```nginx
# /etc/nginx/sites-available/mysite

server {
    listen 80;
    listen [::]:80;  # IPv6
    
    server_name example.com www.example.com;
    
    root /var/www/mysite;
    index index.html index.htm;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    # Logging
    access_log /var/log/nginx/mysite.access.log;
    error_log /var/log/nginx/mysite.error.log;
}
```

## 6.5 Reverse Proxy Configuration

```nginx
# /etc/nginx/sites-available/myapp

upstream backend {
    server 127.0.0.1:3000;
    keepalive 64;
}

server {
    listen 80;
    server_name myapp.com www.myapp.com;
    
    # Security headers
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    
    # Gzip compression
    gzip on;
    gzip_types text/plain application/json application/javascript text/css;
    
    location / {
        proxy_pass http://backend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
    }
    
    # Static files (bypass Node.js)
    location /static/ {
        alias /var/www/myapp/static/;
        expires 30d;
        add_header Cache-Control "public, immutable";
    }
}
```

### Enable Site

```bash
# Create symlink
sudo ln -s /etc/nginx/sites-available/myapp /etc/nginx/sites-enabled/

# Remove default site
sudo rm /etc/nginx/sites-enabled/default

# Test and reload
sudo nginx -t
sudo nginx -s reload
```

## 6.6 Load Balancing

```nginx
# Round-robin (default)
upstream backend {
    server 127.0.0.1:3001;
    server 127.0.0.1:3002;
    server 127.0.0.1:3003;
}

# Weighted
upstream backend {
    server 127.0.0.1:3001 weight=3;  # Gets 3x traffic
    server 127.0.0.1:3002 weight=2;
    server 127.0.0.1:3003 weight=1;
}

# Least connections
upstream backend {
    least_conn;
    server 127.0.0.1:3001;
    server 127.0.0.1:3002;
}

# Health checks
upstream backend {
    server 127.0.0.1:3001 max_fails=3 fail_timeout=30s;
    server 127.0.0.1:3002 max_fails=3 fail_timeout=30s;
    server 127.0.0.1:3003 backup;  # Only used when others fail
}
```

## 6.7 Rate Limiting

```nginx
# In http block (nginx.conf):
limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
limit_conn_zone $binary_remote_addr zone=conn:10m;

# In server/location block:
location /api/ {
    limit_req zone=api burst=20 nodelay;
    limit_conn conn 10;
    
    proxy_pass http://backend;
}
```

---

# Chapter 7: Process Management

## 7.1 PM2 (Node.js Process Manager)

PM2 keeps your Node.js applications alive forever, with automatic restart and clustering.

### Installation and Basic Commands

```bash
# Install globally
sudo npm install -g pm2

# Basic commands
pm2 start app.js                     # Start application
pm2 start app.js --name "my-app"     # Start with name
pm2 start app.js -i max              # Cluster mode (all CPUs)
pm2 start app.js -i 4                # 4 instances

pm2 list                             # List all processes
pm2 logs                             # All logs
pm2 logs my-app                      # Specific app logs
pm2 logs --lines 100                 # Last 100 lines
pm2 monit                            # Real-time dashboard

pm2 stop my-app                      # Stop
pm2 restart my-app                   # Restart
pm2 reload my-app                    # Zero-downtime restart
pm2 delete my-app                    # Delete

pm2 flush                            # Clear all logs
```

### Ecosystem File

```javascript
// ecosystem.config.js
module.exports = {
  apps: [{
    name: 'my-app',
    script: 'app.js',
    instances: 'max',              // Or number: 4
    exec_mode: 'cluster',          // Or 'fork'
    
    // Environment variables
    env: {
      NODE_ENV: 'development',
      PORT: 3000
    },
    env_production: {
      NODE_ENV: 'production',
      PORT: 3000
    },
    
    // Behavior
    max_memory_restart: '1G',      // Restart if memory exceeds
    restart_delay: 4000,           // Delay between restarts
    
    // Logging
    log_date_format: 'YYYY-MM-DD HH:mm:ss Z',
    merge_logs: true
  }]
};
```

```bash
# Use ecosystem file
pm2 start ecosystem.config.js
pm2 start ecosystem.config.js --env production
```

### Startup and Persistence

```bash
# Generate startup script (run at boot)
pm2 startup
# Follow the command it outputs!

# Save current process list
pm2 save

# Resurrect saved processes
pm2 resurrect
```

## 7.2 systemd

systemd is the system and service manager for Linux.

### Basic Commands

```bash
# Service status
sudo systemctl status nginx
sudo systemctl is-active nginx
sudo systemctl is-enabled nginx

# Start/Stop
sudo systemctl start nginx
sudo systemctl stop nginx
sudo systemctl restart nginx
sudo systemctl reload nginx        # Reload config without restart

# Enable/Disable (start at boot)
sudo systemctl enable nginx
sudo systemctl disable nginx
sudo systemctl enable --now nginx  # Enable and start
```

### Custom Service

```ini
# /etc/systemd/system/myapp.service

[Unit]
Description=My Node.js Application
After=network.target

[Service]
Type=simple
User=ubuntu
Group=ubuntu
WorkingDirectory=/var/www/myapp
Environment=NODE_ENV=production
Environment=PORT=3000
ExecStart=/usr/bin/node /var/www/myapp/app.js
Restart=always
RestartSec=10
StandardOutput=syslog
StandardError=syslog
SyslogIdentifier=myapp

[Install]
WantedBy=multi-user.target
```

```bash
# Enable and start
sudo systemctl daemon-reload
sudo systemctl enable myapp
sudo systemctl start myapp
sudo systemctl status myapp

# View logs
sudo journalctl -u myapp -f
```

## 7.3 journalctl (systemd Logging)

```bash
# View all logs
journalctl

# Follow (like tail -f)
journalctl -f

# Specific unit
journalctl -u nginx
journalctl -u nginx -f

# Time-based
journalctl --since "1 hour ago"
journalctl --since "2024-01-15 10:00" --until "2024-01-15 12:00"
journalctl -b                        # Current boot only

# Priority (severity)
journalctl -p err                    # Errors only

# Disk usage
journalctl --disk-usage
sudo journalctl --vacuum-time=7d     # Keep only 7 days
```

---

# PART 3: DATA LAYER

---

# Chapter 8: Databases

## 8.1 PostgreSQL

### Installation

```bash
sudo apt install postgresql postgresql-contrib -y
sudo systemctl start postgresql
sudo systemctl enable postgresql
```

### Basic Setup

```bash
# Switch to postgres user
sudo -u postgres psql

# In psql:
\password postgres           -- Set postgres password
CREATE USER myuser WITH PASSWORD 'mypassword';
CREATE DATABASE mydb OWNER myuser;
GRANT ALL PRIVILEGES ON DATABASE mydb TO myuser;
\q
```

### PostgreSQL Commands

```sql
-- psql commands (backslash commands)
\l                          -- List databases
\c dbname                   -- Connect to database
\dt                         -- List tables
\d tablename                -- Describe table
\du                         -- List users
\q                          -- Quit

-- SQL commands
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

INSERT INTO users (username, email) VALUES ('john', 'john@example.com');
SELECT * FROM users;

-- Create index
CREATE INDEX idx_users_email ON users(email);

-- Show running queries
SELECT pid, query, state FROM pg_stat_activity WHERE state != 'idle';
```

### Backup and Restore

```bash
# Backup
pg_dump -U myuser -h localhost mydb > backup.sql
pg_dump -U myuser -h localhost mydb | gzip > backup.sql.gz

# Restore
psql -U myuser -h localhost mydb < backup.sql
gunzip -c backup.sql.gz | psql -U myuser -h localhost mydb
```

## 8.2 MySQL/MariaDB

```bash
# Install
sudo apt install mysql-server -y
sudo mysql_secure_installation

# Connect
sudo mysql
```

```sql
-- Create user and database
CREATE USER 'myuser'@'localhost' IDENTIFIED BY 'password';
CREATE DATABASE mydb;
GRANT ALL PRIVILEGES ON mydb.* TO 'myuser'@'localhost';
FLUSH PRIVILEGES;
```

```bash
# Backup
mysqldump -u myuser -p mydb > backup.sql

# Restore
mysql -u myuser -p mydb < backup.sql
```

## 8.3 MongoDB

```bash
# Install (Ubuntu)
curl -fsSL https://pgp.mongodb.com/server-7.0.asc | sudo gpg -o /usr/share/keyrings/mongodb-server-7.0.gpg --dearmor

echo "deb [ arch=amd64,arm64 signed-by=/usr/share/keyrings/mongodb-server-7.0.gpg ] https://repo.mongodb.org/apt/ubuntu jammy/mongodb-org/7.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-7.0.list

sudo apt update
sudo apt install -y mongodb-org

sudo systemctl start mongod
sudo systemctl enable mongod
```

```javascript
// Connect
mongosh

// Basic operations
use mydb
db.users.insertOne({ name: "John", email: "john@example.com" })
db.users.find()
db.users.findOne({ name: "John" })
```

---

# Chapter 9: Redis & Caching

## 9.1 Understanding Redis

Redis is an in-memory data structure store, used as database, cache, and message broker.

```
Speed:
â”œâ”€â”€ All data in RAM (microsecond response)
â”œâ”€â”€ Single-threaded (no locking overhead)
â””â”€â”€ Optimized data structures

Use Cases:
â”œâ”€â”€ Caching (API responses, database queries)
â”œâ”€â”€ Session storage
â”œâ”€â”€ Rate limiting
â”œâ”€â”€ Real-time leaderboards
â”œâ”€â”€ Pub/Sub messaging
â””â”€â”€ Queue (with lists or streams)
```

## 9.2 Installation and Configuration

```bash
sudo apt install redis-server -y
sudo systemctl start redis-server
sudo systemctl enable redis-server

# Test
redis-cli ping  # Should return PONG
```

### Security Configuration

```bash
sudo nano /etc/redis/redis.conf
```

```conf
# Bind to localhost only (IMPORTANT!)
bind 127.0.0.1

# Set password
requirepass your_strong_password

# Disable dangerous commands
rename-command FLUSHALL ""
rename-command FLUSHDB ""
rename-command CONFIG ""
```

```bash
sudo systemctl restart redis-server
```

## 9.3 Redis Commands

```bash
redis-cli -a your_password

# Strings
SET name "John"
GET name
SETEX session:123 3600 "data"   # Expires in 1 hour
TTL session:123                  # Check time remaining

# Increment
SET counter 10
INCR counter                     # 11
INCRBY counter 5                 # 16

# Hashes (objects)
HSET user:1 name "John" email "john@example.com" age 30
HGETALL user:1
HGET user:1 name

# Lists (queues)
LPUSH mylist "a" "b" "c"         # Left push
RPOP mylist                       # Right pop
LRANGE mylist 0 -1               # Get all

# Sets
SADD myset "a" "b" "c"
SMEMBERS myset
SISMEMBER myset "a"

# Sorted Sets (leaderboards)
ZADD leaderboard 100 "player1" 200 "player2"
ZREVRANGE leaderboard 0 2 WITHSCORES  # Top 3

# Key operations
KEYS *                           # All keys (don't use in production!)
SCAN 0 MATCH user:* COUNT 100    # Safe iteration
DEL key
EXISTS key
EXPIRE key 60                    # Set expiration
```

## 9.4 Using Redis in Node.js

```javascript
const Redis = require('ioredis');

const redis = new Redis({
  host: process.env.REDIS_HOST || 'localhost',
  port: process.env.REDIS_PORT || 6379,
  password: process.env.REDIS_PASSWORD
});

// Basic operations
await redis.set('key', 'value');
const value = await redis.get('key');

// With expiration
await redis.setex('session', 3600, 'data');

// Caching pattern
async function getCachedData(key, fetchFunction, ttl = 3600) {
  const cached = await redis.get(key);
  if (cached) {
    return JSON.parse(cached);
  }
  
  const data = await fetchFunction();
  await redis.setex(key, ttl, JSON.stringify(data));
  return data;
}
```

---

# PART 4: DEPLOYMENT & SECURITY

---

# Chapter 10: Deployment Strategies

## 10.1 Basic Deployment Script

```bash
#!/bin/bash
# deploy.sh

set -e  # Exit on error

APP_DIR="/var/www/myapp"
BRANCH="main"

echo "ğŸš€ Starting deployment..."

# Pull latest code
cd $APP_DIR
git fetch origin
git reset --hard origin/$BRANCH

# Install dependencies
npm ci --production

# Build if needed
# npm run build

# Reload PM2 (zero-downtime)
pm2 reload ecosystem.config.js --env production

# Verify health
sleep 5
if curl -sf http://localhost:3000/health > /dev/null; then
    echo "âœ… Deployment successful!"
else
    echo "âŒ Health check failed!"
    exit 1
fi
```

## 10.2 Versioned Releases

```
Directory structure:
/var/www/myapp/
â”œâ”€â”€ releases/
â”‚   â”œâ”€â”€ 20240115_100000/
â”‚   â”œâ”€â”€ 20240116_150000/
â”‚   â””â”€â”€ 20240117_120000/  â† Current
â”œâ”€â”€ current â†’ releases/20240117_120000/  (symlink)
â””â”€â”€ shared/
    â”œâ”€â”€ .env
    â”œâ”€â”€ uploads/
    â””â”€â”€ logs/
```

### Rollback

```bash
# One command rollback
PREV_RELEASE=$(ls -t /var/www/myapp/releases | sed -n '2p')
ln -sfn /var/www/myapp/releases/$PREV_RELEASE /var/www/myapp/current
pm2 reload myapp
```

## 10.3 Zero-Downtime Deployment

```javascript
// ecosystem.config.js
module.exports = {
  apps: [{
    name: 'myapp',
    script: 'app.js',
    instances: 'max',
    exec_mode: 'cluster',
    wait_ready: true,           // Wait for process.send('ready')
    listen_timeout: 10000,      // Wait 10s for app to be ready
    kill_timeout: 5000          // Wait 5s for graceful shutdown
  }]
};
```

```javascript
// app.js - Signal PM2 when ready
const server = app.listen(3000, () => {
  console.log('Server ready');
  if (process.send) {
    process.send('ready');
  }
});

// Graceful shutdown
process.on('SIGINT', () => {
  server.close(() => {
    process.exit(0);
  });
});
```

```bash
# Zero-downtime restart
pm2 reload myapp
```

---

# Chapter 11: SSL/TLS & HTTPS

## 11.1 Let's Encrypt with Certbot

```bash
# Install Certbot
sudo apt install certbot python3-certbot-nginx -y

# Get certificate (automatic Nginx configuration)
sudo certbot --nginx -d example.com -d www.example.com

# Test auto-renewal
sudo certbot renew --dry-run
```

## 11.2 Nginx SSL Configuration

```nginx
server {
    listen 80;
    server_name example.com www.example.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    listen [::]:443 ssl http2;
    
    server_name example.com www.example.com;
    
    # SSL Configuration
    ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;
    
    # Modern SSL settings
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_prefer_server_ciphers off;
    
    # HSTS
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    
    location / {
        proxy_pass http://localhost:3000;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

---

# Chapter 12: Monitoring & Logging

## 12.1 Important Log Locations

```
System Logs:
/var/log/syslog          # General system logs
/var/log/auth.log        # Authentication logs

Service Logs:
/var/log/nginx/          # Nginx logs
/var/log/postgresql/     # PostgreSQL logs

Application Logs:
~/.pm2/logs/             # PM2 application logs
```

## 12.2 Basic Monitoring Commands

```bash
# System overview
htop                      # Interactive process viewer

# Memory
free -h

# Disk
df -h                     # Disk space
du -sh /var/log/*        # Directory sizes

# Live logs
tail -f /var/log/nginx/access.log
pm2 logs
journalctl -u nginx -f
```

## 12.3 Health Check Endpoint

```javascript
app.get('/health', async (req, res) => {
  try {
    await db.query('SELECT 1');
    await redis.ping();
    res.json({ 
      status: 'healthy', 
      timestamp: new Date().toISOString(),
      uptime: process.uptime()
    });
  } catch (error) {
    res.status(503).json({ 
      status: 'unhealthy', 
      error: error.message 
    });
  }
});
```

## 12.4 Log Rotation

```bash
# /etc/logrotate.d/myapp

/var/log/myapp/*.log {
    daily
    missingok
    rotate 14
    compress
    delaycompress
    notifempty
    create 0640 ubuntu ubuntu
    sharedscripts
    postrotate
        pm2 reloadLogs
    endscript
}
```

---

# Chapter 13: Backup & Disaster Recovery

## 13.1 Backup Strategy (3-2-1 Rule)

```
3 copies of your data
2 different storage types
1 off-site backup
```

## 13.2 Automated Backup Script

```bash
#!/bin/bash
# /usr/local/bin/backup.sh

set -e

BACKUP_DIR="/var/backups/myapp"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=7

mkdir -p $BACKUP_DIR/$DATE

echo "Starting backup at $(date)"

# Database backup
PGPASSWORD=$DB_PASSWORD pg_dump -h localhost -U $DB_USER $DB_NAME | \
    gzip > $BACKUP_DIR/$DATE/database.sql.gz

# Application files
tar -czf $BACKUP_DIR/$DATE/app.tar.gz \
    --exclude='node_modules' \
    --exclude='.git' \
    /var/www/myapp

# Cleanup old backups
find $BACKUP_DIR -type d -mtime +$RETENTION_DAYS -exec rm -rf {} \; 2>/dev/null

echo "Backup completed: $DATE"
```

```bash
# Make executable and schedule
sudo chmod +x /usr/local/bin/backup.sh

# Add to cron (daily at 2 AM)
sudo crontab -e
# Add: 0 2 * * * /usr/local/bin/backup.sh >> /var/log/backup.log 2>&1
```

## 13.3 Restore Procedure

```bash
#!/bin/bash
# restore.sh

BACKUP_DATE=$1
BACKUP_DIR="/var/backups/myapp/$BACKUP_DATE"

if [ ! -d "$BACKUP_DIR" ]; then
    echo "Backup not found: $BACKUP_DIR"
    exit 1
fi

echo "âš ï¸  Restoring from: $BACKUP_DIR"
read -p "Continue? (yes/no): " confirm

if [ "$confirm" != "yes" ]; then
    exit 1
fi

# Stop application
pm2 stop all

# Restore database
gunzip -c $BACKUP_DIR/database.sql.gz | \
    PGPASSWORD=$DB_PASSWORD psql -h localhost -U $DB_USER $DB_NAME

# Start application
pm2 start all

echo "âœ… Restore complete!"
```

---

# Chapter 14: Security Hardening

## 14.1 Server Hardening Checklist

```bash
# 1. Update system
sudo apt update && sudo apt upgrade -y

# 2. Create non-root user
sudo adduser deploy
sudo usermod -aG sudo deploy

# 3. SSH Hardening
sudo nano /etc/ssh/sshd_config
# PermitRootLogin no
# PasswordAuthentication no
# AllowUsers deploy
# MaxAuthTries 3

# 4. Firewall
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow 22
sudo ufw allow 80
sudo ufw allow 443
sudo ufw enable

# 5. fail2ban
sudo apt install fail2ban -y
sudo systemctl enable fail2ban

# 6. Automatic security updates
sudo apt install unattended-upgrades -y
sudo dpkg-reconfigure unattended-upgrades
```

## 14.2 Application Security

```bash
# Secure .env file
chmod 600 .env

# Redis security
# bind 127.0.0.1
# requirepass strong_password

# PostgreSQL security
# Listen on localhost only
# Use strong passwords
# Regular backups
```

## 14.3 Security Headers (Nginx)

```nginx
# Security headers
add_header X-Frame-Options "SAMEORIGIN" always;
add_header X-Content-Type-Options "nosniff" always;
add_header X-XSS-Protection "1; mode=block" always;
add_header Referrer-Policy "strict-origin-when-cross-origin" always;
add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

# Hide Nginx version
server_tokens off;
```

---

# PART 5: ADVANCED TOPICS

---

# Chapter 15: Performance Tuning

## 15.1 Linux Kernel Tuning

```bash
# /etc/sysctl.d/99-performance.conf

# Network
net.core.somaxconn = 65535
net.core.netdev_max_backlog = 65535
net.ipv4.tcp_max_syn_backlog = 65535
net.ipv4.tcp_tw_reuse = 1

# Memory
vm.swappiness = 10

# File descriptors
fs.file-max = 2097152
```

```bash
# Apply
sudo sysctl -p /etc/sysctl.d/99-performance.conf
```

## 15.2 Ulimit Settings

```bash
# /etc/security/limits.conf

*               soft    nofile          65535
*               hard    nofile          65535
```

## 15.3 Nginx Performance

```nginx
worker_processes auto;
worker_rlimit_nofile 65535;

events {
    worker_connections 65535;
    use epoll;
    multi_accept on;
}

http {
    # Buffers
    client_body_buffer_size 10K;
    client_max_body_size 8m;
    
    # Timeouts
    keepalive_timeout 15;
    send_timeout 10;
    
    # Compression
    gzip on;
    gzip_comp_level 5;
    gzip_min_length 256;
    gzip_types application/javascript text/css application/json;
    
    # Caching
    open_file_cache max=1000 inactive=20s;
}
```

---

# Chapter 16: Cloud Infrastructure (OCI)

## 16.1 OCI Networking

```
VCN (10.0.0.0/16)
â”œâ”€â”€ Public Subnet (10.0.1.0/24)
â”‚   â”œâ”€â”€ Internet Gateway
â”‚   â””â”€â”€ Nginx/Bastion instances
â”‚
â”œâ”€â”€ Private Subnet (10.0.2.0/24)
â”‚   â”œâ”€â”€ NAT Gateway (outbound only)
â”‚   â””â”€â”€ App servers, databases
â”‚
â””â”€â”€ Security:
    â”œâ”€â”€ Network Security Groups (instance-level)
    â””â”€â”€ Security Lists (subnet-level)
```

## 16.2 Best Practices

```
1. Use private subnets for databases
2. Use NSGs instead of Security Lists when possible
3. Enable VCN Flow Logs
4. Use bastion host for SSH access
5. Keep resources in same region for low latency
```

---

# Chapter 17: Infrastructure as Code

## 17.1 Ansible Basics

```yaml
# playbook.yml
---
- name: Setup Web Server
  hosts: webservers
  become: yes
  
  tasks:
    - name: Update apt cache
      apt:
        update_cache: yes
    
    - name: Install Nginx
      apt:
        name: nginx
        state: present
    
    - name: Start Nginx
      service:
        name: nginx
        state: started
        enabled: yes
```

```bash
# Run playbook
ansible-playbook -i inventory.ini playbook.yml
```

---

# Chapter 18: CI/CD Pipelines

## 18.1 GitHub Actions

```yaml
# .github/workflows/deploy.yml

name: Deploy

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run tests
        run: npm test

  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Deploy to server
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.HOST }}
          username: ${{ secrets.USERNAME }}
          key: ${{ secrets.SSH_KEY }}
          script: |
            cd /var/www/myapp
            git pull origin main
            npm ci --production
            pm2 reload ecosystem.config.js --env production
```

---

# Chapter 19: Containers & Docker

## 19.1 Docker Basics

```bash
# Install Docker
curl -fsSL https://get.docker.com | sh
sudo usermod -aG docker $USER

# Basic commands
docker run -d -p 80:80 nginx
docker ps                       # List containers
docker logs container_id
docker exec -it container_id bash
docker stop container_id
docker rm container_id
```

## 19.2 Dockerfile

```dockerfile
FROM node:20-alpine

WORKDIR /app

COPY package*.json ./
RUN npm ci --production

COPY . .

EXPOSE 3000

USER node

CMD ["node", "app.js"]
```

```bash
# Build and run
docker build -t myapp:latest .
docker run -d -p 3000:3000 --name myapp myapp:latest
```

## 19.3 Docker Compose

```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - REDIS_HOST=redis
      - DATABASE_URL=postgresql://user:pass@db:5432/mydb
    depends_on:
      - redis
      - db
    restart: unless-stopped

  redis:
    image: redis:alpine
    volumes:
      - redis-data:/data
    restart: unless-stopped

  db:
    image: postgres:15
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=mydb
    volumes:
      - postgres-data:/var/lib/postgresql/data
    restart: unless-stopped

volumes:
  redis-data:
  postgres-data:
```

```bash
docker-compose up -d
docker-compose down
docker-compose logs -f app
```

---

# PART 6: PROFESSIONAL PRACTICES

---

# Chapter 20: Professional Practices

## 20.1 Post-Mortem Template

```markdown
# Incident Post-Mortem

## Summary
On [DATE], [SERVICE] was unavailable for [DURATION].

## Timeline
- 14:00 - Alert triggered
- 14:05 - On-call acknowledged
- 14:10 - Root cause identified
- 14:15 - Fix deployed
- 14:20 - Service restored

## Root Cause
[Description]

## Impact
- X users affected
- Y minutes of downtime

## Action Items
- [ ] Add monitoring alert
- [ ] Fix root cause
- [ ] Document procedure
```

## 20.2 Documentation

Every project should have:

```markdown
# Project Name

## Quick Start
\```bash
git clone <repo>
npm install
cp .env.example .env
npm run dev
\```

## Environment Variables
| Variable | Description | Required |
|----------|-------------|----------|
| DATABASE_URL | PostgreSQL connection | Yes |
| REDIS_URL | Redis connection | Yes |

## Deployment
\```bash
./scripts/deploy.sh
\```

## Rollback
\```bash
./scripts/rollback.sh
\```
```

---

# Chapter 21: Capstone Projects

## Project 1: Full-Stack Deployment

Deploy a Node.js application with PostgreSQL, Redis, Nginx, and SSL.

### Architecture

```
Internet â†’ Cloudflare â†’ Oracle Cloud Firewall
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Ubuntu Server     â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
                    â”‚  â”‚ Nginx (SSL)   â”‚â”‚
                    â”‚  â”‚ Port 443      â”‚â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                    â”‚          â”‚        â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”â”‚
                    â”‚  â”‚ Node.js (PM2) â”‚â”‚
                    â”‚  â”‚ Port 3000     â”‚â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                    â”‚     â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”   â”‚
                    â”‚     â”‚         â”‚   â”‚
                    â”‚  â”Œâ”€â”€â”´â”€â”€â”  â”Œâ”€â”€â”´â”€â”€â”â”‚
                    â”‚  â”‚ PG  â”‚  â”‚Redisâ”‚â”‚
                    â”‚  â”‚5432 â”‚  â”‚6379 â”‚â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation Steps

1. Server setup & security hardening
2. Install Nginx, PostgreSQL, Redis, Node.js, PM2
3. Configure database and Redis
4. Deploy application with PM2
5. Configure Nginx reverse proxy
6. Setup SSL with Let's Encrypt
7. Configure firewall
8. Setup automated backups
9. Configure monitoring

---

# PART 7: FREE CLOUD & COMPLETE WALKTHROUGHS

---

# Chapter 22: Free Cloud Deployment Options

One of the best ways to learn DevOps is to practice with real servers. Several cloud providers offer generous free tiers.

## 22.1 Comparison of Free Tier Providers

| Provider | Free Resources | Best For | Duration |
|----------|---------------|----------|----------|
| Oracle Cloud | 4 ARM cores, 24GB RAM, 200GB storage | Full-stack apps, databases | Forever |
| Google Cloud | $300 credit + always-free tier | GCP ecosystem, ML/AI | 90 days + forever |
| AWS | 750 hrs EC2, 5GB S3 | Enterprise, AWS ecosystem | 12 months |
| Vercel | 100GB bandwidth, unlimited deploys | Next.js, React frontends | Forever |
| Netlify | 100GB bandwidth, 300 build min | Static sites, JAMstack | Forever |
| Railway | $5 credit/month | Full-stack, databases | Forever |
| Render | Static sites, limited web services | Node.js, Python apps | Forever |
| Cloudflare Pages | Unlimited bandwidth | Static sites, edge functions | Forever |
| Firebase | 10GB hosting, 360MB/day transfer | Mobile backends, real-time | Forever |

## 22.2 Oracle Cloud Free Tier (Best for Full Control)

Oracle Cloud offers the most generous always-free VPS resources.

### What You Get Forever Free:

- ARM-based Ampere A1: 4 OCPUs + 24GB RAM (can split into up to 4 VMs)
- AMD-based VMs: 2 instances with 1/8 OCPU + 1GB RAM each
- Block Storage: Up to 200GB total
- Object Storage: 20GB
- Outbound Data Transfer: 10TB/month
- Load Balancer: 1 instance (10 Mbps)
- Autonomous Database: 2 instances

### Step-by-Step: Create Oracle Cloud Account

1. Go to cloud.oracle.com and click "Start for free"
2. Fill in your details (use a valid email)
3. Verify your email address
4. Provide payment method (verification only, no charge)
5. Select your home region (choose closest to you)
6. Wait for account provisioning

### Step-by-Step: Create Your First VM

1. Login to Oracle Cloud Console
2. Navigate to Compute > Instances > Create Instance
3. Name your instance (e.g., "my-web-server")
4. Under "Image and shape":
   - Click "Change image" > Select "Ubuntu" (22.04 or 24.04)
   - Click "Change shape" > Select "Ampere" > VM.Standard.A1.Flex
   - Set OCPUs to 4 and Memory to 24GB
5. Under "Networking": Ensure "Assign a public IPv4 address" is selected
6. Under "Add SSH keys": Upload your public key or generate a new pair
7. Click "Create"

### Configure Oracle Cloud Firewall

Oracle Cloud has TWO layers of firewall. Configure BOTH:

**Step 1: Cloud Security List (in Oracle Console)**
- Go to Networking > Virtual Cloud Networks
- Click your VCN > Security Lists > Default Security List
- Add Ingress Rules for ports: 22 (SSH), 80 (HTTP), 443 (HTTPS)

**Step 2: OS Firewall (on the server via SSH)**
```bash
# For Ubuntu
sudo iptables -I INPUT -p tcp --dport 80 -j ACCEPT
sudo iptables -I INPUT -p tcp --dport 443 -j ACCEPT
sudo netfilter-persistent save

# Or use UFW
sudo ufw allow 80
sudo ufw allow 443
```

## 22.3 Vercel (Best for Next.js/React)

### Free Tier Includes:
- Unlimited personal projects
- 100GB bandwidth/month
- Automatic SSL/HTTPS
- Global CDN
- Serverless Functions
- Preview Deployments on every PR

### Deploy to Vercel:

```bash
# Install CLI
npm install -g vercel

# Deploy
cd your-project
vercel

# Production deployment
vercel --prod
```

Or deploy via GitHub:
1. Push your code to GitHub
2. Go to vercel.com and sign in with GitHub
3. Click "New Project" > Import your repository
4. Vercel auto-detects your framework
5. Click Deploy

## 22.4 Netlify (Best for Static Sites & JAMstack)

### Free Tier Includes:
- 100GB bandwidth/month
- 300 build minutes/month
- Continuous Deployment from Git
- Serverless Functions
- Form handling (100 submissions/month)

### Deploy to Netlify:

```bash
npm install -g netlify-cli
netlify login
netlify deploy
netlify deploy --prod

# Or drag-and-drop at netlify.com/drop
```

## 22.5 Railway (Best for Full-Stack with Databases)

### Free Tier Includes:
- $5 credit/month (usage-based)
- 500 hours of compute
- One-click PostgreSQL, MySQL, MongoDB, Redis
- Private networking between services

### Deploy Node.js App with PostgreSQL:

```bash
npm install -g @railway/cli
railway login
railway init
railway add postgresql
railway up
railway domain
```

## 22.6 Render (Best for Node.js/Python Apps)

### Free Tier Includes:
- Static Sites: Unlimited
- Web Services: 750 hours/month
- PostgreSQL: 90 days free trial
- Automatic HTTPS

### Deploy to Render:

1. Push your code to GitHub/GitLab
2. Go to render.com and create account
3. New > Web Service > Connect your repo
4. Select "Free" instance type
5. Set build and start commands
6. Click "Create Web Service"

## 22.7 Cloudflare Pages (Best Performance)

### Free Tier Includes:
- Unlimited bandwidth
- Unlimited requests
- 500 builds/month
- Global CDN (300+ locations)
- DDoS protection

```bash
npm install -g wrangler
wrangler login
npx create-cloudflare@latest my-site
npm run deploy
```

---

# Chapter 23: Complete Deployment Walkthrough

This chapter walks you through deploying a full-stack Node.js application step by step.

## 23.1 Architecture Overview

We'll deploy:
- Ubuntu Server on Oracle Cloud (ARM)
- Node.js application managed by PM2
- Nginx as reverse proxy
- PostgreSQL database
- Redis for caching/sessions
- SSL certificate via Let's Encrypt
- UFW firewall + fail2ban

## 23.2 Phase 1: Server Setup

### Step 1: Connect to Your Server

```bash
# Add to ~/.ssh/config
Host oracle
    HostName YOUR_SERVER_IP
    User ubuntu
    IdentityFile ~/.ssh/your_key
    ServerAliveInterval 60

# Connect
ssh oracle
```

### Step 2: Initial Server Configuration

```bash
# Update system
sudo apt update && sudo apt upgrade -y

# Set timezone
sudo timedatectl set-timezone America/New_York

# Create deploy user (optional)
sudo adduser deploy
sudo usermod -aG sudo deploy
```

### Step 3: Configure Firewall

```bash
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow ssh
sudo ufw allow http
sudo ufw allow https
sudo ufw enable
```

### Step 4: Install fail2ban

```bash
sudo apt install fail2ban -y

sudo tee /etc/fail2ban/jail.local << EOF
[DEFAULT]
bantime = 1h
findtime = 10m
maxretry = 5

[sshd]
enabled = true
maxretry = 3
bantime = 24h
EOF

sudo systemctl restart fail2ban
sudo systemctl enable fail2ban
```

### Step 5: Harden SSH

```bash
sudo nano /etc/ssh/sshd_config

# Make these changes:
# PermitRootLogin no
# PasswordAuthentication no
# PubkeyAuthentication yes
# MaxAuthTries 3

sudo sshd -t
sudo systemctl restart sshd
```

## 23.3 Phase 2: Install Software Stack

### Install Node.js

```bash
curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
sudo apt install -y nodejs

node --version
npm --version

sudo npm install -g pm2
```

### Install PostgreSQL

```bash
sudo apt install postgresql postgresql-contrib -y
sudo systemctl start postgresql
sudo systemctl enable postgresql

sudo -u postgres psql << EOF
CREATE USER myapp WITH PASSWORD 'strong_password_here';
CREATE DATABASE myapp_production OWNER myapp;
GRANT ALL PRIVILEGES ON DATABASE myapp_production TO myapp;
\q
EOF
```

### Install Redis

```bash
sudo apt install redis-server -y

sudo nano /etc/redis/redis.conf
# Set: bind 127.0.0.1
# Set: requirepass your_redis_password

sudo systemctl restart redis-server
sudo systemctl enable redis-server

redis-cli ping  # Should return PONG
```

### Install Nginx

```bash
sudo apt install nginx -y
sudo systemctl start nginx
sudo systemctl enable nginx

curl localhost  # Should see Nginx welcome page
```

## 23.4 Phase 3: Deploy Your Application

### Step 1: Create Application Directory

```bash
sudo mkdir -p /var/www/myapp
sudo chown -R ubuntu:ubuntu /var/www/myapp
cd /var/www/myapp
```

### Step 2: Clone Your Code

```bash
# Option A: Clone from Git
git clone https://github.com/yourusername/yourrepo.git .

# Option B: Upload via rsync (from local machine)
rsync -avz --exclude='node_modules' --exclude='.git' \
    ./myapp/ oracle:/var/www/myapp/
```

### Step 3: Configure Environment Variables

```bash
cat > .env << EOF
NODE_ENV=production
PORT=3000
DATABASE_URL=postgresql://myapp:strong_password_here@localhost:5432/myapp_production
REDIS_URL=redis://:your_redis_password@localhost:6379
SESSION_SECRET=$(openssl rand -hex 32)
EOF

chmod 600 .env
```

### Step 4: Install Dependencies and Build

```bash
npm ci --production
# npm run build  # if you have a build step
```

### Step 5: Start with PM2

```bash
cat > ecosystem.config.js << 'EOF'
module.exports = {
  apps: [{
    name: 'myapp',
    script: 'app.js',
    instances: 'max',
    exec_mode: 'cluster',
    env_production: {
      NODE_ENV: 'production'
    },
    max_memory_restart: '500M'
  }]
};
EOF

pm2 start ecosystem.config.js --env production
pm2 save
pm2 startup  # Run the command it outputs!

pm2 list
pm2 logs
```

## 23.5 Phase 4: Configure Nginx Reverse Proxy

```bash
sudo nano /etc/nginx/sites-available/myapp
```

```nginx
upstream myapp {
    server 127.0.0.1:3000;
    keepalive 64;
}

server {
    listen 80;
    server_name yourdomain.com www.yourdomain.com;

    # Security headers
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;

    # Gzip compression
    gzip on;
    gzip_types text/plain application/json application/javascript text/css;

    location / {
        proxy_pass http://myapp;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
    }
}
```

```bash
sudo ln -s /etc/nginx/sites-available/myapp /etc/nginx/sites-enabled/
sudo rm /etc/nginx/sites-enabled/default
sudo nginx -t
sudo nginx -s reload
```

## 23.6 Phase 5: Setup SSL with Let's Encrypt

```bash
sudo apt install certbot python3-certbot-nginx -y

sudo certbot --nginx -d yourdomain.com -d www.yourdomain.com

sudo certbot renew --dry-run
```

## 23.7 Phase 6: Setup Automated Backups

```bash
sudo nano /usr/local/bin/backup.sh
```

```bash
#!/bin/bash
BACKUP_DIR="/var/backups/myapp"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=7

mkdir -p $BACKUP_DIR/$DATE

# Backup PostgreSQL
PGPASSWORD='strong_password_here' pg_dump -h localhost -U myapp myapp_production | gzip > $BACKUP_DIR/$DATE/database.sql.gz

# Backup application files
tar -czf $BACKUP_DIR/$DATE/app.tar.gz --exclude='node_modules' /var/www/myapp

# Cleanup old backups
find $BACKUP_DIR -type d -mtime +$RETENTION_DAYS -exec rm -rf {} \; 2>/dev/null

echo "Backup completed: $DATE"
```

```bash
sudo chmod +x /usr/local/bin/backup.sh

# Add to cron (daily at 2 AM)
sudo crontab -e
# Add: 0 2 * * * /usr/local/bin/backup.sh >> /var/log/backup.log 2>&1
```

## 23.8 Phase 7: Setup Health Monitoring

### Add Health Check Endpoint to Your App

```javascript
app.get('/health', async (req, res) => {
  try {
    await db.query('SELECT 1');
    await redis.ping();
    res.json({ 
      status: 'healthy', 
      timestamp: new Date().toISOString(),
      uptime: process.uptime() 
    });
  } catch (error) {
    res.status(503).json({ 
      status: 'unhealthy', 
      error: error.message 
    });
  }
});
```

### Setup Simple Monitoring Script

```bash
sudo nano /usr/local/bin/healthcheck.sh
```

```bash
#!/bin/bash
if ! curl -sf http://localhost:3000/health > /dev/null; then
    echo "$(date): Health check failed, restarting PM2" >> /var/log/healthcheck.log
    pm2 restart myapp
fi
```

```bash
sudo chmod +x /usr/local/bin/healthcheck.sh

# Add to cron (every 5 minutes)
sudo crontab -e
# Add: */5 * * * * /usr/local/bin/healthcheck.sh
```

## 23.9 Deployment Checklist

| Category | Item | Status |
|----------|------|--------|
| Server | System updated | â–¡ |
| Server | Non-root user created | â–¡ |
| Server | SSH key authentication only | â–¡ |
| Security | UFW firewall enabled | â–¡ |
| Security | fail2ban configured | â–¡ |
| Security | SSH hardened | â–¡ |
| Application | Code deployed | â–¡ |
| Application | Dependencies installed | â–¡ |
| Application | Environment variables set | â–¡ |
| Application | PM2 running in cluster mode | â–¡ |
| Application | PM2 startup configured | â–¡ |
| Database | PostgreSQL secured | â–¡ |
| Database | Redis password set | â–¡ |
| Database | Backups scheduled | â–¡ |
| Web Server | Nginx configured | â–¡ |
| Web Server | SSL certificate installed | â–¡ |
| Web Server | HTTPS redirect working | â–¡ |
| Monitoring | Health check endpoint | â–¡ |
| Monitoring | Log rotation configured | â–¡ |

---

# Chapter 24: Automated Deployment Scripts

## 24.1 Simple Deployment Script

```bash
#!/bin/bash
# deploy.sh - Simple deployment script

set -e  # Exit on error

APP_DIR="/var/www/myapp"
BRANCH="main"

echo "ğŸš€ Starting deployment..."

# Pull latest code
cd $APP_DIR
git fetch origin
git reset --hard origin/$BRANCH

# Install dependencies
npm ci --production

# Build if needed
# npm run build

# Reload PM2 (zero-downtime)
pm2 reload ecosystem.config.js --env production

# Verify health
sleep 5
if curl -sf http://localhost:3000/health > /dev/null; then
    echo "âœ… Deployment successful!"
else
    echo "âŒ Health check failed!"
    exit 1
fi
```

## 24.2 Blue-Green Deployment Script

```bash
#!/bin/bash
# blue-green-deploy.sh

set -e

APP_BASE="/var/www"
CURRENT_LINK="$APP_BASE/current"
RELEASES_DIR="$APP_BASE/releases"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
NEW_RELEASE="$RELEASES_DIR/$TIMESTAMP"

echo "ğŸš€ Blue-Green Deployment starting..."

# Create new release directory
mkdir -p $NEW_RELEASE
cd $NEW_RELEASE

# Clone code
git clone --depth 1 https://github.com/user/repo.git .

# Copy shared files
ln -s $APP_BASE/shared/.env .env
ln -s $APP_BASE/shared/uploads uploads

# Install and build
npm ci --production
# npm run build

# Switch symlink (atomic operation)
ln -sfn $NEW_RELEASE $CURRENT_LINK

# Reload application
pm2 reload ecosystem.config.js --env production

# Health check
sleep 5
if curl -sf http://localhost:3000/health > /dev/null; then
    echo "âœ… Deployment successful!"
    
    # Cleanup old releases (keep last 5)
    cd $RELEASES_DIR
    ls -t | tail -n +6 | xargs -r rm -rf
else
    echo "âŒ Deployment failed! Rolling back..."
    PREV_RELEASE=$(ls -t $RELEASES_DIR | sed -n '2p')
    ln -sfn $RELEASES_DIR/$PREV_RELEASE $CURRENT_LINK
    pm2 reload ecosystem.config.js --env production
    exit 1
fi
```

## 24.3 GitHub Actions CI/CD

```yaml
# .github/workflows/deploy.yml

name: Deploy to Production

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run tests
        run: npm test
      
      - name: Deploy to server
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.HOST }}
          username: ${{ secrets.USERNAME }}
          key: ${{ secrets.SSH_KEY }}
          script: |
            cd /var/www/myapp
            git pull origin main
            npm ci --production
            pm2 reload ecosystem.config.js --env production
```

---

# Chapter 25: Quick Reference

## 25.1 Essential Commands Cheatsheet

| Task | Command |
|------|---------|
| System update | `sudo apt update && sudo apt upgrade -y` |
| Check disk space | `df -h` |
| Check memory | `free -h` |
| View running processes | `htop` |
| Check open ports | `sudo ss -tulpn` |
| View service status | `sudo systemctl status nginx` |
| Restart service | `sudo systemctl restart nginx` |
| View logs | `sudo journalctl -u nginx -f` |
| PM2 status | `pm2 list` |
| PM2 logs | `pm2 logs --lines 100` |
| PM2 restart | `pm2 reload all` |
| Nginx test config | `sudo nginx -t` |
| Nginx reload | `sudo nginx -s reload` |
| UFW status | `sudo ufw status verbose` |
| fail2ban status | `sudo fail2ban-client status sshd` |
| SSL certificate renew | `sudo certbot renew` |
| Database backup | `pg_dump -U user dbname > backup.sql` |
| Redis CLI | `redis-cli -a password` |

## 25.2 Important File Locations

| Purpose | Location |
|---------|----------|
| Nginx sites | `/etc/nginx/sites-available/` |
| Nginx logs | `/var/log/nginx/` |
| SSH config | `/etc/ssh/sshd_config` |
| PostgreSQL config | `/etc/postgresql/*/main/` |
| Redis config | `/etc/redis/redis.conf` |
| PM2 logs | `~/.pm2/logs/` |
| SSL certificates | `/etc/letsencrypt/live/` |
| System logs | `/var/log/syslog` |
| Auth logs | `/var/log/auth.log` |
| Web root | `/var/www/` |
| Cron jobs | `/etc/cron.d/` or `crontab -e` |
| UFW rules | `/etc/ufw/` |
| fail2ban config | `/etc/fail2ban/jail.local` |

## 25.3 Free Tier Quick Reference

| Action | Platform | Command/URL |
|--------|----------|-------------|
| Deploy static site | Netlify | `netlify deploy --prod` |
| Deploy Next.js | Vercel | `vercel --prod` |
| Deploy full-stack | Railway | `railway up` |
| Deploy Node.js | Render | `git push` (auto-deploy) |
| Create VPS | Oracle Cloud | cloud.oracle.com |
| Get SSL cert | Let's Encrypt | `sudo certbot --nginx -d domain.com` |
| Free CDN | Cloudflare | cloudflare.com |
| Free monitoring | UptimeRobot | uptimerobot.com |
| Free error tracking | Sentry | sentry.io (5K errors/mo) |

---

# Conclusion

Congratulations! You now have comprehensive knowledge to deploy and manage production applications.

## What You've Learned:

- âœ… Linux server administration and command-line mastery
- âœ… SSH security and key management
- âœ… Web server configuration with Nginx
- âœ… Process management with PM2 and systemd
- âœ… Database setup and management (PostgreSQL, Redis)
- âœ… SSL/TLS encryption with Let's Encrypt
- âœ… Firewall configuration and security hardening
- âœ… Automated backups and disaster recovery
- âœ… CI/CD pipelines with GitHub Actions
- âœ… Free cloud deployment options
- âœ… Complete production deployment workflows

## Next Steps:

1. **Practice on Oracle Cloud Free Tier** - Get hands-on experience
2. **Deploy a real application** - Start with something simple
3. **Break things and fix them** - Best way to learn
4. **Document everything** - Your future self will thank you
5. **Iterate and improve** - DevOps is a continuous journey

## Remember the DevOps Mantra:

> **Automate everything, version control everything, and always have a rollback plan.**

---

**Good luck on your DevOps journey! ğŸš€**

---

# Chapter 26: Cloud Provider Fundamentals

> *"Moving beyond single-server thinking to cloud-native architecture"*

## 26.1 Why This Matters

```
Single Server Approach:          Cloud Platform Approach:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    One VM           â”‚          â”‚         VPC Network             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Everything    â”‚  â”‚          â”‚  â”‚ Web Tierâ”‚    â”‚ App Tierâ”‚    â”‚
â”‚  â”‚ runs here     â”‚  â”‚   â†’      â”‚  â”‚ (Public)â”‚â”€â”€â”€â”€â”‚(Private)â”‚    â”‚
â”‚  â”‚               â”‚  â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚          â”‚                      â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚                â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”   â”‚
                                 â”‚                â”‚  DB Tier  â”‚   â”‚
Problems:                        â”‚                â”‚ (Private) â”‚   â”‚
- Single point of failure        â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
- Can't scale                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
- Large blast radius             
- Everything exposed             Benefits:
                                 - Isolation & security
                                 - Independent scaling
                                 - Reduced blast radius
                                 - Professional architecture
```

## 26.2 IAM & Identity Management

### Understanding IAM (Identity and Access Management)

```
IAM Controls:
â”œâ”€â”€ WHO can access (Authentication)
â”‚   â”œâ”€â”€ Users (humans)
â”‚   â”œâ”€â”€ Service Accounts (applications)
â”‚   â””â”€â”€ Groups (collections of users)
â”‚
â”œâ”€â”€ WHAT they can access (Authorization)
â”‚   â”œâ”€â”€ Resources (VMs, databases, storage)
â”‚   â””â”€â”€ Actions (read, write, delete, admin)
â”‚
â””â”€â”€ HOW access is verified (Policies)
    â”œâ”€â”€ Role-based access (RBAC)
    â””â”€â”€ Attribute-based access (ABAC)
```

### IAM Best Practices

```
Principle of Least Privilege:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âŒ BAD: Give admin access to everyone                          â”‚
â”‚  âœ… GOOD: Give minimum permissions needed for the job           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Examples:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Role               â”‚ Permissions                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Developer          â”‚ Read logs, deploy to dev environment        â”‚
â”‚ DevOps Engineer    â”‚ Manage infrastructure, deploy to prod       â”‚
â”‚ Database Admin     â”‚ Manage databases only                       â”‚
â”‚ Security Auditor   â”‚ Read-only access to audit logs              â”‚
â”‚ Application        â”‚ Read secrets, write to specific bucket      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Users vs Service Accounts

```bash
# User Account (for humans)
- Has password/MFA
- Interactive login
- Example: john@company.com

# Service Account (for applications)
- Has API keys/tokens
- No interactive login
- Example: app-backend@project.iam.gserviceaccount.com
```

### OCI IAM Setup

```bash
# OCI uses Compartments for resource organization
# Think of it as folders for cloud resources

# Structure example:
root (tenancy)
â”œâ”€â”€ Production
â”‚   â”œâ”€â”€ prod-network
â”‚   â”œâ”€â”€ prod-compute
â”‚   â””â”€â”€ prod-database
â”œâ”€â”€ Development
â”‚   â”œâ”€â”€ dev-network
â”‚   â””â”€â”€ dev-compute
â””â”€â”€ Shared
    â””â”€â”€ shared-storage
```

### Key Rotation Policy

```bash
# NEVER use permanent credentials!

# Key Rotation Schedule:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Credential Type     â”‚ Rotation Period  â”‚ How                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SSH Keys            â”‚ 90 days          â”‚ Generate new, update    â”‚
â”‚ API Keys            â”‚ 90 days          â”‚ Rotate in cloud console â”‚
â”‚ Database Passwords  â”‚ 90 days          â”‚ Update + restart apps   â”‚
â”‚ Service Account Keysâ”‚ 30-90 days       â”‚ Create new, delete old  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Automation script for tracking key age:
#!/bin/bash
# check-key-age.sh

KEY_FILE="$HOME/.ssh/id_ed25519"
KEY_AGE_DAYS=$(( ($(date +%s) - $(stat -c %Y "$KEY_FILE")) / 86400 ))

if [ $KEY_AGE_DAYS -gt 90 ]; then
    echo "âš ï¸  SSH key is $KEY_AGE_DAYS days old. Time to rotate!"
else
    echo "âœ… SSH key is $KEY_AGE_DAYS days old. OK."
fi
```

## 26.3 VPC Networking Deep Dive

### VPC Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        VPC (10.0.0.0/16)                                â”‚
â”‚                                                                         â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚                    PUBLIC SUBNET (10.0.1.0/24)                  â”‚  â”‚
â”‚    â”‚                                                                 â”‚  â”‚
â”‚    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚  â”‚
â”‚    â”‚   â”‚ Bastion â”‚    â”‚  Nginx  â”‚    â”‚  Nginx  â”‚                    â”‚  â”‚
â”‚    â”‚   â”‚  Host   â”‚    â”‚   LB    â”‚    â”‚   LB    â”‚                    â”‚  â”‚
â”‚    â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                    â”‚  â”‚
â”‚    â”‚        â”‚              â”‚              â”‚                          â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚             â”‚              â”‚              â”‚                              â”‚
â”‚             â”‚         â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”                        â”‚
â”‚             â”‚         â”‚                        â”‚                        â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚        â”‚    PRIVATE SUBNET (10.0.2.0/24)  â”‚                     â”‚  â”‚
â”‚    â”‚        â”‚         â”‚                        â”‚                     â”‚  â”‚
â”‚    â”‚        â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚                     â”‚  â”‚
â”‚    â”‚        â””â”€â”€â”€>â”‚  App    â”‚    â”‚   App   â”‚    â”‚                     â”‚  â”‚
â”‚    â”‚   (SSH)     â”‚ Server  â”‚    â”‚ Server  â”‚    â”‚                     â”‚  â”‚
â”‚    â”‚             â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â”‚                     â”‚  â”‚
â”‚    â”‚                  â”‚              â”‚         â”‚                     â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â”‚              â”‚         â”‚                        â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚             DATABASE SUBNET (10.0.3.0/24) â”‚                     â”‚  â”‚
â”‚    â”‚                  â”‚              â”‚         â”‚                     â”‚  â”‚
â”‚    â”‚             â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”    â”‚                     â”‚  â”‚
â”‚    â”‚             â”‚ Primary â”‚    â”‚ Replica â”‚    â”‚                     â”‚  â”‚
â”‚    â”‚             â”‚   DB    â”‚â”€â”€â”€>â”‚   DB    â”‚    â”‚                     â”‚  â”‚
â”‚    â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                     â”‚  â”‚
â”‚    â”‚                                           â”‚                     â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚    â”‚   Internet   â”‚                           â”‚     NAT      â”‚         â”‚
â”‚    â”‚   Gateway    â”‚                           â”‚   Gateway    â”‚         â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚           â”‚                                          â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                          â”‚
            â–¼                                          â–¼
       INTERNET                                   INTERNET
    (inbound+outbound)                         (outbound only)
```

### Subnet Types Explained

```
PUBLIC SUBNET:
â”œâ”€â”€ Has route to Internet Gateway
â”œâ”€â”€ Resources get public IPs
â”œâ”€â”€ Accessible from internet
â””â”€â”€ Use for: Load balancers, bastion hosts, public-facing services

PRIVATE SUBNET:
â”œâ”€â”€ No direct internet access
â”œâ”€â”€ Resources only have private IPs
â”œâ”€â”€ Uses NAT Gateway for outbound (updates, API calls)
â””â”€â”€ Use for: App servers, databases, internal services

DATABASE SUBNET:
â”œâ”€â”€ Most restricted
â”œâ”€â”€ No internet access (even outbound)
â”œâ”€â”€ Only accessible from app subnet
â””â”€â”€ Use for: Databases, sensitive data stores
```

### Route Tables

```bash
# Public Subnet Route Table
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Destination         â”‚ Target              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 10.0.0.0/16        â”‚ local               â”‚  â† VPC internal
â”‚ 0.0.0.0/0          â”‚ Internet Gateway    â”‚  â† All other â†’ internet
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Private Subnet Route Table
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Destination         â”‚ Target              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 10.0.0.0/16        â”‚ local               â”‚  â† VPC internal
â”‚ 0.0.0.0/0          â”‚ NAT Gateway         â”‚  â† Outbound only
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### OCI VCN Setup (Step by Step)

```bash
# 1. Create VCN with Wizard (easiest)
# OCI Console â†’ Networking â†’ Virtual Cloud Networks
# â†’ Start VCN Wizard â†’ Create VCN with Internet Connectivity

# This creates:
# - VCN (10.0.0.0/16)
# - Public Subnet (10.0.0.0/24)
# - Private Subnet (10.0.1.0/24)
# - Internet Gateway
# - NAT Gateway
# - Service Gateway
# - Route Tables
# - Security Lists

# 2. Or create manually via CLI:
oci network vcn create \
    --compartment-id $COMPARTMENT_ID \
    --cidr-blocks '["10.0.0.0/16"]' \
    --display-name "production-vcn"

# 3. Create subnets
oci network subnet create \
    --compartment-id $COMPARTMENT_ID \
    --vcn-id $VCN_ID \
    --cidr-block "10.0.1.0/24" \
    --display-name "public-subnet" \
    --prohibit-public-ip-on-vnic false

oci network subnet create \
    --compartment-id $COMPARTMENT_ID \
    --vcn-id $VCN_ID \
    --cidr-block "10.0.2.0/24" \
    --display-name "private-subnet" \
    --prohibit-public-ip-on-vnic true
```

## 26.4 Cloud Load Balancing

### Load Balancer Types

```
Layer 4 (Network/TCP):
â”œâ”€â”€ Routes based on IP and port
â”œâ”€â”€ Faster, lower latency
â”œâ”€â”€ No HTTP awareness
â””â”€â”€ Use for: TCP services, databases, non-HTTP

Layer 7 (Application/HTTP):
â”œâ”€â”€ Routes based on URL, headers, cookies
â”œâ”€â”€ Can do SSL termination
â”œâ”€â”€ Health checks at HTTP level
â””â”€â”€ Use for: Web apps, APIs, microservices
```

### Load Balancer Architecture

```
                    INTERNET
                        â”‚
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Cloud Load     â”‚
              â”‚  Balancer       â”‚
              â”‚                 â”‚
              â”‚  - SSL Termination
              â”‚  - Health Checksâ”‚
              â”‚  - Routing Rulesâ”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚             â”‚             â”‚
         â–¼             â–¼             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Server  â”‚   â”‚ Server  â”‚   â”‚ Server  â”‚
    â”‚   1     â”‚   â”‚   2     â”‚   â”‚   3     â”‚
    â”‚ :3000   â”‚   â”‚ :3000   â”‚   â”‚ :3000   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### OCI Load Balancer Setup

```bash
# Create Load Balancer
# OCI Console â†’ Networking â†’ Load Balancers â†’ Create

# Configuration:
# - Type: Layer 7 (HTTP/HTTPS)
# - Shape: Flexible (10 Mbps free tier)
# - Subnet: Public subnet
# - Backends: Your app servers (private subnet)

# Backend Set Configuration:
# - Health Check: HTTP GET /health
# - Port: 3000
# - Policy: Round Robin

# Listener Configuration:
# - Protocol: HTTPS
# - Port: 443
# - SSL Certificate: Upload or use Let's Encrypt
```

### Where TLS Lives (Important!)

```
Option 1: TLS at Load Balancer (Recommended)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    HTTPS    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    HTTP     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚    LB    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚  Server  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   (443)     â”‚(SSL term)â”‚   (3000)    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Pros: Simpler server config, centralized cert management
Cons: Traffic unencrypted inside VPC (usually OK)

Option 2: TLS End-to-End
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    HTTPS    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   HTTPS    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚    LB    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚  Server  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   (443)     â”‚(passthru)â”‚   (443)    â”‚ (has SSL)â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Pros: Encrypted everywhere
Cons: More complex, cert management on each server

Option 3: TLS Re-encryption
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    HTTPS    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   HTTPS    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚    LB    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚  Server  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   (443)     â”‚(decrypt/ â”‚   (443)    â”‚ (has SSL)â”‚
                         â”‚ encrypt) â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Pros: Can inspect traffic + encrypted backend
Cons: Most complex, higher CPU usage
```

## 26.5 Secrets Management

### Why Not Hardcode Credentials?

```bash
# âŒ NEVER DO THIS:
DATABASE_URL="postgresql://admin:SuperSecret123@db.example.com/prod"

# Problems:
# 1. Credentials in git history FOREVER
# 2. Anyone with code access has DB access
# 3. Can't rotate without code changes
# 4. No audit trail of who accessed what
```

### Secrets Management Solutions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Solution            â”‚ Best For                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Environment Vars    â”‚ Simple apps, single server (basic)           â”‚
â”‚ HashiCorp Vault     â”‚ Enterprise, multi-cloud, advanced features   â”‚
â”‚ AWS Secrets Manager â”‚ AWS-native applications                      â”‚
â”‚ GCP Secret Manager  â”‚ GCP-native applications                      â”‚
â”‚ OCI Vault           â”‚ OCI-native applications                      â”‚
â”‚ Kubernetes Secrets  â”‚ K8s workloads (with encryption at rest)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Basic Secrets Management (Environment Variables)

```bash
# Store secrets in .env file (NOT in git!)
# .env
DATABASE_URL=postgresql://user:pass@localhost/db
REDIS_URL=redis://:password@localhost:6379
API_KEY=sk-xxxxxxxxxxxx

# .gitignore
.env
*.pem
*.key

# Load in application
require('dotenv').config();
const dbUrl = process.env.DATABASE_URL;

# Secure the .env file
chmod 600 .env
```

### OCI Vault Setup

```bash
# 1. Create Vault
# OCI Console â†’ Identity & Security â†’ Vault â†’ Create Vault

# 2. Create Master Encryption Key
# Inside Vault â†’ Master Encryption Keys â†’ Create Key

# 3. Create Secret
# Vault â†’ Secrets â†’ Create Secret
# - Name: database-password
# - Encryption Key: Your key
# - Secret Contents: your_actual_password

# 4. Access from application
# Install OCI SDK
pip install oci

# Python example:
import oci
import base64

config = oci.config.from_file()
secrets_client = oci.secrets.SecretsClient(config)

secret_bundle = secrets_client.get_secret_bundle(
    secret_id="ocid1.vaultsecret.oc1..."
)

secret_content = base64.b64decode(
    secret_bundle.data.secret_bundle_content.content
).decode('utf-8')
```

### Secret Rotation Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SECRET ROTATION PROCESS                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  1. Create new secret version                                    â”‚
â”‚     â””â”€â†’ New password generated                                   â”‚
â”‚                                                                  â”‚
â”‚  2. Update service with new credential                           â”‚
â”‚     â””â”€â†’ Database user password changed                           â”‚
â”‚                                                                  â”‚
â”‚  3. Update applications to use new version                       â”‚
â”‚     â””â”€â†’ Apps fetch new secret, reconnect                        â”‚
â”‚                                                                  â”‚
â”‚  4. Verify old secret no longer works                            â”‚
â”‚     â””â”€â†’ Test that old password fails                            â”‚
â”‚                                                                  â”‚
â”‚  5. Mark old version as deprecated                               â”‚
â”‚     â””â”€â†’ Audit log shows rotation completed                      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 26.6 FinOps - Cloud Cost Management

### Why FinOps Matters

```
Common Cloud Cost Disasters:
â”œâ”€â”€ "Free tier" VM accidentally upgraded â†’ $500/month
â”œâ”€â”€ Forgot to delete test resources â†’ $200/month
â”œâ”€â”€ Log storage growing unbounded â†’ $100/month
â”œâ”€â”€ Unused load balancers running â†’ $50/month
â””â”€â”€ Total surprise bill: $850/month ğŸ˜±
```

### Cost Monitoring Setup

```bash
# OCI Budget Setup
# OCI Console â†’ Billing & Cost Management â†’ Budgets â†’ Create Budget

# Example Budget:
# - Amount: $50/month
# - Alert at: 50%, 80%, 100%
# - Email: your-email@example.com

# Cost Analysis
# Billing â†’ Cost Analysis
# - Filter by: Compartment, Service, Tag
# - Group by: Service, Resource
# - Time: Last 30 days
```

### Cost Optimization Checklist

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WEEKLY COST REVIEW                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â–¡ Check for unused resources                                    â”‚
â”‚    â””â”€ VMs not receiving traffic                                  â”‚
â”‚    â””â”€ Unattached block volumes                                   â”‚
â”‚    â””â”€ Old snapshots and backups                                  â”‚
â”‚                                                                  â”‚
â”‚  â–¡ Right-size resources                                          â”‚
â”‚    â””â”€ VM using 10% CPU? â†’ Downgrade                             â”‚
â”‚    â””â”€ Database oversized? â†’ Reduce                              â”‚
â”‚                                                                  â”‚
â”‚  â–¡ Check for cost anomalies                                      â”‚
â”‚    â””â”€ Sudden spikes in any service                              â”‚
â”‚    â””â”€ Unexpected new resources                                   â”‚
â”‚                                                                  â”‚
â”‚  â–¡ Review reserved capacity                                      â”‚
â”‚    â””â”€ Committed use discounts available?                        â”‚
â”‚    â””â”€ Spot/preemptible instances for dev?                       â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Free Tier Maximization (OCI)

```bash
# Always Free Resources (Oracle Cloud):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Resource                    â”‚ Free Allowance                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ AMD Compute                 â”‚ 2 VMs (1/8 OCPU, 1GB RAM each)    â”‚
â”‚ ARM Compute (Ampere)        â”‚ 4 OCPUs, 24GB RAM total           â”‚
â”‚ Block Volume                â”‚ 200 GB total                       â”‚
â”‚ Object Storage              â”‚ 20 GB                              â”‚
â”‚ Outbound Data               â”‚ 10 TB/month                        â”‚
â”‚ Load Balancer               â”‚ 1 (10 Mbps)                        â”‚
â”‚ Autonomous Database         â”‚ 2 instances                        â”‚
â”‚ Monitoring                  â”‚ 500 million ingestion datapoints   â”‚
â”‚ Notifications               â”‚ 1 million sent                     â”‚
â”‚ Vault                       â”‚ 20 key versions                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Tips to stay in free tier:
# 1. Use ARM (Ampere) instances - more free resources
# 2. Stay in your home region
# 3. Don't upgrade to paid shapes
# 4. Monitor usage in Cost Analysis
# 5. Set budget alerts at $0.01
```

---

# Chapter 27: Kubernetes Fundamentals

> *"Declare what you want, let Kubernetes figure out how"*

## 27.1 What is Kubernetes?

```
Traditional Deployment:                    Kubernetes:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ You manage:             â”‚               â”‚ You declare:                    â”‚
â”‚ - Which server runs whatâ”‚               â”‚ - "I want 3 copies of my app"   â”‚
â”‚ - Restart on crash      â”‚               â”‚ - "Each needs 512MB RAM"        â”‚
â”‚ - Load balancing        â”‚               â”‚ - "Expose on port 80"           â”‚
â”‚ - Scaling up/down       â”‚               â”‚                                 â”‚
â”‚ - Health monitoring     â”‚               â”‚ Kubernetes handles:             â”‚
â”‚ - Rolling updates       â”‚               â”‚ - Placement on servers          â”‚
â”‚                         â”‚               â”‚ - Auto-restart on crash         â”‚
â”‚ Manual work 24/7        â”‚               â”‚ - Load balancing                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚ - Scaling                       â”‚
                                          â”‚ - Health checks                 â”‚
                                          â”‚ - Rolling updates               â”‚
                                          â”‚                                 â”‚
                                          â”‚ Automated 24/7                  â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 27.2 Kubernetes Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         KUBERNETES CLUSTER                               â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      CONTROL PLANE                               â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚   â”‚
â”‚  â”‚  â”‚ API Server   â”‚  â”‚  Scheduler   â”‚  â”‚ Controller   â”‚          â”‚   â”‚
â”‚  â”‚  â”‚              â”‚  â”‚              â”‚  â”‚  Manager     â”‚          â”‚   â”‚
â”‚  â”‚  â”‚ (Entry point â”‚  â”‚ (Decides     â”‚  â”‚ (Ensures     â”‚          â”‚   â”‚
â”‚  â”‚  â”‚  for all     â”‚  â”‚  where pods  â”‚  â”‚  desired     â”‚          â”‚   â”‚
â”‚  â”‚  â”‚  commands)   â”‚  â”‚  run)        â”‚  â”‚  state)      â”‚          â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚   â”‚
â”‚  â”‚  â”‚    etcd      â”‚  (Cluster state database)                     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                       WORKER NODES                               â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚
â”‚  â”‚  â”‚      Node 1         â”‚        â”‚      Node 2         â”‚        â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”   â”‚        â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”   â”‚        â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ Pod â”‚ â”‚ Pod â”‚   â”‚        â”‚  â”‚ Pod â”‚ â”‚ Pod â”‚   â”‚        â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ App â”‚ â”‚ App â”‚   â”‚        â”‚  â”‚ App â”‚ â”‚Redisâ”‚   â”‚        â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜   â”‚        â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜   â”‚        â”‚   â”‚
â”‚  â”‚  â”‚                     â”‚        â”‚                     â”‚        â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚        â”‚   â”‚
â”‚  â”‚  â”‚  â”‚   kubelet    â”‚  â”‚        â”‚  â”‚   kubelet    â”‚  â”‚        â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ (Node agent) â”‚  â”‚        â”‚  â”‚ (Node agent) â”‚  â”‚        â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚        â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 27.3 When to Use Kubernetes

```
âœ… USE KUBERNETES WHEN:
â”œâ”€â”€ Multiple services/microservices
â”œâ”€â”€ Need auto-scaling based on load
â”œâ”€â”€ Want self-healing (auto-restart crashed pods)
â”œâ”€â”€ Require rolling deployments with zero downtime
â”œâ”€â”€ Team needs standardized deployment process
â”œâ”€â”€ Running in multiple environments (dev/staging/prod)
â””â”€â”€ High availability is critical

âŒ DON'T USE KUBERNETES WHEN:
â”œâ”€â”€ Single application + single database
â”œâ”€â”€ Small team (1-3 developers)
â”œâ”€â”€ Simple deployment needs
â”œâ”€â”€ Limited budget (K8s has overhead)
â”œâ”€â”€ Learning curve would slow you down
â””â”€â”€ VM + PM2 + Nginx is working fine

Your Current Stack (VM + PM2):
â”œâ”€â”€ Simpler to understand
â”œâ”€â”€ Cheaper to run
â”œâ”€â”€ Faster to troubleshoot
â”œâ”€â”€ Perfect for: MVP, small-medium apps, learning
â””â”€â”€ Upgrade to K8s when you NEED it, not because it's trendy
```

## 27.4 Core Kubernetes Objects

### Pod (Smallest Deployable Unit)

```yaml
# pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-app
  labels:
    app: my-app
spec:
  containers:
    - name: my-app
      image: node:20-alpine
      ports:
        - containerPort: 3000
      resources:
        requests:
          memory: "128Mi"
          cpu: "100m"
        limits:
          memory: "256Mi"
          cpu: "500m"
```

```bash
# Pod is usually NOT created directly
# Instead, use Deployment (manages Pods)

# But for learning:
kubectl apply -f pod.yaml
kubectl get pods
kubectl describe pod my-app
kubectl logs my-app
kubectl delete pod my-app
```

### Deployment (Manages Replicas)

```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 3                    # Run 3 copies
  selector:
    matchLabels:
      app: my-app
  template:                      # Pod template
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app
          image: myregistry/my-app:v1.0.0
          ports:
            - containerPort: 3000
          resources:
            requests:
              memory: "128Mi"
              cpu: "100m"
            limits:
              memory: "256Mi"
              cpu: "500m"
          # Health checks
          livenessProbe:
            httpGet:
              path: /health
              port: 3000
            initialDelaySeconds: 10
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /health
              port: 3000
            initialDelaySeconds: 5
            periodSeconds: 5
          # Environment variables
          env:
            - name: NODE_ENV
              value: "production"
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: app-secrets
                  key: database-url
```

```bash
# Apply deployment
kubectl apply -f deployment.yaml

# Check status
kubectl get deployments
kubectl get pods
kubectl describe deployment my-app

# Scale
kubectl scale deployment my-app --replicas=5

# Update image (triggers rolling update)
kubectl set image deployment/my-app my-app=myregistry/my-app:v1.1.0

# Rollback
kubectl rollout undo deployment/my-app
kubectl rollout history deployment/my-app
```

### Service (Network Access to Pods)

```yaml
# service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app-service
spec:
  selector:
    app: my-app              # Match pods with this label
  ports:
    - protocol: TCP
      port: 80               # Service port
      targetPort: 3000       # Pod port
  type: ClusterIP            # Internal only (default)
---
# For external access:
apiVersion: v1
kind: Service
metadata:
  name: my-app-external
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 3000
  type: LoadBalancer         # Creates cloud load balancer
```

```
Service Types:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Type            â”‚ Use Case                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ClusterIP       â”‚ Internal communication between services            â”‚
â”‚ NodePort        â”‚ Expose on each node's IP at a static port          â”‚
â”‚ LoadBalancer    â”‚ Expose via cloud provider's load balancer          â”‚
â”‚ ExternalName    â”‚ Map service to external DNS name                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ingress (HTTP Routing)

```yaml
# ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
    - hosts:
        - myapp.example.com
      secretName: myapp-tls
  rules:
    - host: myapp.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: my-app-service
                port:
                  number: 80
          - path: /api
            pathType: Prefix
            backend:
              service:
                name: api-service
                port:
                  number: 80
```

### ConfigMap & Secret

```yaml
# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  LOG_LEVEL: "info"
  MAX_CONNECTIONS: "100"
  config.json: |
    {
      "feature_flags": {
        "new_ui": true
      }
    }
---
# secret.yaml (values are base64 encoded)
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
type: Opaque
data:
  database-url: cG9zdGdyZXNxbDovL3VzZXI6cGFzc0Bob3N0L2Ri  # base64 encoded
  api-key: c2stc2VjcmV0a2V5MTIz
```

```bash
# Create secret from command line
kubectl create secret generic app-secrets \
  --from-literal=database-url='postgresql://user:pass@host/db' \
  --from-literal=api-key='sk-secretkey123'

# View secrets (encoded)
kubectl get secret app-secrets -o yaml

# Decode secret
kubectl get secret app-secrets -o jsonpath='{.data.database-url}' | base64 -d
```

## 27.5 Essential kubectl Commands

```bash
# Cluster info
kubectl cluster-info
kubectl get nodes

# Namespaces (isolation)
kubectl get namespaces
kubectl create namespace production
kubectl config set-context --current --namespace=production

# Deployments
kubectl get deployments
kubectl describe deployment my-app
kubectl rollout status deployment/my-app
kubectl rollout restart deployment/my-app

# Pods
kubectl get pods
kubectl get pods -o wide                    # More details
kubectl describe pod my-app-xxxxx
kubectl logs my-app-xxxxx
kubectl logs my-app-xxxxx -f                # Follow
kubectl logs my-app-xxxxx --previous        # Previous container
kubectl exec -it my-app-xxxxx -- /bin/sh    # Shell into pod

# Services
kubectl get services
kubectl describe service my-app-service

# Apply/Delete
kubectl apply -f manifest.yaml
kubectl delete -f manifest.yaml
kubectl delete pod my-app-xxxxx

# Debugging
kubectl get events
kubectl top pods                            # Resource usage
kubectl top nodes
```

## 27.6 Resource Management

```yaml
# resources in deployment
resources:
  requests:                    # Minimum guaranteed
    memory: "128Mi"           # 128 Megabytes
    cpu: "100m"               # 100 millicores (0.1 CPU)
  limits:                      # Maximum allowed
    memory: "256Mi"
    cpu: "500m"               # 500 millicores (0.5 CPU)
```

```
CPU Units:
â”œâ”€â”€ 1 = 1 full CPU core
â”œâ”€â”€ 500m = 0.5 CPU (half core)
â”œâ”€â”€ 100m = 0.1 CPU (10% of a core)
â””â”€â”€ 1000m = 1 CPU

Memory Units:
â”œâ”€â”€ Ki = Kibibyte (1024 bytes)
â”œâ”€â”€ Mi = Mebibyte (1024 Ki)
â”œâ”€â”€ Gi = Gibibyte (1024 Mi)
â””â”€â”€ Plain numbers = bytes
```

## 27.7 Health Probes

```yaml
# Three types of probes:

# 1. Liveness Probe - Is the container alive?
#    Fails â†’ Container is restarted
livenessProbe:
  httpGet:
    path: /health
    port: 3000
  initialDelaySeconds: 10
  periodSeconds: 10
  failureThreshold: 3

# 2. Readiness Probe - Is the container ready for traffic?
#    Fails â†’ Removed from Service endpoints (no traffic)
readinessProbe:
  httpGet:
    path: /ready
    port: 3000
  initialDelaySeconds: 5
  periodSeconds: 5

# 3. Startup Probe - For slow-starting containers
#    Fails â†’ Container is restarted (after startupProbe succeeds, liveness takes over)
startupProbe:
  httpGet:
    path: /health
    port: 3000
  failureThreshold: 30
  periodSeconds: 10
```

---

# Chapter 28: Lightweight Kubernetes with K3s

> *"Full Kubernetes on a single VM - perfect for learning"*

## 28.1 What is K3s?

```
K3s vs Full Kubernetes:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Full Kubernetes                               â”‚
â”‚  - Multiple components                                          â”‚
â”‚  - 4GB+ RAM recommended                                         â”‚
â”‚  - Complex installation                                         â”‚
â”‚  - Production-grade                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         K3s                                      â”‚
â”‚  - Single binary (~100MB)                                       â”‚
â”‚  - 512MB RAM minimum                                            â”‚
â”‚  - 1 command installation                                       â”‚
â”‚  - Fully certified Kubernetes                                   â”‚
â”‚  - Perfect for: Edge, IoT, CI/CD, Learning                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 28.2 Install K3s on Oracle Cloud VM

```bash
# SSH into your Oracle Cloud VM
ssh oracle

# Install K3s (single command!)
curl -sfL https://get.k3s.io | sh -

# Wait for installation (about 30 seconds)
# Check status
sudo systemctl status k3s

# Verify cluster is running
sudo kubectl get nodes
# Output: NAME         STATUS   ROLES                  AGE   VERSION
#         my-server    Ready    control-plane,master   1m    v1.28.x+k3s1

# Make kubectl work without sudo
mkdir -p ~/.kube
sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
sudo chown $(id -u):$(id -g) ~/.kube/config
export KUBECONFIG=~/.kube/config

# Add to .bashrc for persistence
echo 'export KUBECONFIG=~/.kube/config' >> ~/.bashrc

# Now kubectl works without sudo
kubectl get nodes
```

## 28.3 Deploy Your First Application on K3s

### Step 1: Create Deployment

```yaml
# Create file: my-app-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
  labels:
    app: my-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app
          image: nginx:alpine    # Using nginx for demo
          ports:
            - containerPort: 80
          resources:
            requests:
              memory: "64Mi"
              cpu: "50m"
            limits:
              memory: "128Mi"
              cpu: "100m"
```

```bash
kubectl apply -f my-app-deployment.yaml
kubectl get pods
# Output shows 2 pods running
```

### Step 2: Create Service

```yaml
# Create file: my-app-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: ClusterIP
```

```bash
kubectl apply -f my-app-service.yaml
kubectl get services
```

### Step 3: Create Ingress (External Access)

```yaml
# Create file: my-app-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-app-ingress
  annotations:
    kubernetes.io/ingress.class: traefik    # K3s uses Traefik by default
spec:
  rules:
    - host: myapp.example.com    # Replace with your domain
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: my-app-service
                port:
                  number: 80
```

```bash
kubectl apply -f my-app-ingress.yaml
kubectl get ingress

# For testing without domain, use the server's public IP directly:
curl http://YOUR_SERVER_IP
```

## 28.4 Deploy Node.js App on K3s

### Step 1: Dockerize Your App

```dockerfile
# Dockerfile
FROM node:20-alpine

WORKDIR /app

COPY package*.json ./
RUN npm ci --production

COPY . .

EXPOSE 3000

USER node

CMD ["node", "app.js"]
```

### Step 2: Build and Push to Registry

```bash
# Option 1: Docker Hub (free)
docker build -t yourusername/my-app:v1.0.0 .
docker push yourusername/my-app:v1.0.0

# Option 2: GitHub Container Registry (free)
docker build -t ghcr.io/yourusername/my-app:v1.0.0 .
docker push ghcr.io/yourusername/my-app:v1.0.0
```

### Step 3: Deploy to K3s

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-node-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: my-node-app
  template:
    metadata:
      labels:
        app: my-node-app
    spec:
      containers:
        - name: my-node-app
          image: yourusername/my-app:v1.0.0
          ports:
            - containerPort: 3000
          env:
            - name: NODE_ENV
              value: "production"
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: app-secrets
                  key: database-url
          resources:
            requests:
              memory: "128Mi"
              cpu: "100m"
            limits:
              memory: "256Mi"
              cpu: "200m"
          livenessProbe:
            httpGet:
              path: /health
              port: 3000
            initialDelaySeconds: 10
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /health
              port: 3000
            initialDelaySeconds: 5
            periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: my-node-app
spec:
  selector:
    app: my-node-app
  ports:
    - port: 80
      targetPort: 3000
  type: ClusterIP
```

```bash
# Create secret first
kubectl create secret generic app-secrets \
  --from-literal=database-url='postgresql://user:pass@localhost:5432/db'

# Deploy
kubectl apply -f k8s/deployment.yaml

# Check status
kubectl get pods
kubectl logs -f deployment/my-node-app
```

## 28.5 K3s with PostgreSQL

```yaml
# postgres.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres
spec:
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
        - name: postgres
          image: postgres:15
          ports:
            - containerPort: 5432
          env:
            - name: POSTGRES_USER
              value: "myapp"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: password
            - name: POSTGRES_DB
              value: "myapp"
          volumeMounts:
            - name: postgres-storage
              mountPath: /var/lib/postgresql/data
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "500m"
      volumes:
        - name: postgres-storage
          persistentVolumeClaim:
            claimName: postgres-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: postgres
spec:
  selector:
    app: postgres
  ports:
    - port: 5432
      targetPort: 5432
  type: ClusterIP
```

```bash
# Create secret
kubectl create secret generic postgres-secret \
  --from-literal=password='your-secure-password'

# Deploy
kubectl apply -f postgres.yaml

# Connect to postgres
kubectl exec -it deployment/postgres -- psql -U myapp -d myapp
```

## 28.6 K3s Useful Commands

```bash
# Check K3s status
sudo systemctl status k3s

# View K3s logs
sudo journalctl -u k3s -f

# Restart K3s
sudo systemctl restart k3s

# Uninstall K3s
/usr/local/bin/k3s-uninstall.sh

# Check resource usage
kubectl top nodes
kubectl top pods

# View all resources
kubectl get all
kubectl get all -A    # All namespaces
```

---

# Chapter 29: Managed Kubernetes (GKE & OKE)

> *"When you need production-grade Kubernetes without managing the control plane"*

## 29.1 Managed vs Self-Managed Kubernetes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SELF-MANAGED (K3s)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ You manage:                                                            â”‚
â”‚ â”œâ”€â”€ Control plane (API server, scheduler, etc.)                        â”‚
â”‚ â”œâ”€â”€ Worker nodes                                                       â”‚
â”‚ â”œâ”€â”€ Networking (CNI)                                                   â”‚
â”‚ â”œâ”€â”€ Storage                                                            â”‚
â”‚ â”œâ”€â”€ Upgrades                                                           â”‚
â”‚ â””â”€â”€ High availability                                                  â”‚
â”‚                                                                        â”‚
â”‚ âœ… Pros: Full control, cheaper, learn deeply                           â”‚
â”‚ âŒ Cons: More work, single point of failure, upgrade complexity        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MANAGED (GKE/OKE/EKS)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Cloud manages:                                                         â”‚
â”‚ â”œâ”€â”€ Control plane (automatic HA, upgrades)                             â”‚
â”‚ â”œâ”€â”€ API server availability                                            â”‚
â”‚ â””â”€â”€ etcd backups                                                       â”‚
â”‚                                                                        â”‚
â”‚ You manage:                                                            â”‚
â”‚ â”œâ”€â”€ Worker nodes (or use node pools)                                   â”‚
â”‚ â”œâ”€â”€ Applications                                                       â”‚
â”‚ â””â”€â”€ Ingress/networking config                                          â”‚
â”‚                                                                        â”‚
â”‚ âœ… Pros: Less ops work, built-in HA, easy upgrades                     â”‚
â”‚ âŒ Cons: Costs money, less control, vendor lock-in                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 29.2 GKE (Google Kubernetes Engine)

### GKE Pricing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GKE PRICING                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Autopilot Mode:                                                 â”‚
â”‚ â”œâ”€â”€ $0.10 per vCPU per hour                                    â”‚
â”‚ â”œâ”€â”€ $0.01 per GB memory per hour                               â”‚
â”‚ â””â”€â”€ Pay only for pods, not nodes                               â”‚
â”‚                                                                  â”‚
â”‚ Standard Mode:                                                   â”‚
â”‚ â”œâ”€â”€ $0.10/hour cluster management fee                          â”‚
â”‚ â”œâ”€â”€ + Node costs (VM pricing)                                  â”‚
â”‚ â””â”€â”€ FREE for 1 zonal cluster (first cluster free!)             â”‚
â”‚                                                                  â”‚
â”‚ Free Tier:                                                       â”‚
â”‚ â”œâ”€â”€ 1 zonal cluster free (no management fee)                   â”‚
â”‚ â”œâ”€â”€ $300 credit for new accounts (90 days)                     â”‚
â”‚ â””â”€â”€ Pay only for worker node VMs                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Create GKE Cluster

```bash
# Install gcloud CLI first
# https://cloud.google.com/sdk/docs/install

# Login
gcloud auth login

# Set project
gcloud config set project YOUR_PROJECT_ID

# Create cluster (Standard mode - 1 free zonal cluster)
gcloud container clusters create my-cluster \
  --zone us-central1-a \
  --num-nodes 2 \
  --machine-type e2-small \
  --disk-size 20GB

# Get credentials (configures kubectl)
gcloud container clusters get-credentials my-cluster --zone us-central1-a

# Verify
kubectl get nodes
```

### GKE Autopilot (Serverless Kubernetes)

```bash
# Create Autopilot cluster (pay per pod, not per node)
gcloud container clusters create-auto my-autopilot-cluster \
  --region us-central1

# No need to manage nodes!
# Just deploy your workloads
kubectl apply -f deployment.yaml
```

## 29.3 OKE (Oracle Kubernetes Engine)

### OKE Pricing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OKE PRICING                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Control Plane:                                                   â”‚
â”‚ â””â”€â”€ FREE (no cluster management fee!)                           â”‚
â”‚                                                                  â”‚
â”‚ Worker Nodes:                                                    â”‚
â”‚ â”œâ”€â”€ Pay for compute instances                                   â”‚
â”‚ â”œâ”€â”€ Can use Always Free ARM instances                           â”‚
â”‚ â””â”€â”€ ~$0.01/hour for basic shapes                               â”‚
â”‚                                                                  â”‚
â”‚ Free Tier Option:                                                â”‚
â”‚ â”œâ”€â”€ Use Always Free compute for worker nodes                   â”‚
â”‚ â”œâ”€â”€ Up to 4 ARM OCPUs + 24GB RAM                               â”‚
â”‚ â””â”€â”€ OKE control plane is always free                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Create OKE Cluster via Console

```bash
# OCI Console â†’ Developer Services â†’ Kubernetes Clusters (OKE)
# â†’ Create Cluster â†’ Quick Create

# Configuration:
# - Name: my-cluster
# - Kubernetes Version: Latest stable
# - Shape: VM.Standard.A1.Flex (ARM - Always Free eligible)
# - OCPUs: 2 per node
# - Memory: 12GB per node
# - Node Count: 2

# After creation, download kubeconfig:
# Cluster Details â†’ Access Cluster â†’ Local Access
# Follow the oci commands shown
```

### Create OKE Cluster via CLI

```bash
# Install OCI CLI
# https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/cliinstall.htm

# Create cluster
oci ce cluster create \
  --compartment-id $COMPARTMENT_ID \
  --name my-cluster \
  --kubernetes-version v1.28.2 \
  --vcn-id $VCN_ID \
  --service-lb-subnet-ids '["'$SUBNET_ID'"]'

# Create node pool
oci ce node-pool create \
  --cluster-id $CLUSTER_ID \
  --compartment-id $COMPARTMENT_ID \
  --name my-node-pool \
  --kubernetes-version v1.28.2 \
  --node-shape VM.Standard.A1.Flex \
  --node-shape-config '{"ocpus": 2, "memoryInGBs": 12}' \
  --size 2

# Get kubeconfig
oci ce cluster create-kubeconfig \
  --cluster-id $CLUSTER_ID \
  --file ~/.kube/config \
  --token-version 2.0.0

# Verify
kubectl get nodes
```

## 29.4 When to Use Which

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Use Case        â”‚ Recommendation                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Learning K8s    â”‚ K3s on Oracle Cloud VM (free)                  â”‚
â”‚ Small projects  â”‚ K3s or single-node cluster                     â”‚
â”‚ Cost-sensitive  â”‚ OKE (free control plane + Always Free nodes)   â”‚
â”‚ GCP ecosystem   â”‚ GKE (great integration, 1 free cluster)        â”‚
â”‚ AWS ecosystem   â”‚ EKS (but $0.10/hr per cluster)                 â”‚
â”‚ Production      â”‚ Managed K8s (GKE/OKE/EKS)                      â”‚
â”‚ Multi-cloud     â”‚ GKE or any managed (easier migration)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 29.5 Recommended Learning Path

```
Stage 1: Learn Kubernetes concepts (FREE)
â””â”€â”€ K3s on Oracle Cloud VM
    â””â”€â”€ Deploy apps, services, ingress
    â””â”€â”€ Learn kubectl commands
    â””â”€â”€ Understand core objects

Stage 2: Experience managed Kubernetes ($5-20/month)
â””â”€â”€ GKE with 1 free zonal cluster
    â””â”€â”€ Or OKE with Always Free nodes
    â””â”€â”€ Learn cloud integration (load balancers, storage)
    â””â”€â”€ Practice upgrades, scaling

Stage 3: Production patterns
â””â”€â”€ Multi-zone/region clusters
â””â”€â”€ GitOps with ArgoCD
â””â”€â”€ Monitoring with Prometheus/Grafana
â””â”€â”€ Service mesh (if needed)
```

---

# Chapter 30: Production Reliability & SRE

> *"Moving from 'logs exist' to 'we can operate confidently'"*

## 30.1 What is SRE?

```
Site Reliability Engineering (SRE):
â”œâ”€â”€ Apply software engineering to operations problems
â”œâ”€â”€ Balance reliability with velocity
â”œâ”€â”€ Use data to make decisions
â””â”€â”€ Automate toil (repetitive manual work)

Core Principles:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Define reliability targets (SLOs)                            â”‚
â”‚ 2. Measure what matters (SLIs)                                  â”‚
â”‚ 3. Create error budgets (room for failures)                     â”‚
â”‚ 4. Reduce toil through automation                               â”‚
â”‚ 5. Learn from incidents (postmortems)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 30.2 SLI/SLO/SLA Framework

### Definitions

```
SLI (Service Level Indicator):
â”œâ”€â”€ A metric that measures service behavior
â”œâ”€â”€ Example: "99.5% of requests complete in < 200ms"
â””â”€â”€ The actual measurement

SLO (Service Level Objective):
â”œâ”€â”€ Target value for an SLI
â”œâ”€â”€ Example: "99.9% availability"
â”œâ”€â”€ Internal goal
â””â”€â”€ Drives engineering decisions

SLA (Service Level Agreement):
â”œâ”€â”€ Contract with customers
â”œâ”€â”€ Example: "99.5% uptime or refund"
â”œâ”€â”€ Has financial/legal consequences
â””â”€â”€ Usually less strict than SLO

Relationship:
SLI (what you measure) â†’ SLO (your target) â†’ SLA (your promise)
```

### Common SLIs

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AVAILABILITY SLI                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Formula: (Successful requests / Total requests) Ã— 100           â”‚
â”‚                                                                  â”‚
â”‚ Example SLO: 99.9% availability                                 â”‚
â”‚                                                                  â”‚
â”‚ What 99.9% means (per month):                                   â”‚
â”‚ â”œâ”€â”€ 99.9% = 43 minutes downtime allowed                        â”‚
â”‚ â”œâ”€â”€ 99.99% = 4.3 minutes downtime allowed                      â”‚
â”‚ â””â”€â”€ 99.999% = 26 seconds downtime allowed                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LATENCY SLI                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Formula: Percentage of requests faster than threshold           â”‚
â”‚                                                                  â”‚
â”‚ Example SLOs:                                                    â”‚
â”‚ â”œâ”€â”€ p50 (median): 50% of requests < 100ms                      â”‚
â”‚ â”œâ”€â”€ p90: 90% of requests < 200ms                               â”‚
â”‚ â”œâ”€â”€ p99: 99% of requests < 500ms                               â”‚
â”‚ â””â”€â”€ p99.9: 99.9% of requests < 1000ms                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ERROR RATE SLI                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Formula: (Error responses / Total responses) Ã— 100              â”‚
â”‚                                                                  â”‚
â”‚ Example SLO: Error rate < 0.1%                                  â”‚
â”‚                                                                  â”‚
â”‚ Count as errors:                                                 â”‚
â”‚ â”œâ”€â”€ HTTP 5xx responses                                          â”‚
â”‚ â”œâ”€â”€ Timeouts                                                    â”‚
â”‚ â””â”€â”€ Failed health checks                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Error Budget

```
Error Budget = 100% - SLO

Example:
â”œâ”€â”€ SLO: 99.9% availability
â”œâ”€â”€ Error Budget: 0.1% (100% - 99.9%)
â”œâ”€â”€ Per month: 43 minutes of allowed downtime
â””â”€â”€ Use it for: Deployments, experiments, maintenance

How to use Error Budget:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Error Budget Status       â”‚ Action                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Budget remaining > 50%    â”‚ Ship features, take risks           â”‚
â”‚ Budget remaining 20-50%   â”‚ Normal operations, be careful       â”‚
â”‚ Budget remaining < 20%    â”‚ Focus on reliability, slow down     â”‚
â”‚ Budget exhausted          â”‚ Stop all non-critical changes       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementing SLOs in Code

```javascript
// Health check endpoint with SLI tracking
const prometheus = require('prom-client');

// Create metrics
const httpRequestDuration = new prometheus.Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  labelNames: ['method', 'route', 'status_code'],
  buckets: [0.1, 0.2, 0.5, 1, 2, 5]
});

const httpRequestTotal = new prometheus.Counter({
  name: 'http_requests_total',
  help: 'Total number of HTTP requests',
  labelNames: ['method', 'route', 'status_code']
});

// Middleware to track metrics
app.use((req, res, next) => {
  const start = Date.now();
  
  res.on('finish', () => {
    const duration = (Date.now() - start) / 1000;
    const labels = {
      method: req.method,
      route: req.route?.path || req.path,
      status_code: res.statusCode
    };
    
    httpRequestDuration.observe(labels, duration);
    httpRequestTotal.inc(labels);
  });
  
  next();
});

// Metrics endpoint for Prometheus
app.get('/metrics', async (req, res) => {
  res.set('Content-Type', prometheus.register.contentType);
  res.end(await prometheus.register.metrics());
});
```

## 30.3 Incident Response

### Severity Levels

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Severity â”‚ Definition                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SEV-1    â”‚ Complete outage, all users affected                    â”‚
â”‚ (P1)     â”‚ Response: Immediate, all hands                         â”‚
â”‚          â”‚ Example: Site down, data loss                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SEV-2    â”‚ Major feature broken, many users affected              â”‚
â”‚ (P2)     â”‚ Response: Within 1 hour, on-call + backup              â”‚
â”‚          â”‚ Example: Payments failing, login broken                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SEV-3    â”‚ Minor feature broken, some users affected              â”‚
â”‚ (P3)     â”‚ Response: Within 4 hours, on-call                      â”‚
â”‚          â”‚ Example: Search slow, minor UI bug                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SEV-4    â”‚ Minimal impact, workaround available                   â”‚
â”‚ (P4)     â”‚ Response: Next business day                            â”‚
â”‚          â”‚ Example: Cosmetic issue, edge case                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Incident Response Runbook Template

```markdown
# [SERVICE NAME] Incident Runbook

## Quick Reference
- On-call: Check PagerDuty rotation
- Escalation: #incidents Slack channel
- Status Page: status.example.com

## Symptoms & Quick Fixes

### Site Not Loading (SEV-1)
**Check:**
1. `kubectl get pods -n production` - All pods running?
2. `kubectl logs -n production deployment/app --tail=100`
3. Check load balancer health in cloud console

**Quick Fixes:**
1. Restart pods: `kubectl rollout restart deployment/app -n production`
2. Rollback: `kubectl rollout undo deployment/app -n production`
3. Scale up: `kubectl scale deployment/app --replicas=5 -n production`

### High Error Rate (SEV-2)
**Check:**
1. Grafana dashboard: https://grafana.example.com/d/app-overview
2. Recent deployments: `kubectl rollout history deployment/app`
3. Database connections: Check RDS console

**Quick Fixes:**
1. If after deploy: Rollback immediately
2. If DB issue: Check connection pool, restart app
3. If external API: Enable circuit breaker

### High Latency (SEV-3)
**Check:**
1. Database slow query log
2. Redis memory usage
3. CPU/Memory of pods: `kubectl top pods`

**Quick Fixes:**
1. Scale up replicas
2. Clear Redis cache (if safe)
3. Enable query result caching

## Communication Templates

### Initial Communication (within 10 minutes)
> We are investigating reports of [ISSUE]. 
> Current impact: [DESCRIPTION]
> Next update in 15 minutes.

### During Incident
> Update: We have identified the cause as [CAUSE].
> We are working on [ACTION].
> ETA to resolution: [TIME]

### Resolution
> Resolved: [ISSUE] has been fixed.
> Root cause: [CAUSE]
> Duration: [TIME]
> Postmortem will be shared within 48 hours.
```

## 30.4 Postmortem Process

### Postmortem Template

```markdown
# Postmortem: [Incident Title]

**Date:** 2024-01-15
**Authors:** [Names]
**Status:** Complete

## Summary
On January 15, 2024, from 14:00 to 14:45 UTC, the payment service 
was unavailable for 45 minutes, affecting approximately 5,000 users 
attempting to make purchases.

## Impact
- Duration: 45 minutes
- Users affected: ~5,000
- Revenue impact: ~$15,000 in failed transactions
- Error budget consumed: 75% of monthly budget

## Timeline (UTC)
| Time  | Event |
|-------|-------|
| 13:45 | Deploy v2.3.1 to production |
| 14:00 | Alerts fire: Payment error rate > 5% |
| 14:05 | On-call acknowledges, begins investigation |
| 14:15 | Root cause identified: DB connection leak |
| 14:20 | Decision made to rollback |
| 14:25 | Rollback initiated |
| 14:35 | Rollback complete, monitoring |
| 14:45 | All metrics normal, incident resolved |

## Root Cause
The v2.3.1 release introduced a database connection leak in the 
payment validation module. Under load, connections were exhausted 
within 15 minutes, causing all subsequent requests to fail.

## Contributing Factors
1. Code review didn't catch the connection leak
2. Load testing in staging used lower traffic than production
3. Connection pool alerts were set too high (90% vs recommended 70%)

## What Went Well
- Alerts fired quickly (within 5 minutes)
- Rollback procedure worked smoothly
- Team communication was clear

## What Went Wrong
- Took 15 minutes to identify root cause
- No automated rollback on error rate spike
- Load testing didn't match production patterns

## Action Items
| Action | Owner | Due Date | Status |
|--------|-------|----------|--------|
| Add connection pool monitoring | @alice | 2024-01-22 | TODO |
| Lower connection pool alert to 70% | @bob | 2024-01-18 | TODO |
| Add DB connection lint rule | @carol | 2024-01-29 | TODO |
| Update load test to match prod | @dave | 2024-02-01 | TODO |
| Implement auto-rollback on error spike | @alice | 2024-02-15 | TODO |

## Lessons Learned
1. Connection management requires explicit testing
2. Staging environment should mirror production load patterns
3. Consider automatic rollback for critical services
```

### Postmortem Best Practices

```
BLAMELESS POSTMORTEM CULTURE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ DON'T:                                                       â”‚
â”‚ â”œâ”€â”€ "John caused the outage"                                    â”‚
â”‚ â”œâ”€â”€ "If Sarah had just..."                                      â”‚
â”‚ â””â”€â”€ "This was a human error"                                    â”‚
â”‚                                                                  â”‚
â”‚ âœ… DO:                                                          â”‚
â”‚ â”œâ”€â”€ "The deploy process allowed this change"                    â”‚
â”‚ â”œâ”€â”€ "Our testing didn't catch this pattern"                     â”‚
â”‚ â””â”€â”€ "The system permitted this failure mode"                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

WHY BLAMELESS?
â”œâ”€â”€ People hide problems if they fear punishment
â”œâ”€â”€ The goal is to improve systems, not punish people
â”œâ”€â”€ Humans will always make mistakes; systems should prevent impact
â””â”€â”€ Psychological safety enables honest analysis
```

## 30.5 Observability Stack

### The Three Pillars

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OBSERVABILITY                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     METRICS     â”‚      LOGS       â”‚          TRACES             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Numbers over    â”‚ Event records   â”‚ Request flow across         â”‚
â”‚ time            â”‚ with context    â”‚ services                    â”‚
â”‚                 â”‚                 â”‚                             â”‚
â”‚ "What is        â”‚ "What          â”‚ "How did this request       â”‚
â”‚ happening?"     â”‚ happened?"      â”‚ flow through the system?"   â”‚
â”‚                 â”‚                 â”‚                             â”‚
â”‚ CPU: 80%        â”‚ Error: DB       â”‚ User â†’ API â†’ DB â†’ Cache    â”‚
â”‚ Requests: 1000  â”‚ connection      â”‚     50ms  30ms  5ms         â”‚
â”‚ Errors: 5       â”‚ failed at 14:23 â”‚                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Prometheus      â”‚ Loki            â”‚ Jaeger                      â”‚
â”‚ Grafana         â”‚ ELK Stack       â”‚ Zipkin                      â”‚
â”‚                 â”‚ CloudWatch      â”‚ Tempo                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Basic Monitoring Setup (Prometheus + Grafana)

```yaml
# docker-compose.monitoring.yaml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana:latest
    volumes:
      - grafana-data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
      - "3001:3000"
    depends_on:
      - prometheus

volumes:
  prometheus-data:
  grafana-data:
```

```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'node-app'
    static_configs:
      - targets: ['host.docker.internal:3000']
    metrics_path: '/metrics'

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
```

## 30.6 Load Testing

### Why Load Test?

```
"Hope is not a strategy"

Know your limits BEFORE users find them:
â”œâ”€â”€ Maximum requests per second
â”œâ”€â”€ Breaking point (when errors start)
â”œâ”€â”€ Degradation curve (how performance drops under load)
â””â”€â”€ Recovery behavior (how system recovers)
```

### Basic Load Testing with k6

```bash
# Install k6
sudo apt install k6
# Or: brew install k6

# Create test script
cat > load-test.js << 'EOF'
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
  stages: [
    { duration: '1m', target: 50 },   // Ramp up to 50 users
    { duration: '3m', target: 50 },   // Stay at 50 users
    { duration: '1m', target: 100 },  // Ramp up to 100 users
    { duration: '3m', target: 100 },  // Stay at 100 users
    { duration: '1m', target: 0 },    // Ramp down
  ],
  thresholds: {
    http_req_duration: ['p(95)<500'],  // 95% of requests < 500ms
    http_req_failed: ['rate<0.01'],    // Error rate < 1%
  },
};

export default function () {
  let response = http.get('https://api.example.com/health');
  
  check(response, {
    'status is 200': (r) => r.status === 200,
    'response time < 200ms': (r) => r.timings.duration < 200,
  });
  
  sleep(1);
}
EOF

# Run test
k6 run load-test.js

# Run with more options
k6 run --vus 100 --duration 5m load-test.js
```

### Capacity Planning

```
Based on load test results:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric              â”‚ Current â”‚ At Load â”‚ Limit    â”‚ Action     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CPU Usage           â”‚ 30%     â”‚ 80%     â”‚ 90%      â”‚ Scale at 70%
â”‚ Memory Usage        â”‚ 2GB     â”‚ 3.5GB   â”‚ 4GB      â”‚ Scale at 3GB
â”‚ Response Time (p95) â”‚ 100ms   â”‚ 400ms   â”‚ 500ms    â”‚ Alert at 300ms
â”‚ Error Rate          â”‚ 0.01%   â”‚ 0.5%    â”‚ 1%       â”‚ Alert at 0.5%
â”‚ Requests/sec        â”‚ 100     â”‚ 800     â”‚ 1000     â”‚ Scale at 700
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Capacity Plan:
â”œâ”€â”€ Current: 2 pods handle 200 req/s normally
â”œâ”€â”€ Growth: Expecting 2x traffic in 6 months
â”œâ”€â”€ Plan: Auto-scale to 4 pods at 70% CPU
â””â”€â”€ Budget: Approved for up to 6 pods
```

---

# Chapter 31: Advanced Security Hardening

> *"Security is a process, not a product"*

## 31.1 Security Maturity Levels

```
Level 1: Basics (You've done this!)
â”œâ”€â”€ SSH key auth, disable password
â”œâ”€â”€ Firewall (UFW)
â”œâ”€â”€ fail2ban
â”œâ”€â”€ TLS/HTTPS
â””â”€â”€ Basic user permissions

Level 2: Intermediate (This chapter)
â”œâ”€â”€ Patch management & vulnerability scanning
â”œâ”€â”€ Secrets rotation & audit trails
â”œâ”€â”€ WAF & DDoS protection
â”œâ”€â”€ Container image scanning
â””â”€â”€ Network segmentation

Level 3: Advanced
â”œâ”€â”€ Zero-trust architecture
â”œâ”€â”€ Security Information & Event Management (SIEM)
â”œâ”€â”€ Penetration testing
â”œâ”€â”€ Compliance frameworks (SOC2, HIPAA)
â””â”€â”€ Bug bounty programs
```

## 31.2 Patch Management

### Automated Security Updates

```bash
# Ubuntu: Enable automatic security updates
sudo apt install unattended-upgrades -y

# Configure
sudo dpkg-reconfigure -plow unattended-upgrades

# Verify configuration
cat /etc/apt/apt.conf.d/20auto-upgrades
# APT::Periodic::Update-Package-Lists "1";
# APT::Periodic::Unattended-Upgrade "1";

# Check what will be upgraded
sudo unattended-upgrade --dry-run --debug

# View upgrade log
cat /var/log/unattended-upgrades/unattended-upgrades.log
```

### Patch Management Policy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PATCH PRIORITY MATRIX                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Severity            â”‚ Timeline                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Critical (CVE 9.0+) â”‚ Within 24 hours                          â”‚
â”‚ High (CVE 7.0-8.9)  â”‚ Within 7 days                            â”‚
â”‚ Medium (CVE 4.0-6.9)â”‚ Within 30 days                           â”‚
â”‚ Low (CVE 0.1-3.9)   â”‚ Next maintenance window                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Monthly Patch Checklist:
â–¡ Check for OS updates
â–¡ Update runtime (Node.js, Python)
â–¡ Update dependencies (npm audit, pip-audit)
â–¡ Update container base images
â–¡ Review CVE databases for used software
â–¡ Test patches in staging before production
```

## 31.3 Vulnerability Scanning

### OS-Level Scanning

```bash
# Install Lynis (security auditing tool)
sudo apt install lynis -y

# Run audit
sudo lynis audit system

# View report
sudo cat /var/log/lynis-report.dat

# Key sections to review:
# - [WARNING] items
# - Hardening index score
# - Suggestions for improvement
```

### Dependency Scanning

```bash
# Node.js - npm audit
npm audit
npm audit fix
npm audit --production    # Only production dependencies

# Python - pip-audit
pip install pip-audit
pip-audit

# Python - Safety
pip install safety
safety check

# Automated in CI/CD:
# .github/workflows/security.yml
name: Security Scan
on:
  push:
    branches: [main]
  schedule:
    - cron: '0 0 * * *'  # Daily

jobs:
  audit:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm audit --audit-level=high
```

### Container Image Scanning

```bash
# Trivy - comprehensive vulnerability scanner
# Install
curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin

# Scan local image
trivy image myapp:latest

# Scan before push in CI
trivy image --exit-code 1 --severity HIGH,CRITICAL myapp:latest

# Scan filesystem
trivy fs /path/to/project

# Example output:
# myapp:latest (ubuntu 22.04)
# Total: 15 (HIGH: 3, CRITICAL: 1)
# 
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ Library         â”‚ Vulnerability   â”‚ Severity â”‚ Fixed Version                   â”‚
# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
# â”‚ openssl         â”‚ CVE-2023-XXXXX  â”‚ CRITICAL â”‚ 1.1.1n-0ubuntu0.22.04.1         â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 31.4 Secrets Rotation & Audit

### Rotation Schedule

```bash
# Create rotation tracking
cat > /etc/secrets-rotation.yaml << 'EOF'
secrets:
  database:
    type: postgresql
    rotation_days: 90
    last_rotated: 2024-01-01
    next_rotation: 2024-04-01
    
  redis:
    type: redis
    rotation_days: 90
    last_rotated: 2024-01-01
    next_rotation: 2024-04-01
    
  api_keys:
    type: api_key
    rotation_days: 30
    last_rotated: 2024-01-15
    next_rotation: 2024-02-15
    
  ssh_keys:
    type: ssh
    rotation_days: 90
    last_rotated: 2024-01-01
    next_rotation: 2024-04-01
EOF
```

### Rotation Checklist

```bash
# Database Password Rotation
# 1. Generate new password
NEW_PASS=$(openssl rand -base64 32)

# 2. Update in PostgreSQL
sudo -u postgres psql -c "ALTER USER myapp PASSWORD '$NEW_PASS';"

# 3. Update in secrets manager / .env
# 4. Restart application
pm2 restart myapp

# 5. Verify connection
curl -f http://localhost:3000/health

# 6. Update rotation tracking
```

### Audit Logging

```bash
# Enable PostgreSQL audit logging
# postgresql.conf
log_statement = 'all'
log_connections = on
log_disconnections = on

# Application audit logging
// middleware/audit.js
const auditLog = (action, userId, resource, details) => {
  console.log(JSON.stringify({
    timestamp: new Date().toISOString(),
    action,
    userId,
    resource,
    details,
    ip: req.ip,
    userAgent: req.headers['user-agent']
  }));
};

// Usage
app.post('/api/secrets/:id', (req, res) => {
  auditLog('SECRET_ACCESS', req.user.id, req.params.id, {
    method: 'read'
  });
  // ... handle request
});
```

## 31.5 WAF & DDoS Protection

### Cloudflare Setup (Free Tier)

```bash
# Cloudflare provides free:
# - DDoS protection
# - Basic WAF rules
# - SSL/TLS
# - CDN

Setup Steps:
1. Sign up at cloudflare.com
2. Add your domain
3. Update nameservers at your registrar
4. Enable "Under Attack Mode" if needed

# Recommended free settings:
# - SSL/TLS: Full (strict)
# - Always Use HTTPS: On
# - Auto Minify: On
# - Brotli: On
# - Security Level: Medium
# - Challenge Passage: 30 minutes
```

### Rate Limiting at Nginx Level

```nginx
# /etc/nginx/nginx.conf

http {
    # Define rate limit zones
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=login:10m rate=1r/s;
    limit_conn_zone $binary_remote_addr zone=conn:10m;
    
    server {
        # General API rate limit
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            limit_conn conn 10;
            proxy_pass http://backend;
        }
        
        # Strict rate limit for auth endpoints
        location /api/auth/ {
            limit_req zone=login burst=5 nodelay;
            proxy_pass http://backend;
        }
        
        # Block common attack patterns
        location ~* (\.php|\.asp|\.aspx|\.jsp|\.cgi)$ {
            return 404;
        }
        
        # Block SQL injection attempts
        location ~* "(\'|\"|\;|\-\-|\|)" {
            return 403;
        }
    }
}
```

### Application-Level Rate Limiting

```javascript
// Using express-rate-limit
const rateLimit = require('express-rate-limit');

// General API rate limit
const apiLimiter = rateLimit({
  windowMs: 15 * 60 * 1000,  // 15 minutes
  max: 100,                   // 100 requests per window
  message: { error: 'Too many requests, please try again later.' }
});

// Strict limit for auth endpoints
const authLimiter = rateLimit({
  windowMs: 60 * 60 * 1000,  // 1 hour
  max: 5,                     // 5 attempts per hour
  message: { error: 'Too many login attempts, please try again later.' }
});

app.use('/api/', apiLimiter);
app.use('/api/auth/', authLimiter);
```

## 31.6 Supply Chain Security

### Dependency Security

```bash
# 1. Lock dependency versions
# package-lock.json (npm) - always commit this
# requirements.txt with pinned versions (pip)

# 2. Use npm ci instead of npm install in CI/CD
npm ci --production

# 3. Check for known vulnerabilities
npm audit --audit-level=moderate

# 4. Use Dependabot or Renovate for updates
# .github/dependabot.yml
version: 2
updates:
  - package-ecosystem: "npm"
    directory: "/"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 10
```

### Container Security Best Practices

```dockerfile
# Dockerfile with security best practices

# 1. Use specific version, not 'latest'
FROM node:20.10-alpine

# 2. Run as non-root user
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001

# 3. Set ownership before switching user
WORKDIR /app
COPY --chown=nodejs:nodejs package*.json ./

# 4. Install dependencies
RUN npm ci --production

# 5. Copy application code
COPY --chown=nodejs:nodejs . .

# 6. Switch to non-root user
USER nodejs

# 7. Don't run as PID 1 (use tini or dumb-init)
# Or use Node.js directly with proper signal handling

EXPOSE 3000
CMD ["node", "app.js"]
```

## 31.7 Security Checklist

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SECURITY AUDIT CHECKLIST                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚ NETWORK & ACCESS                                                 â”‚
â”‚ â–¡ SSH: Key-only auth, no root login, non-standard port          â”‚
â”‚ â–¡ Firewall: Default deny, only required ports open              â”‚
â”‚ â–¡ fail2ban: Configured and running                              â”‚
â”‚ â–¡ TLS: Valid certificates, TLS 1.2+ only                        â”‚
â”‚ â–¡ VPN/Bastion: For internal service access                      â”‚
â”‚                                                                  â”‚
â”‚ APPLICATION                                                      â”‚
â”‚ â–¡ Dependencies: No high/critical vulnerabilities                â”‚
â”‚ â–¡ Secrets: Not in code, rotated regularly                       â”‚
â”‚ â–¡ Input validation: All user input sanitized                    â”‚
â”‚ â–¡ Rate limiting: Implemented at multiple levels                 â”‚
â”‚ â–¡ Security headers: X-Frame-Options, CSP, etc.                  â”‚
â”‚                                                                  â”‚
â”‚ DATA                                                            â”‚
â”‚ â–¡ Encryption at rest: Database, backups                         â”‚
â”‚ â–¡ Encryption in transit: TLS everywhere                         â”‚
â”‚ â–¡ Backups: Tested restore procedure                             â”‚
â”‚ â–¡ Access logging: Who accessed what, when                       â”‚
â”‚                                                                  â”‚
â”‚ OPERATIONS                                                       â”‚
â”‚ â–¡ Patch management: Automated or scheduled                      â”‚
â”‚ â–¡ Monitoring: Alerts for security events                        â”‚
â”‚ â–¡ Incident response: Documented runbook                         â”‚
â”‚ â–¡ Audit logs: Retained and reviewed                             â”‚
â”‚                                                                  â”‚
â”‚ CONTAINERS (if applicable)                                       â”‚
â”‚ â–¡ Base images: From trusted sources, scanned                    â”‚
â”‚ â–¡ Non-root: Containers run as non-root                          â”‚
â”‚ â–¡ Read-only: Filesystem where possible                          â”‚
â”‚ â–¡ Resource limits: CPU/memory limits set                        â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Quick Reference: Advanced Topics

## Command Cheatsheet

```bash
# Kubernetes (kubectl)
kubectl get all                    # All resources
kubectl logs -f deployment/app     # Follow logs
kubectl exec -it pod/app -- sh     # Shell into pod
kubectl rollout undo deployment/app # Rollback

# K3s
curl -sfL https://get.k3s.io | sh -  # Install
sudo kubectl get nodes               # Check status
/usr/local/bin/k3s-uninstall.sh     # Uninstall

# Security Scanning
lynis audit system                 # OS audit
npm audit                          # Node.js deps
trivy image myapp:latest           # Container scan

# Load Testing
k6 run load-test.js               # Run load test
```

## File Locations

```
Kubernetes:
~/.kube/config                    # Kubeconfig
/etc/rancher/k3s/k3s.yaml        # K3s config

Security:
/var/log/auth.log                # Auth logs
/var/log/fail2ban.log            # fail2ban logs
/var/log/lynis-report.dat        # Security audit

Monitoring:
/var/log/prometheus/             # Prometheus logs
/var/lib/grafana/                # Grafana data
```

---

# Learning Path Summary

```
CURRENT LEVEL: VM + PM2 + Nginx (Solid Foundation!)
     â”‚
     â–¼
NEXT STEPS:
     â”‚
     â”œâ”€â†’ Chapter 26: Cloud Fundamentals (IAM, VPC, Secrets)
     â”‚   â””â”€â†’ Practice: Setup proper OCI networking
     â”‚
     â”œâ”€â†’ Chapter 27-28: Kubernetes with K3s
     â”‚   â””â”€â†’ Practice: Deploy app on K3s (your Oracle VM)
     â”‚
     â”œâ”€â†’ Chapter 30: SRE Basics (SLIs, SLOs, Incidents)
     â”‚   â””â”€â†’ Practice: Define SLOs for your app
     â”‚
     â””â”€â†’ Chapter 31: Advanced Security
         â””â”€â†’ Practice: Run security audit with Lynis
```

---

**Continue building your skills! ğŸš€**

The best path: Master your current VM setup â†’ Learn K3s on same VM â†’ Then graduate to managed Kubernetes when you NEED it.
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  PHASE 1: FOUNDATION (Chapters 1-14)                    [4-6 weeks]     â”‚
â”‚  â”œâ”€â”€ Linux, SSH, Networking                                             â”‚
â”‚  â”œâ”€â”€ Nginx, PM2, Databases, Redis                                       â”‚
â”‚  â”œâ”€â”€ Deployment, SSL, Monitoring, Backups                               â”‚
â”‚  â””â”€â”€ âœ… OUTCOME: Deploy single-server production app                    â”‚
â”‚                                                                         â”‚
â”‚  PHASE 2: AUTOMATION (Chapters 15-25)                   [4-6 weeks]     â”‚
â”‚  â”œâ”€â”€ Performance, Cloud (OCI), Ansible                                  â”‚
â”‚  â”œâ”€â”€ CI/CD, Docker, Free Cloud Options                                  â”‚
â”‚  â””â”€â”€ âœ… OUTCOME: Automated deployments with containers                  â”‚
â”‚                                                                         â”‚
â”‚  PHASE 3: CLOUD MATURITY (Chapters 26-31)               [4-6 weeks]     â”‚
â”‚  â”œâ”€â”€ IAM, VPC, Secrets, FinOps basics                                   â”‚
â”‚  â”œâ”€â”€ Kubernetes (K3s), Managed K8s                                      â”‚
â”‚  â”œâ”€â”€ SRE basics, Advanced Security                                      â”‚
â”‚  â””â”€â”€ âœ… OUTCOME: Cloud-native deployments with K8s                      â”‚
â”‚                                                                         â”‚
â”‚  PHASE 4: PLATFORM MATURITY (Chapters 32-39)            [6-8 weeks]     â”‚
â”‚  â”œâ”€â”€ Terraform IaC                                                      â”‚
â”‚  â”œâ”€â”€ GitOps (ArgoCD)                                                    â”‚
â”‚  â”œâ”€â”€ Observability (Prometheus, Grafana, Loki, Jaeger)                  â”‚
â”‚  â”œâ”€â”€ SRE in Practice (Error Budgets, Incidents)                         â”‚
â”‚  â”œâ”€â”€ Container Security (Scanning, Signing, Policies)                   â”‚
â”‚  â”œâ”€â”€ K8s Real Ops (Helm, cert-manager, HPA)                             â”‚
â”‚  â”œâ”€â”€ Multi-Region & DR                                                  â”‚
â”‚  â”œâ”€â”€ FinOps                                                             â”‚
â”‚  â””â”€â”€ âœ… OUTCOME: Production-grade platform operations                   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Reference: All Chapters

| Ch | Title | Key Skills |
|----|-------|------------|
| 1-4 | Fundamentals | Linux, SSH, Networking |
| 5-7 | Infrastructure | Firewall, Nginx, PM2 |
| 8-9 | Data | PostgreSQL, Redis |
| 10-14 | Deployment | SSL, Monitoring, Backups, Security |
| 15-19 | Advanced | Performance, Docker, CI/CD |
| 20-25 | Professional | Projects, Free Cloud, Walkthroughs |
| 26 | Cloud Fundamentals | IAM, VPC, Secrets, FinOps |
| 27-29 | Kubernetes | K8s, K3s, GKE/OKE |
| 30-31 | SRE & Security | SLI/SLO, Hardening |
| 32 | Terraform | IaC, State, Modules |
| 33 | GitOps | ArgoCD, Kustomize |
| 34 | Observability | Prometheus, Grafana, Loki, Jaeger |
| 35 | SRE Practice | Error Budgets, Incidents, On-call |
| 36 | Container Security | SBOM, Signing, Kyverno |
| 37 | K8s Real Ops | Helm, cert-manager, HPA, Upgrades |
| 38 | Multi-Region | DR, Traffic Shifting, RPO/RTO |
| 39 | FinOps | Budgets, Tagging, Cost Optimization |

---

## Final Production-Ready Checklist

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PRODUCTION-READY PLATFORM CHECKLIST                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚ INFRASTRUCTURE                                                          â”‚
â”‚ â–¡ Infrastructure defined in Terraform                                   â”‚
â”‚ â–¡ State stored remotely with locking                                    â”‚
â”‚ â–¡ Environments separated (dev/staging/prod)                             â”‚
â”‚ â–¡ Network segmentation (VPC, subnets)                                   â”‚
â”‚ â–¡ IAM follows least privilege                                           â”‚
â”‚                                                                         â”‚
â”‚ DEPLOYMENT                                                              â”‚
â”‚ â–¡ GitOps workflow with ArgoCD                                           â”‚
â”‚ â–¡ Helm charts for all applications                                      â”‚
â”‚ â–¡ Automated image builds in CI                                          â”‚
â”‚ â–¡ Image scanning before deployment                                      â”‚
â”‚ â–¡ Signed images required for production                                 â”‚
â”‚                                                                         â”‚
â”‚ RELIABILITY                                                             â”‚
â”‚ â–¡ SLOs defined for all services                                         â”‚
â”‚ â–¡ Error budgets tracked                                                 â”‚
â”‚ â–¡ On-call rotation established                                          â”‚
â”‚ â–¡ Incident runbooks documented                                          â”‚
â”‚ â–¡ Postmortem process in place                                           â”‚
â”‚                                                                         â”‚
â”‚ OBSERVABILITY                                                           â”‚
â”‚ â–¡ Metrics (Prometheus), Logs (Loki), Traces (Jaeger)                    â”‚
â”‚ â–¡ Dashboards for all services                                           â”‚
â”‚ â–¡ Alerts routed appropriately                                           â”‚
â”‚                                                                         â”‚
â”‚ SECURITY                                                                â”‚
â”‚ â–¡ TLS everywhere, Secrets in vault                                      â”‚
â”‚ â–¡ Network policies enforced                                             â”‚
â”‚ â–¡ Regular vulnerability scanning                                        â”‚
â”‚                                                                         â”‚
â”‚ DISASTER RECOVERY                                                       â”‚
â”‚ â–¡ Backups automated and tested                                          â”‚
â”‚ â–¡ DR region configured, RPO/RTO defined                                 â”‚
â”‚ â–¡ DR drills scheduled                                                   â”‚
â”‚                                                                         â”‚
â”‚ FINOPS                                                                  â”‚
â”‚ â–¡ All resources tagged                                                  â”‚
â”‚ â–¡ Budgets with alerts                                                   â”‚
â”‚ â–¡ Weekly cost review                                                    â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Congratulations!** ğŸ‰

You now have a complete curriculum from Linux basics to production-grade platform operations.

**Total: 39 Chapters covering everything from `ls` to SRE practices!**


---

# Chapter 32: Terraform Infrastructure as Code

> *"Infrastructure should be version-controlled, reviewable, and reproducible"*

## 32.1 Why Terraform?

```
Terraform vs Other Tools:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature         â”‚ Terraform       â”‚ Ansible         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Approach        â”‚ Declarative     â”‚ Procedural      â”‚
â”‚ State Mgmt      â”‚ Yes (critical)  â”‚ No              â”‚
â”‚ Multi-cloud     â”‚ Yes             â”‚ Yes             â”‚
â”‚ Drift Detection â”‚ Yes             â”‚ No              â”‚
â”‚ Best For        â”‚ Infrastructure  â”‚ Configuration   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 32.2 Core Concepts

```bash
# Install Terraform
wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg
echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
sudo apt update && sudo apt install terraform

# Workflow
terraform init      # Download providers
terraform plan      # Preview changes
terraform apply     # Create resources
terraform destroy   # Remove everything
```

## 32.3 Basic Configuration

```hcl
# main.tf
terraform {
  required_providers {
    oci = {
      source  = "oracle/oci"
      version = "~> 5.0"
    }
  }
}

provider "oci" {
  region = var.region
}

variable "region" {
  default = "us-ashburn-1"
}

variable "compartment_id" {
  type = string
}

resource "oci_core_vcn" "main" {
  compartment_id = var.compartment_id
  cidr_blocks    = ["10.0.0.0/16"]
  display_name   = "my-vcn"
}

output "vcn_id" {
  value = oci_core_vcn.main.id
}
```

## 32.4 State Management

```
âš ï¸ CRITICAL RULES:
â”œâ”€â”€ NEVER edit state manually
â”œâ”€â”€ NEVER commit state to git (contains secrets!)
â”œâ”€â”€ ALWAYS use remote backend for teams
â””â”€â”€ ALWAYS enable state locking
```

```hcl
# Remote backend (Terraform Cloud - free)
terraform {
  cloud {
    organization = "my-org"
    workspaces {
      name = "myapp-prod"
    }
  }
}
```

## 32.5 Modules

```hcl
# modules/network/main.tf
resource "oci_core_vcn" "main" {
  compartment_id = var.compartment_id
  cidr_blocks    = [var.vcn_cidr]
  display_name   = "vcn-${var.environment}"
}

# Using module
module "network" {
  source         = "./modules/network"
  compartment_id = var.compartment_id
  environment    = "prod"
  vcn_cidr       = "10.0.0.0/16"
}
```

## 32.6 Environment Management

```
terraform/
â”œâ”€â”€ modules/
â”‚   â””â”€â”€ network/
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â””â”€â”€ terraform.tfvars
â”‚   â”œâ”€â”€ staging/
â”‚   â””â”€â”€ prod/
```

## 32.7 Drift Detection

```bash
# Detect drift
terraform plan

# Automated drift check in CI
terraform plan -detailed-exitcode
# Exit code 2 = drift detected
```

## 32.8 Definition of Done

```
â–¡ Write HCL configurations
â–¡ Use remote backend for state
â–¡ Create reusable modules
â–¡ Manage multiple environments
â–¡ Run drift detection
â–¡ Use policy checks (Checkov)
```

---

# Chapter 33: GitOps with ArgoCD

> *"Git as the single source of truth"*

## 33.1 What is GitOps?

```
Traditional: Developer â†’ Build â†’ SSH â†’ Deploy (manual)
GitOps:      Developer â†’ Git â†’ ArgoCD â†’ Cluster (automated)

Principles:
1. Declarative: System described in Git
2. Versioned: All changes tracked
3. Automated: Auto-applied on merge
4. Continuously Reconciled: Actual = Desired
```

## 33.2 Install ArgoCD

```bash
# Install on K3s
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# Get admin password
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d

# Port forward
kubectl port-forward svc/argocd-server -n argocd 8080:443
```

## 33.3 Repository Structure

```
gitops-repo/
â”œâ”€â”€ apps/
â”‚   â””â”€â”€ myapp/
â”‚       â”œâ”€â”€ base/
â”‚       â”‚   â”œâ”€â”€ deployment.yaml
â”‚       â”‚   â”œâ”€â”€ service.yaml
â”‚       â”‚   â””â”€â”€ kustomization.yaml
â”‚       â””â”€â”€ overlays/
â”‚           â”œâ”€â”€ dev/
â”‚           â”œâ”€â”€ staging/
â”‚           â””â”€â”€ prod/
â””â”€â”€ clusters/
    â”œâ”€â”€ dev/
    â””â”€â”€ prod/
```

## 33.4 ArgoCD Application

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: myapp-prod
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/yourorg/gitops.git
    targetRevision: main
    path: apps/myapp/overlays/prod
  destination:
    server: https://kubernetes.default.svc
    namespace: myapp-prod
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
```

## 33.5 Kustomize Overlays

```yaml
# base/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - deployment.yaml
  - service.yaml

# overlays/prod/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: myapp-prod
resources:
  - ../../base
replicas:
  - name: myapp
    count: 3
images:
  - name: myregistry/myapp
    newTag: v1.2.3
```

## 33.6 Rollback

```bash
# Via ArgoCD
argocd app rollback myapp-prod

# Via Git (preferred)
git revert HEAD
git push
# ArgoCD auto-syncs
```

## 33.7 Definition of Done

```
â–¡ Install ArgoCD on K3s
â–¡ Create GitOps repository structure
â–¡ Use Kustomize for environments
â–¡ Set up auto-sync for dev
â–¡ Perform rollback via git
```

---

# Chapter 34: Production Observability

> *"You can't fix what you can't see"*

## 34.1 Three Pillars

```
METRICS          LOGS              TRACES
(Prometheus)     (Loki)            (Jaeger)
    â”‚                â”‚                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
               â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
               â”‚  GRAFANA  â”‚
               â”‚ Dashboard â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 34.2 Prometheus Setup

```yaml
# prometheus-config.yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
```

## 34.3 Application Metrics (Node.js)

```javascript
const prometheus = require('prom-client');
prometheus.collectDefaultMetrics();

const httpDuration = new prometheus.Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests',
  labelNames: ['method', 'route', 'status'],
  buckets: [0.1, 0.5, 1, 2, 5]
});

app.get('/metrics', async (req, res) => {
  res.set('Content-Type', prometheus.register.contentType);
  res.end(await prometheus.register.metrics());
});
```

## 34.4 Loki for Logs

```yaml
# Install Loki + Promtail for log aggregation
# Query in Grafana:
{app="myapp"} |= "error"
```

## 34.5 Alert Rules

```yaml
groups:
  - name: application
    rules:
      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) 
          / sum(rate(http_requests_total[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: Error rate above 5%
```

## 34.6 Definition of Done

```
â–¡ Deploy Prometheus + Grafana
â–¡ Add /metrics endpoint to app
â–¡ Set up Loki for logs
â–¡ Create dashboard for service
â–¡ Configure alerts
```

---

# Chapter 35: SRE in Practice

> *"Hope is not a strategy"*

## 35.1 Error Budgets

```
SLO: 99.9% availability
Error Budget: 0.1% = 43 minutes/month

Budget > 50%: Ship features freely
Budget 20-50%: Be careful
Budget < 20%: Focus on reliability
Budget exhausted: Feature freeze
```

## 35.2 Alert Hygiene

```
Good Alert:
â”œâ”€â”€ Actionable
â”œâ”€â”€ Urgent
â”œâ”€â”€ Indicates user impact
â””â”€â”€ Non-noisy

Bad Alert:
â”œâ”€â”€ "CPU high" (no context)
â”œâ”€â”€ Fires 10x/day (fatigue)
â””â”€â”€ No one knows what to do
```

## 35.3 Incident Roles

```
Incident Commander (IC)
â”œâ”€â”€ Tech Lead (investigation)
â”œâ”€â”€ Comms Lead (stakeholders)
â””â”€â”€ Scribe (documentation)
```

## 35.4 Severity Levels

```
SEV-1: Complete outage      â†’ Page immediately
SEV-2: Major feature broken â†’ Page within 1 hour
SEV-3: Minor issue          â†’ Next business day
```

## 35.5 Postmortem Template

```markdown
# Incident: [Title]

## Summary
[What happened, duration, impact]

## Timeline
- 14:00 - Alert fired
- 14:05 - Acknowledged
- 14:15 - Root cause found
- 14:20 - Fix deployed

## Root Cause
[Why it happened]

## Action Items
| Action | Owner | Due Date |
|--------|-------|----------|
```

## 35.6 Definition of Done

```
â–¡ Define SLOs for services
â–¡ Configure error budget tracking
â–¡ Set up on-call rotation
â–¡ Document escalation paths
â–¡ Run one postmortem
```

---

# Chapter 36: Container Security

> *"Secure from code to production"*

## 36.1 Image Scanning

```bash
# Install Trivy
curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin

# Scan image
trivy image myapp:latest

# Fail on HIGH/CRITICAL
trivy image --exit-code 1 --severity HIGH,CRITICAL myapp:latest
```

## 36.2 SBOM Generation

```bash
# Install Syft
curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin

# Generate SBOM
syft myapp:latest -o spdx-json > sbom.json
```

## 36.3 Image Signing

```bash
# Install Cosign
curl -sSfL https://github.com/sigstore/cosign/releases/latest/download/cosign-linux-amd64 -o /usr/local/bin/cosign

# Sign image (keyless with GitHub Actions)
cosign sign myregistry/myapp:v1.0.0

# Verify
cosign verify myregistry/myapp:v1.0.0
```

## 36.4 Secure Pod Configuration

```yaml
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
  containers:
    - name: app
      securityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
        capabilities:
          drop: ["ALL"]
```

## 36.5 Kyverno Policies

```yaml
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: require-non-root
spec:
  validationFailureAction: Enforce
  rules:
    - name: check-non-root
      match:
        resources:
          kinds: [Pod]
      validate:
        message: "Containers must run as non-root"
        pattern:
          spec:
            containers:
              - securityContext:
                  runAsNonRoot: true
```

## 36.6 Definition of Done

```
â–¡ Scan images in CI/CD
â–¡ Generate SBOMs
â–¡ Sign production images
â–¡ Enforce non-root containers
â–¡ Deploy Kyverno policies
```

---

# Chapter 37: Kubernetes Real Operations

> *"Beyond kubectl apply"*

## 37.1 Helm

```bash
# Install Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# Create chart
helm create myapp

# Install
helm install myapp ./myapp -f values-prod.yaml

# Upgrade
helm upgrade myapp ./myapp --set image.tag=v2.0.0

# Rollback
helm rollback myapp 1
```

## 37.2 Cert-Manager

```bash
# Install
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.0/cert-manager.yaml
```

```yaml
# ClusterIssuer for Let's Encrypt
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: admin@example.com
    privateKeySecretRef:
      name: letsencrypt-prod-key
    solvers:
      - http01:
          ingress:
            class: traefik
```

## 37.3 Network Policies

```yaml
# Default deny all
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny
spec:
  podSelector: {}
  policyTypes: [Ingress, Egress]
```

## 37.4 HPA (Horizontal Pod Autoscaler)

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
```

## 37.5 Cluster Upgrades

```bash
# K3s upgrade
curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION=v1.28.4+k3s1 sh -

# Verify
kubectl get nodes
```

## 37.6 Definition of Done

```
â–¡ Create Helm chart
â–¡ Set up cert-manager with Let's Encrypt
â–¡ Implement network policies
â–¡ Configure HPA
â–¡ Document upgrade procedure
```

---

# Chapter 38: Multi-Region & Disaster Recovery

> *"One cluster is none clusters"*

## 38.1 Architecture Patterns

```
Active-Passive (DR):
â”œâ”€â”€ Primary region: All traffic
â”œâ”€â”€ Secondary: Standby, replicated data
â””â”€â”€ Failover: Manual or automated

Active-Active:
â”œâ”€â”€ Both regions serve traffic
â”œâ”€â”€ Global load balancing
â””â”€â”€ Bi-directional replication
```

## 38.2 RPO/RTO

```
RPO (Recovery Point Objective):
â””â”€â”€ Max acceptable data loss
â””â”€â”€ "How old can backup be?"

RTO (Recovery Time Objective):
â””â”€â”€ Max acceptable downtime
â””â”€â”€ "How long until restored?"

Example:
â”œâ”€â”€ Tier 1 (Critical): RPO < 1hr, RTO < 15min
â”œâ”€â”€ Tier 2 (High):     RPO < 4hr, RTO < 1hr
â””â”€â”€ Tier 3 (Medium):   RPO < 24hr, RTO < 4hr
```

## 38.3 DR Drill Checklist

```markdown
## Pre-Drill
â–¡ Notify stakeholders
â–¡ Verify DR region ready
â–¡ Confirm monitoring in place

## Failover
â–¡ Scale up DR pods
â–¡ Promote DR database
â–¡ Update DNS
â–¡ Verify app responding

## Failback
â–¡ Sync data to primary
â–¡ Switch DNS back
â–¡ Demote DR database

## Post-Drill
â–¡ Document issues
â–¡ Update runbook
```

## 38.4 Traffic Shifting

```yaml
# Weighted routing for canary
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  name: myapp-weighted
spec:
  routes:
    - match: Host(`myapp.example.com`)
      services:
        - name: myapp-blue
          weight: 90
        - name: myapp-green
          weight: 10
```

## 38.5 Definition of Done

```
â–¡ Define RPO/RTO per service
â–¡ Set up DR region
â–¡ Document failover procedure
â–¡ Schedule quarterly DR drills
â–¡ Test traffic shifting
```

---

# Chapter 39: FinOps

> *"Cloud cost is everyone's responsibility"*

## 39.1 Tagging Strategy

```yaml
Required Tags:
  - Environment: dev/staging/prod
  - Team: platform/backend/frontend
  - Service: service name
  - CostCenter: CC-XXXX

Example:
freeform_tags = {
  Environment = "prod"
  Team        = "backend"
  Service     = "api-gateway"
  CostCenter  = "CC-1234"
}
```

## 39.2 Budget Alerts

```bash
# OCI Budget via CLI
oci budgets budget create \
  --compartment-id $COMPARTMENT_ID \
  --amount 100 \
  --reset-period MONTHLY \
  --display-name "Production Budget"

# Alert at 80%
oci budgets alert-rule create \
  --budget-id $BUDGET_ID \
  --threshold 80 \
  --threshold-type PERCENTAGE \
  --recipients "alerts@company.com"
```

## 39.3 Cost Anomaly Detection

```python
def detect_anomaly(daily_costs, threshold_std=2):
    historical = daily_costs[:-1][-30:]
    today = daily_costs[-1]
    
    mean = statistics.mean(historical)
    std = statistics.stdev(historical)
    z_score = (today - mean) / std
    
    return abs(z_score) > threshold_std
```

## 39.4 Free Tier Enforcement

```
OCI Always Free Limits:
â”œâ”€â”€ Ampere A1: 4 OCPU, 24GB RAM
â”œâ”€â”€ Block Volume: 200 GB total
â”œâ”€â”€ Object Storage: 20 GB
â””â”€â”€ Outbound: 10 TB/month

Enforcement:
â”œâ”€â”€ Daily automated checks
â”œâ”€â”€ Alert before exceeding
â””â”€â”€ Auto-scale down scripts
```

## 39.5 Weekly Review Template

```markdown
## Cost Summary
| Metric | This Week | Last Week | Change |
|--------|-----------|-----------|--------|
| Total  | $XXX      | $XXX      | +X%    |

## Top Cost Drivers
1. [Service] - $XX
2. [Service] - $XX

## Action Items
â–¡ Right-size [resource]
â–¡ Delete unused [resource]
```

## 39.6 Definition of Done

```
â–¡ Tag all resources
â–¡ Set up budget alerts
â–¡ Create cost dashboard
â–¡ Configure anomaly detection
â–¡ Schedule weekly reviews
```

---

# Complete Guide Summary

## All 39 Chapters

| Phase | Chapters | Focus |
|-------|----------|-------|
| **Foundation** | 1-14 | Linux, Deployment, Security |
| **Automation** | 15-25 | Docker, CI/CD, Free Cloud |
| **Cloud Maturity** | 26-31 | K8s, SRE, Advanced Security |
| **Platform Maturity** | 32-39 | Terraform, GitOps, Observability, FinOps |

## Learning Timeline

```
Weeks 1-6:   Foundation (Ch 1-14)
Weeks 7-12:  Automation (Ch 15-25)
Weeks 13-18: Cloud Maturity (Ch 26-31)
Weeks 19-26: Platform Maturity (Ch 32-39)
```

## Final Checklist

```
INFRASTRUCTURE
â–¡ Terraform for all resources
â–¡ Remote state with locking
â–¡ Environments separated

DEPLOYMENT
â–¡ GitOps with ArgoCD
â–¡ Helm charts for apps
â–¡ Image scanning + signing

RELIABILITY
â–¡ SLOs defined
â–¡ Error budgets tracked
â–¡ On-call rotation

OBSERVABILITY
â–¡ Metrics + Logs + Traces
â–¡ Dashboards per service
â–¡ Alert routing

SECURITY
â–¡ TLS everywhere
â–¡ Secrets in vault
â–¡ Runtime policies

DR & FINOPS
â–¡ Backups tested
â–¡ DR drills scheduled
â–¡ Budgets with alerts
```

---

**You now have everything from `ls` to production-grade platform operations!** ğŸš€

**Total: 39 Chapters | ~8,000+ lines | Complete DevOps Curriculum**


# ğŸš€ The ULTIMATE DevOps & System Architecture Guide
## Complete Encyclopedia - From Zero to Principal Engineer

**Version 2.0 - Complete Edition (75 Chapters)**
**~15,000+ Lines | Full Curriculum | 60-80 Weeks of Learning**

> Including everything from Linux basics to Distributed Systems, Service Mesh, Chaos Engineering, MLOps, and Platform Engineering

**Last Updated: January 2026**

---

# ğŸ“š COMPLETE TABLE OF CONTENTS

## PART 1: FOUNDATIONS (Chapters 1-14) - Beginner
1. Introduction & Prerequisites
2. Linux Fundamentals  
3. SSH Mastery
4. Networking Fundamentals
5. Firewall & Network Security
6. Web Servers (Nginx)
7. Process Management
8. Databases
9. Redis & Caching
10. Deployment Strategies
11. SSL/TLS & HTTPS
12. Monitoring & Logging
13. Backup & Disaster Recovery
14. Security Hardening

## PART 2: AUTOMATION & CONTAINERS (Chapters 15-25) - Intermediate
15. Performance Tuning
16. Cloud Infrastructure (OCI)
17. Infrastructure as Code (Ansible)
18. CI/CD Pipelines
19. Containers & Docker
20. Professional Practices
21. Capstone Projects
22. Free Cloud Deployment Options
23. Complete Deployment Walkthrough
24. Automated Deployment Scripts
25. Quick Reference

## PART 3: CLOUD MATURITY (Chapters 26-31) - Advanced
26. Cloud Provider Fundamentals (IAM, VPC, Secrets)
27. Kubernetes Fundamentals
28. Lightweight Kubernetes with K3s
29. Managed Kubernetes (GKE & OKE)
30. Production Reliability & SRE
31. Advanced Security Hardening

## PART 4: PLATFORM ENGINEERING (Chapters 32-39) - Senior
32. Terraform Infrastructure as Code
33. GitOps with ArgoCD
34. Production Observability
35. SRE in Practice
36. Container Security
37. Kubernetes Real Operations
38. Multi-Region & Disaster Recovery
39. FinOps

## PART 5: SERVICE MESH & NETWORKING (Chapters 40-44) - Senior â­NEW
40. Service Mesh Fundamentals
41. Istio Deep Dive
42. Advanced Networking (CNI, eBPF)
43. API Gateway & Management
44. Network Security & Zero Trust

## PART 6: MESSAGE QUEUES & EVENTS (Chapters 45-48) - Senior â­NEW
45. Message Queue Fundamentals
46. Apache Kafka
47. RabbitMQ & Other Queues
48. Event-Driven Architecture

## PART 7: SERVERLESS & EDGE (Chapters 49-51) - Senior â­NEW
49. Serverless Fundamentals
50. AWS Lambda & Cloud Functions
51. Edge Computing & CDN

## PART 8: CHAOS ENGINEERING (Chapters 52-55) - Expert â­NEW
52. Chaos Engineering Fundamentals
53. Chaos Tools (LitmusChaos, Gremlin)
54. Game Days & Disaster Simulation
55. Advanced SRE & Error Budgets

## PART 9: COMPLIANCE & GOVERNANCE (Chapters 56-58) - Expert â­NEW
56. Compliance Fundamentals (SOC2, HIPAA, PCI-DSS)
57. Policy as Code (OPA, Kyverno)
58. Audit & Governance

## PART 10: SYSTEM ARCHITECTURE (Chapters 59-68) - Architect â­NEW
59. System Design Fundamentals
60. Distributed Systems Concepts
61. Design Patterns (CQRS, Event Sourcing, Saga)
62. Scalability Patterns
63. Caching Strategies
64. Database Architecture & Sharding
65. API Design (REST, GraphQL, gRPC)
66. Data Architecture (Lakes, Warehouses, Mesh)
67. Capacity Planning & Performance Modeling
68. System Design Case Studies

## PART 11: ML/AI OPS (Chapters 69-71) - Expert â­NEW
69. MLOps Fundamentals
70. ML Platforms (Kubeflow, MLflow)
71. Model Serving & Feature Stores

## PART 12: PLATFORM ENGINEERING (Chapters 72-75) - Principal â­NEW
72. Platform Engineering Fundamentals
73. Internal Developer Platforms (Backstage)
74. Developer Experience (DX)
75. Platform as a Product

---

# ğŸ¯ CAREER PROGRESSION

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DEVOPS CAREER LADDER                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  JUNIOR (0-2 years)              Chapters 1-25                         â”‚
â”‚  â”œâ”€â”€ Salary: $50K-80K (US) | 80K-200K PKR/mo                          â”‚
â”‚  â”œâ”€â”€ Focus: Linux, Docker, CI/CD basics                               â”‚
â”‚  â””â”€â”€ Skills: SSH, Nginx, PM2, basic cloud                             â”‚
â”‚                                                                         â”‚
â”‚  MID-LEVEL (2-4 years)           Chapters 26-39                        â”‚
â”‚  â”œâ”€â”€ Salary: $80K-130K (US) | 200K-400K PKR/mo                        â”‚
â”‚  â”œâ”€â”€ Focus: Kubernetes, Terraform, GitOps                             â”‚
â”‚  â””â”€â”€ Skills: IaC, monitoring, SRE basics                              â”‚
â”‚                                                                         â”‚
â”‚  SENIOR (4-7 years)              Chapters 40-58                        â”‚
â”‚  â”œâ”€â”€ Salary: $130K-180K (US) | 400K-700K PKR/mo                       â”‚
â”‚  â”œâ”€â”€ Focus: Service Mesh, Kafka, Chaos Eng                            â”‚
â”‚  â””â”€â”€ Skills: System design, compliance                                 â”‚
â”‚                                                                         â”‚
â”‚  STAFF/ARCHITECT (7+ years)      Chapters 59-75                        â”‚
â”‚  â”œâ”€â”€ Salary: $180K-300K+ (US) | 700K-1.5M+ PKR/mo                     â”‚
â”‚  â”œâ”€â”€ Focus: System Architecture, Platform Eng                         â”‚
â”‚  â””â”€â”€ Skills: Distributed systems, MLOps                               â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# PART 1: FOUNDATIONS

---

## Chapter 1: Introduction & Prerequisites

### What is DevOps?

DevOps combines software development (Dev) and IT operations (Ops) to shorten the development lifecycle while delivering features frequently.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DEVOPS INFINITY LOOP                   â”‚
â”‚                                                          â”‚
â”‚     PLAN â†’ CODE â†’ BUILD â†’ TEST â†’ RELEASE â†’ DEPLOY       â”‚
â”‚       â†‘                                         â†“        â”‚
â”‚       â””â”€â”€â”€â”€ MONITOR â† OPERATE â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Role Comparison

| Role | Focus | Key Tools |
|------|-------|-----------|
| DevOps Engineer | CI/CD, Automation | Jenkins, Docker, Terraform |
| SRE | Reliability, SLOs | Prometheus, PagerDuty |
| Platform Engineer | Developer Experience | Backstage, Crossplane |
| System Architect | System Design | Whiteboards, Documentation |
| Cloud Architect | Cloud Strategy | Cloud consoles, Cost tools |

---

## Chapter 2: Linux Fundamentals

### Essential Commands

```bash
# Navigation
pwd                     # Current directory
ls -la                  # List with details
cd /path                # Change directory

# File Operations
cp source dest          # Copy
mv old new              # Move/rename
rm file                 # Delete (CAREFUL!)
mkdir -p dir/subdir     # Create nested directories

# Viewing Files
cat file                # Print file
less file               # Page through file
head -n 20 file         # First 20 lines
tail -f file            # Follow file (live logs)

# Searching
grep "pattern" file     # Find in file
grep -r "pattern" ./    # Recursive search
find /path -name "*.txt" # Find files

# Permissions
chmod 755 script.sh     # Set permissions
chown user:group file   # Change ownership
```

### File Permissions

```
-rwxr-xr-x  1  user  group  4096  Jan 15  script.sh
 â”‚â””â”¬â”˜â””â”¬â”˜â””â”¬â”˜
 â”‚ â”‚  â”‚  â””â”€â”€ Others: read + execute
 â”‚ â”‚  â””â”€â”€ Group: read + execute  
 â”‚ â””â”€â”€ Owner: read + write + execute
 â””â”€â”€ File type

Permission Values:
r (read)    = 4
w (write)   = 2
x (execute) = 1

Common: 755 (scripts), 644 (files), 600 (secrets)
```

---

## Chapter 3: SSH Mastery

### Generate SSH Keys

```bash
# Modern Ed25519 (recommended)
ssh-keygen -t ed25519 -C "your_email@example.com"

# RSA (legacy compatibility)
ssh-keygen -t rsa -b 4096 -C "your_email@example.com"
```

### SSH Config (~/.ssh/config)

```bash
Host oracle
    HostName 129.154.xxx.xxx
    User ubuntu
    IdentityFile ~/.ssh/oracle_key

Host prod
    HostName prod.example.com
    User deploy
    Port 2222

# Now just: ssh oracle
```

### SSH Hardening (/etc/ssh/sshd_config)

```bash
Port 2222
PermitRootLogin no
PasswordAuthentication no
MaxAuthTries 3
AllowUsers ubuntu deploy
```

---

## Chapter 4: Networking Fundamentals

### Common Ports

| Port | Service | Description |
|------|---------|-------------|
| 22 | SSH | Secure Shell |
| 80 | HTTP | Web traffic |
| 443 | HTTPS | Secure web |
| 3000 | Node.js | Dev server |
| 5432 | PostgreSQL | Database |
| 6379 | Redis | Cache |
| 9092 | Kafka | Message broker |

### Network Commands

```bash
# Check connectivity
ping google.com
traceroute google.com

# Check ports
ss -tulpn           # All listening ports
sudo lsof -i :80    # What's using port 80

# DNS
dig example.com
nslookup example.com
```

---

## Chapter 5: Firewall & Network Security

### UFW (Uncomplicated Firewall)

```bash
# Enable/Status
sudo ufw enable
sudo ufw status verbose

# Default policies
sudo ufw default deny incoming
sudo ufw default allow outgoing

# Allow ports
sudo ufw allow 22
sudo ufw allow 80
sudo ufw allow 443

# Rate limiting
sudo ufw limit ssh
```

### fail2ban

```bash
sudo apt install fail2ban -y

# /etc/fail2ban/jail.local
[sshd]
enabled = true
maxretry = 3
bantime = 24h
```

---

## Chapter 6: Web Servers (Nginx)

### Reverse Proxy Configuration

```nginx
upstream backend {
    server 127.0.0.1:3000;
    keepalive 64;
}

server {
    listen 80;
    server_name example.com;
    
    location / {
        proxy_pass http://backend;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

### Load Balancing

```nginx
upstream backend {
    least_conn;                    # Use least connections
    server 127.0.0.1:3001 weight=3;
    server 127.0.0.1:3002 weight=2;
    server 127.0.0.1:3003 backup;  # Only when others fail
}
```

---

## Chapter 7: Process Management

### PM2 (Node.js)

```bash
# Start application
pm2 start app.js --name "my-app" -i max

# Commands
pm2 list
pm2 logs my-app
pm2 reload my-app    # Zero-downtime
pm2 stop my-app

# Persistence
pm2 startup
pm2 save
```

### Ecosystem File

```javascript
// ecosystem.config.js
module.exports = {
  apps: [{
    name: 'my-app',
    script: 'app.js',
    instances: 'max',
    exec_mode: 'cluster',
    env_production: {
      NODE_ENV: 'production'
    }
  }]
};
```

---

## Chapter 8-9: Databases & Redis

### PostgreSQL

```bash
sudo -u postgres psql

# Create user and database
CREATE USER myapp WITH PASSWORD 'password';
CREATE DATABASE mydb OWNER myapp;
GRANT ALL PRIVILEGES ON DATABASE mydb TO myapp;

# Backup
pg_dump -U myapp mydb > backup.sql
```

### Redis

```bash
redis-cli

SET key "value"
GET key
SETEX session 3600 "data"    # Expires in 1 hour
HSET user:1 name "John" age 30
HGETALL user:1
```

---

## Chapter 10-14: Deployment, SSL, Monitoring, Security

### Let's Encrypt SSL

```bash
sudo apt install certbot python3-certbot-nginx -y
sudo certbot --nginx -d example.com -d www.example.com
sudo certbot renew --dry-run
```

### Health Check Endpoint

```javascript
app.get('/health', async (req, res) => {
  try {
    await db.query('SELECT 1');
    await redis.ping();
    res.json({ status: 'healthy' });
  } catch (error) {
    res.status(503).json({ status: 'unhealthy' });
  }
});
```

### Security Headers (Nginx)

```nginx
add_header X-Frame-Options "SAMEORIGIN" always;
add_header X-Content-Type-Options "nosniff" always;
add_header X-XSS-Protection "1; mode=block" always;
add_header Strict-Transport-Security "max-age=31536000" always;
server_tokens off;
```

---

# PART 2: AUTOMATION & CONTAINERS

---

## Chapter 19: Docker

### Dockerfile

```dockerfile
FROM node:20-alpine

WORKDIR /app
COPY package*.json ./
RUN npm ci --production
COPY . .

EXPOSE 3000
USER node
CMD ["node", "app.js"]
```

### Docker Compose

```yaml
version: '3.8'
services:
  app:
    build: .
    ports:
      - "3000:3000"
    depends_on:
      - db
      - redis
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/mydb

  db:
    image: postgres:15
    volumes:
      - postgres-data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine

volumes:
  postgres-data:
```

### Docker Commands

```bash
docker build -t myapp:v1 .
docker run -d -p 3000:3000 myapp:v1
docker-compose up -d
docker-compose logs -f app
docker system prune -a
```

---

## Chapter 18: CI/CD (GitHub Actions)

```yaml
# .github/workflows/deploy.yml
name: Deploy

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
      - run: npm ci
      - run: npm test

  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.HOST }}
          username: ${{ secrets.USER }}
          key: ${{ secrets.SSH_KEY }}
          script: |
            cd /var/www/app
            git pull
            npm ci --production
            pm2 reload ecosystem.config.js
```

---

# PART 3-4: KUBERNETES & PLATFORM ENGINEERING

---

## Chapter 27: Kubernetes Fundamentals

### Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
        - name: myapp
          image: myapp:v1
          ports:
            - containerPort: 3000
          resources:
            requests:
              memory: "128Mi"
              cpu: "100m"
            limits:
              memory: "256Mi"
              cpu: "500m"
```

### Essential kubectl

```bash
kubectl get pods
kubectl logs -f deployment/myapp
kubectl exec -it pod/myapp -- sh
kubectl rollout restart deployment/myapp
kubectl rollout undo deployment/myapp
```

---

## Chapter 28: K3s (Lightweight Kubernetes)

```bash
# Install
curl -sfL https://get.k3s.io | sh -

# Verify
sudo kubectl get nodes

# Configure kubectl
mkdir -p ~/.kube
sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
sudo chown $(id -u):$(id -g) ~/.kube/config
```

---

## Chapter 32: Terraform

```hcl
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

variable "environment" {
  default = "prod"
}

resource "aws_instance" "web" {
  ami           = "ami-12345678"
  instance_type = "t3.micro"
  
  tags = {
    Name = "web-${var.environment}"
  }
}

output "instance_ip" {
  value = aws_instance.web.public_ip
}
```

```bash
terraform init
terraform plan
terraform apply
terraform destroy
```

---

## Chapter 33: GitOps (ArgoCD)

```bash
# Install ArgoCD
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# Get password
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d
```

---

# PART 5: SERVICE MESH (NEW)

---

## Chapter 40-41: Istio

### Install Istio

```bash
curl -L https://istio.io/downloadIstio | sh -
istioctl install --set profile=demo -y
kubectl label namespace default istio-injection=enabled
```

### Traffic Management

```yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp-canary
spec:
  hosts:
    - myapp
  http:
    - route:
        - destination:
            host: myapp
            subset: v1
          weight: 90
        - destination:
            host: myapp
            subset: v2
          weight: 10
```

### mTLS

```yaml
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
spec:
  mtls:
    mode: STRICT
```

---

# PART 6: KAFKA & EVENT-DRIVEN (NEW)

---

## Chapter 46: Apache Kafka

### Docker Setup

```yaml
version: '3.8'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
```

### Kafka Commands

```bash
# Create topic
kafka-topics --create --bootstrap-server localhost:9092 \
  --topic orders --partitions 3

# Produce
kafka-console-producer --bootstrap-server localhost:9092 --topic orders

# Consume
kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic orders --from-beginning
```

### Node.js Producer/Consumer

```javascript
const { Kafka } = require('kafkajs');
const kafka = new Kafka({ brokers: ['localhost:9092'] });

// Producer
const producer = kafka.producer();
await producer.send({
  topic: 'orders',
  messages: [{ key: '1', value: JSON.stringify({ orderId: 1 }) }]
});

// Consumer
const consumer = kafka.consumer({ groupId: 'order-processor' });
await consumer.subscribe({ topic: 'orders' });
await consumer.run({
  eachMessage: async ({ message }) => {
    console.log(JSON.parse(message.value.toString()));
  }
});
```

---

# PART 7: SERVERLESS (NEW)

---

## Chapter 49-50: AWS Lambda

```javascript
// Lambda Handler
exports.handler = async (event) => {
  return {
    statusCode: 200,
    body: JSON.stringify({ message: 'Hello!' })
  };
};
```

### Serverless Framework

```yaml
# serverless.yml
service: my-api
provider:
  name: aws
  runtime: nodejs20.x

functions:
  api:
    handler: handler.main
    events:
      - http:
          path: /
          method: ANY
```

---

# PART 8: CHAOS ENGINEERING (NEW)

---

## Chapter 52-53: Chaos Engineering

### Principles

```
1. Define steady state (normal behavior)
2. Hypothesize (system will handle failure)
3. Introduce failures (kill pods, add latency)
4. Observe and learn
5. Fix weaknesses found
```

### LitmusChaos

```yaml
apiVersion: litmuschaos.io/v1alpha1
kind: ChaosEngine
metadata:
  name: pod-delete-chaos
spec:
  appinfo:
    appns: production
    applabel: "app=api"
  experiments:
    - name: pod-delete
      spec:
        components:
          env:
            - name: TOTAL_CHAOS_DURATION
              value: "60"
```

---

# PART 9: COMPLIANCE (NEW)

---

## Chapter 56: Compliance Frameworks

| Framework | Focus | For |
|-----------|-------|-----|
| SOC 2 | Security, availability | SaaS companies |
| HIPAA | Healthcare data | Health tech |
| PCI-DSS | Credit cards | Payment processing |
| GDPR | Privacy | EU data |
| ISO 27001 | InfoSec | Any organization |

---

# PART 10: SYSTEM DESIGN (NEW)

---

## Chapter 59: System Design Process

```
1. REQUIREMENTS (5 min)
   - What should it do?
   - Scale? Latency? Availability?

2. CAPACITY ESTIMATION (5 min)
   - Users: DAU, MAU
   - Traffic: QPS
   - Storage: Data size

3. HIGH-LEVEL DESIGN (10 min)
   - Components
   - Data flow

4. DETAILED DESIGN (15 min)
   - Database schema
   - API design
   - Caching

5. BOTTLENECKS (5 min)
   - Single points of failure
   - Scaling limits
```

## Chapter 60: CAP Theorem

```
In distributed systems, choose 2 of 3:

CONSISTENCY: All nodes see same data
AVAILABILITY: System always responds
PARTITION TOLERANCE: Works despite network failures

CP Systems: MongoDB, Redis Cluster
AP Systems: Cassandra, DynamoDB
```

## Chapter 61: Design Patterns

### CQRS

```
Commands (Write) â†’ Write DB â†’ Events â†’ Read DB â† Queries (Read)

Benefits:
- Optimize read/write independently
- Scale separately
```

### Circuit Breaker

```
CLOSED â†’ (failures exceed threshold) â†’ OPEN
   â†‘                                      â†“
   â””â”€â”€â”€â”€â”€â”€ (recovery succeeds) â†â”€â”€ HALF-OPEN
```

### Saga Pattern

```
Distributed Transactions:

Happy Path:
Create Order â†’ Reserve Stock â†’ Process Payment â†’ Ship

Compensation (if fails):
Cancel Order â† Release Stock â† Refund Payment
```

---

# QUICK REFERENCE

## Essential Commands

```bash
# Linux
df -h                    # Disk space
free -h                  # Memory
htop                     # Processes

# Docker
docker ps -a             # Containers
docker logs -f <c>       # Logs
docker system prune -a   # Cleanup

# Kubernetes
kubectl get all          # All resources
kubectl logs -f deploy/x # Logs
kubectl rollout undo     # Rollback

# Terraform
terraform plan           # Preview
terraform apply          # Create
terraform destroy        # Delete
```

## Important Ports

```
22    SSH
80    HTTP
443   HTTPS
3000  Node.js
5432  PostgreSQL
6379  Redis
9092  Kafka
9090  Prometheus
```

---

# CERTIFICATIONS

| Cert | Provider | Focus |
|------|----------|-------|
| CKA | CNCF | Kubernetes Admin |
| CKS | CNCF | Kubernetes Security |
| AWS SAA | Amazon | Solutions Architect |
| Terraform | HashiCorp | IaC |
| GCP PCA | Google | Cloud Architect |

---

# RESOURCES

## Books
- "The Phoenix Project" - DevOps culture
- "Site Reliability Engineering" - Google SRE
- "Designing Data-Intensive Applications" - Distributed systems
- "Kubernetes Up & Running" - K8s

## YouTube
- TechWorld with Nana (DevOps)
- ByteByteGo (System Design)
- KodeKloud (Kubernetes)

---

# FINAL CHECKLIST

```
INFRASTRUCTURE
â–¡ Terraform for all resources
â–¡ GitOps workflow

DEPLOYMENT  
â–¡ CI/CD pipeline
â–¡ Container scanning
â–¡ Zero-downtime deploys

RELIABILITY
â–¡ SLOs defined
â–¡ Error budgets
â–¡ On-call rotation

OBSERVABILITY
â–¡ Metrics + Logs + Traces
â–¡ Dashboards
â–¡ Alerts

SECURITY
â–¡ TLS everywhere
â–¡ Secrets in vault
â–¡ Network policies

DR & FINOPS
â–¡ Backups tested
â–¡ DR drills
â–¡ Cost monitoring
```

---

> **ğŸ‰ CONGRATULATIONS!**
> 
> You now have the complete DevOps & System Architecture curriculum!
> 
> **75 Chapters | 12 Parts | Complete Journey**
> 
> From `ls` command to Platform Engineering
> 
> Keep Learning, Keep Building! ğŸš€

---

**Created with â¤ï¸ for Usama**  
**Version 2.0 - Complete Edition**  
**January 2026**