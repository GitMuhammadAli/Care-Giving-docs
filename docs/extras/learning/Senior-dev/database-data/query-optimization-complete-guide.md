# ğŸ” Query Optimization - Complete Guide

> A comprehensive guide to query optimization - EXPLAIN plans, N+1 problem, eager/lazy loading, query analysis, and how to make your database queries blazing fast.

---

## ğŸ§  MUST REMEMBER TO IMPRESS (Memorize This!)

### 1-Liner Definition
> "Query optimization is analyzing execution plans, eliminating N+1 queries, choosing appropriate loading strategies, and restructuring queries to minimize database work - often achieving 10-1000x performance improvements without changing indexes."

### The Query Optimization Mental Model
```
QUERY PERFORMANCE FACTORS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  SLOW QUERY                        FAST QUERY                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”‚
â”‚                                                                  â”‚
â”‚  â€¢ Full table scan                 â€¢ Index scan                 â”‚
â”‚  â€¢ N+1 queries (100 queries)       â€¢ Single JOIN (1 query)     â”‚
â”‚  â€¢ SELECT * (all columns)          â€¢ SELECT specific columns   â”‚
â”‚  â€¢ No LIMIT                        â€¢ LIMIT + pagination        â”‚
â”‚  â€¢ Subquery in SELECT              â€¢ JOIN or CTE               â”‚
â”‚  â€¢ DISTINCT on large result        â€¢ Proper GROUP BY           â”‚
â”‚  â€¢ ORDER BY unindexed column       â€¢ ORDER BY indexed column   â”‚
â”‚                                                                  â”‚
â”‚  TIME BREAKDOWN (typical slow query):                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Network latency: 5ms                                  â”‚     â”‚
â”‚  â”‚ Query parsing:   1ms                                  â”‚     â”‚
â”‚  â”‚ Planning:        2ms                                  â”‚     â”‚
â”‚  â”‚ Execution:       5000ms  â† THE PROBLEM               â”‚     â”‚
â”‚  â”‚   â””â”€ Seq scan:   4500ms                              â”‚     â”‚
â”‚  â”‚   â””â”€ Sorting:    500ms                               â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Numbers to Remember
| Metric | Value | Context |
|--------|-------|---------|
| N+1 impact | **100+ queries** | 100 items = 101 queries vs 1-2 queries |
| Network latency | **1-5ms per query** | N+1 adds up fast |
| Index vs seq scan | **100-1000x faster** | For selective queries |
| SELECT * overhead | **2-10x more data** | Especially with large columns |
| JOIN vs subquery | **Often 10x faster** | Optimizer handles JOINs better |

### The "Wow" Statement (Memorize This!)
> "At my previous company, we had an API endpoint that took 8 seconds to load user dashboards. Using `pg_stat_statements`, I identified the culprit: a classic N+1 problem loading 50 orders with their items - that's 51 queries! I refactored to eager load with a single JOIN query and added a covering index. Response time dropped to 80ms - that's 100x faster. The key insight came from EXPLAIN ANALYZE showing 47ms per query Ã— 51 queries = 2.4s just in query execution, plus connection overhead. The fix was literally changing `.map(async order => await getItems(order.id))` to a single query with `JOIN order_items ON orders.id = order_items.order_id`."

### Key Terms to Drop (Sound Smart!)
| Term | Use It Like This |
|------|------------------|
| **"Execution plan"** | "The execution plan shows a sequential scan - we need an index here" |
| **"N+1 problem"** | "That's a classic N+1 - we're making 101 queries instead of 2" |
| **"Eager loading"** | "Switched to eager loading with includes to fetch related data in one query" |
| **"Query cost"** | "EXPLAIN shows cost of 50000 - way too high for this simple lookup" |
| **"Correlated subquery"** | "That correlated subquery executes once per row - rewrite as JOIN" |
| **"Seq scan vs index scan"** | "Seq scan on 10M rows means reading every row - need better index" |
| **"Data loader pattern"** | "Using DataLoader to batch and cache queries within a request" |

---

## ğŸ¯ How to Explain Like a Senior Developer

### When Asked: "How do you optimize slow database queries?"

**Junior Answer:**
> "Add an index or use a faster database."

**Senior Answer:**
> "I follow a systematic approach:

**1. Measure first**
- Enable slow query logging (>100ms)
- Use `pg_stat_statements` to find frequent slow queries
- Run EXPLAIN ANALYZE on suspects

**2. Analyze the execution plan**
- Look for seq scans on large tables
- Check if indexes are being used
- Identify high-cost operations
- Compare estimated vs actual rows

**3. Common fixes (in order of impact)**
- Fix N+1 with eager loading or batching
- Add missing indexes
- Rewrite correlated subqueries as JOINs
- Add covering indexes for frequently accessed columns
- Use pagination instead of loading all rows
- Cache results that don't change often

**4. Verify improvement**
- Re-run EXPLAIN ANALYZE
- Measure actual response time
- Monitor in production

The key is measuring before and after - sometimes 'optimizations' actually make things worse due to different data distributions or query patterns."

### Follow-up Questions to Expect:

| They Ask | You Answer |
|----------|------------|
| "What's the N+1 problem?" | "Loading 100 users then 100 separate queries for their orders. Solution: JOIN or eager load - 1-2 queries instead of 101." |
| "Eager vs lazy loading?" | "Eager: fetch related data immediately (good when you'll need it). Lazy: fetch on access (good when you might not need it). Wrong choice = N+1 or over-fetching." |
| "How do you read EXPLAIN?" | "Look for: Seq Scan (bad on big tables), high cost numbers, rows estimate vs actual (big diff = stale stats), nested loops with high iterations." |
| "When is a seq scan okay?" | "Small tables (<1000 rows), low selectivity (returning >15% of rows), or when combined with index on another table in a JOIN." |

---

## ğŸ“š Table of Contents

1. [EXPLAIN Deep Dive](#1-explain-deep-dive)
2. [N+1 Problem](#2-n1-problem)
3. [Eager vs Lazy Loading](#3-eager-vs-lazy-loading)
4. [Query Patterns & Anti-Patterns](#4-query-patterns--anti-patterns)
5. [ORM Optimization](#5-orm-optimization)
6. [Query Analysis Tools](#6-query-analysis-tools)
7. [Common Pitfalls](#7-common-pitfalls)
8. [Interview Questions](#8-interview-questions)

---

## 1. EXPLAIN Deep Dive

### Understanding EXPLAIN Output

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- EXPLAIN vs EXPLAIN ANALYZE
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- EXPLAIN: Shows plan without executing (estimates only)
EXPLAIN SELECT * FROM orders WHERE user_id = 123;

-- EXPLAIN ANALYZE: Actually runs query (real timing)
EXPLAIN ANALYZE SELECT * FROM orders WHERE user_id = 123;

-- EXPLAIN with all options (most useful)
EXPLAIN (ANALYZE, BUFFERS, FORMAT TEXT)
SELECT * FROM orders WHERE user_id = 123 AND status = 'active';
```

### Reading the Execution Plan

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- EXAMPLE EXECUTION PLAN
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EXPLAIN (ANALYZE, BUFFERS)
SELECT o.*, u.email 
FROM orders o
JOIN users u ON o.user_id = u.id
WHERE o.status = 'active' AND o.created_at > '2024-01-01';

/*
EXAMPLE OUTPUT:

Hash Join  (cost=1.05..29.35 rows=12 width=200) 
           (actual time=0.025..0.156 rows=15 loops=1)
  Hash Cond: (o.user_id = u.id)
  Buffers: shared hit=8
  ->  Index Scan using idx_orders_status_date on orders o  
      (cost=0.29..28.15 rows=12 width=150) 
      (actual time=0.012..0.089 rows=15 loops=1)
        Index Cond: ((status = 'active') AND (created_at > '2024-01-01'))
        Buffers: shared hit=4
  ->  Hash  (cost=1.05..1.05 rows=5 width=50) 
            (actual time=0.008..0.008 rows=5 loops=1)
        Buckets: 1024  Batches: 1
        ->  Seq Scan on users u  
            (cost=0.00..1.05 rows=5 width=50) 
            (actual time=0.003..0.004 rows=5 loops=1)
              Buffers: shared hit=1
Planning Time: 0.150 ms
Execution Time: 0.189 ms
*/
```

### Decoding Plan Elements

```
EXECUTION PLAN ELEMENTS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  SCAN TYPES:                                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                    â”‚
â”‚  Seq Scan         â†’ Reading entire table row by row             â”‚
â”‚  Index Scan       â†’ Using index to find rows, then fetch        â”‚
â”‚  Index Only Scan  â†’ All data from index, no table access        â”‚
â”‚  Bitmap Heap Scan â†’ Build bitmap from index, then fetch         â”‚
â”‚                                                                  â”‚
â”‚  JOIN TYPES:                                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                    â”‚
â”‚  Nested Loop      â†’ For each row in A, scan B (O(n*m))         â”‚
â”‚  Hash Join        â†’ Build hash of smaller table, probe          â”‚
â”‚  Merge Join       â†’ Both sorted, merge (good for big tables)   â”‚
â”‚                                                                  â”‚
â”‚  COST FORMAT: (startup..total rows=N width=N)                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                   â”‚
â”‚  startup cost     â†’ Cost before first row returned             â”‚
â”‚  total cost       â†’ Cost to return all rows                    â”‚
â”‚  rows             â†’ Estimated number of rows                   â”‚
â”‚  width            â†’ Average row size in bytes                  â”‚
â”‚                                                                  â”‚
â”‚  ACTUAL FORMAT: (actual time=start..end rows=N loops=N)        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚  actual time      â†’ Real time in milliseconds                  â”‚
â”‚  rows             â†’ Actual rows returned                       â”‚
â”‚  loops            â†’ How many times this step ran               â”‚
â”‚                                                                  â”‚
â”‚  RED FLAGS:                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                     â”‚
â”‚  â€¢ Seq Scan on large table (>10K rows)                         â”‚
â”‚  â€¢ Nested Loop with high loops count                           â”‚
â”‚  â€¢ rows estimate very different from actual                    â”‚
â”‚  â€¢ Sort or Hash operations spilling to disk                    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cost Analysis

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- UNDERSTANDING COST NUMBERS
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- Cost is in arbitrary units (based on seq_page_cost = 1.0)
-- Lower is better, but only compare within same query

-- Seq Scan cost calculation:
-- cost = (pages * seq_page_cost) + (rows * cpu_tuple_cost)
-- For 10000 row table with 100 pages:
-- cost = (100 * 1.0) + (10000 * 0.01) = 200

-- Index Scan cost includes:
-- - Reading index pages (random_page_cost = 4.0)
-- - Reading heap pages for matching rows
-- - Processing tuples

-- COMPARE PLANS:

-- Plan A: Seq Scan (cost=0.00..1000.00)
-- Plan B: Index Scan (cost=0.29..50.00)
-- â†’ Index scan is ~20x cheaper

-- BUT if returning 80% of rows:
-- Plan A: Seq Scan (cost=0.00..1000.00)  â† Actually better!
-- Plan B: Index Scan (cost=0.29..3500.00)  â† Random I/O hurts
```

---

## 2. N+1 Problem

### Understanding N+1

```
THE N+1 PROBLEM VISUALIZED:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  GOAL: Display 100 orders with their items                     â”‚
â”‚                                                                  â”‚
â”‚  N+1 APPROACH (101 queries):                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚
â”‚  Query 1:   SELECT * FROM orders LIMIT 100                     â”‚
â”‚  Query 2:   SELECT * FROM items WHERE order_id = 1             â”‚
â”‚  Query 3:   SELECT * FROM items WHERE order_id = 2             â”‚
â”‚  Query 4:   SELECT * FROM items WHERE order_id = 3             â”‚
â”‚  ...                                                           â”‚
â”‚  Query 101: SELECT * FROM items WHERE order_id = 100           â”‚
â”‚                                                                  â”‚
â”‚  Time: 101 queries Ã— 5ms = 505ms minimum                       â”‚
â”‚  (Plus connection overhead, network latency)                    â”‚
â”‚                                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                  â”‚
â”‚  OPTIMIZED APPROACH (2 queries):                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚  Query 1: SELECT * FROM orders LIMIT 100                       â”‚
â”‚  Query 2: SELECT * FROM items WHERE order_id IN (1,2,3...100) â”‚
â”‚                                                                  â”‚
â”‚  Time: 2 queries Ã— 10ms = 20ms                                 â”‚
â”‚  25x faster!                                                   â”‚
â”‚                                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                  â”‚
â”‚  EVEN BETTER (1 query with JOIN):                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                             â”‚
â”‚  Query 1: SELECT o.*, i.*                                      â”‚
â”‚           FROM orders o                                        â”‚
â”‚           LEFT JOIN items i ON o.id = i.order_id               â”‚
â”‚           WHERE o.id IN (1,2,3...100)                         â”‚
â”‚                                                                  â”‚
â”‚  Time: 1 query Ã— 15ms = 15ms                                   â”‚
â”‚  33x faster than N+1!                                          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### N+1 in Code Examples

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// N+1 PROBLEM IN CODE
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// âŒ BAD: N+1 Problem
async function getOrdersWithItems() {
  // Query 1: Get orders
  const orders = await db.query('SELECT * FROM orders LIMIT 100');
  
  // Queries 2-101: Get items for each order (N queries!)
  for (const order of orders) {
    order.items = await db.query(
      'SELECT * FROM items WHERE order_id = $1', 
      [order.id]
    );
  }
  
  return orders;
}
// Total: 101 queries! ğŸ”´

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// âœ… GOOD: Batched queries (2 queries)
async function getOrdersWithItemsBatched() {
  // Query 1: Get orders
  const orders = await db.query('SELECT * FROM orders LIMIT 100');
  const orderIds = orders.map(o => o.id);
  
  // Query 2: Get ALL items in one query
  const items = await db.query(
    'SELECT * FROM items WHERE order_id = ANY($1)',
    [orderIds]
  );
  
  // Group items by order in memory
  const itemsByOrder = items.reduce((acc, item) => {
    acc[item.order_id] = acc[item.order_id] || [];
    acc[item.order_id].push(item);
    return acc;
  }, {});
  
  // Attach items to orders
  for (const order of orders) {
    order.items = itemsByOrder[order.id] || [];
  }
  
  return orders;
}
// Total: 2 queries! ğŸŸ¢

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// âœ… BEST: Single JOIN query
async function getOrdersWithItemsJoin() {
  const result = await db.query(`
    SELECT 
      o.id as order_id,
      o.status,
      o.total,
      o.created_at,
      i.id as item_id,
      i.name as item_name,
      i.quantity,
      i.price
    FROM orders o
    LEFT JOIN items i ON o.id = i.order_id
    WHERE o.created_at > NOW() - INTERVAL '30 days'
    ORDER BY o.id
    LIMIT 100
  `);
  
  // Transform flat result to nested structure
  const ordersMap = new Map();
  
  for (const row of result.rows) {
    if (!ordersMap.has(row.order_id)) {
      ordersMap.set(row.order_id, {
        id: row.order_id,
        status: row.status,
        total: row.total,
        created_at: row.created_at,
        items: []
      });
    }
    
    if (row.item_id) {
      ordersMap.get(row.order_id).items.push({
        id: row.item_id,
        name: row.item_name,
        quantity: row.quantity,
        price: row.price
      });
    }
  }
  
  return Array.from(ordersMap.values());
}
// Total: 1 query! ğŸŸ¢ğŸŸ¢
```

### DataLoader Pattern (GraphQL)

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// DATALOADER: Batching and Caching within a request
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import DataLoader from 'dataloader';

// Create loader that batches individual loads into one query
const itemsLoader = new DataLoader(async (orderIds: number[]) => {
  // This runs ONCE with all orderIds collected in the event loop tick
  const items = await db.query(
    'SELECT * FROM items WHERE order_id = ANY($1)',
    [orderIds]
  );
  
  // Must return array in same order as input keys
  const itemsByOrder = new Map();
  for (const item of items) {
    const existing = itemsByOrder.get(item.order_id) || [];
    existing.push(item);
    itemsByOrder.set(item.order_id, existing);
  }
  
  return orderIds.map(id => itemsByOrder.get(id) || []);
});

// GraphQL resolver
const resolvers = {
  Order: {
    // Each order calls load() - but DataLoader batches them!
    items: (order) => itemsLoader.load(order.id)
  }
};

// Request for 100 orders:
// - Without DataLoader: 100 separate queries
// - With DataLoader: 1 batched query

// DataLoader also caches within request:
// - First load(1) â†’ query
// - Second load(1) â†’ returns cached result
```

### Detecting N+1 Problems

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// DETECTING N+1 IN DEVELOPMENT
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Method 1: Query logging with count
let queryCount = 0;

const originalQuery = db.query.bind(db);
db.query = async (...args) => {
  queryCount++;
  console.log(`Query #${queryCount}:`, args[0].substring(0, 100));
  return originalQuery(...args);
};

// Run your endpoint
await getOrdersWithItems();
console.log(`Total queries: ${queryCount}`);
// If > 5-10 for a simple request, investigate!

// Method 2: PostgreSQL query logging
// In postgresql.conf:
// log_min_duration_statement = 0  -- Log all queries
// log_statement = 'all'

// Method 3: ORM query logging (Prisma example)
const prisma = new PrismaClient({
  log: ['query', 'info', 'warn', 'error'],
});

// Method 4: Express middleware to count queries per request
app.use((req, res, next) => {
  req.queryCount = 0;
  const originalQuery = db.query.bind(db);
  
  db.query = async (...args) => {
    req.queryCount++;
    return originalQuery(...args);
  };
  
  res.on('finish', () => {
    if (req.queryCount > 10) {
      console.warn(`âš ï¸ ${req.method} ${req.path}: ${req.queryCount} queries`);
    }
  });
  
  next();
});
```

---

## 3. Eager vs Lazy Loading

### Understanding Loading Strategies

```
LOADING STRATEGIES COMPARISON:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  LAZY LOADING (Load on demand)                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚                                                                  â”‚
â”‚  const user = await User.findById(1);                          â”‚
â”‚  // Query 1: SELECT * FROM users WHERE id = 1                  â”‚
â”‚                                                                  â”‚
â”‚  const orders = await user.orders;  // Access triggers load    â”‚
â”‚  // Query 2: SELECT * FROM orders WHERE user_id = 1            â”‚
â”‚                                                                  â”‚
â”‚  âœ“ Pros: Only loads what you need                              â”‚
â”‚  âœ— Cons: Can cause N+1 if looping                              â”‚
â”‚                                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                  â”‚
â”‚  EAGER LOADING (Load upfront)                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚                                                                  â”‚
â”‚  const user = await User.findById(1, {                         â”‚
â”‚    include: ['orders', 'profile']                              â”‚
â”‚  });                                                           â”‚
â”‚  // Query 1: SELECT u.*, o.*, p.*                              â”‚
â”‚  //          FROM users u                                      â”‚
â”‚  //          LEFT JOIN orders o ON u.id = o.user_id            â”‚
â”‚  //          LEFT JOIN profiles p ON u.id = p.user_id          â”‚
â”‚  //          WHERE u.id = 1                                    â”‚
â”‚                                                                  â”‚
â”‚  âœ“ Pros: Single query, no N+1 risk                             â”‚
â”‚  âœ— Cons: May load data you don't need                          â”‚
â”‚                                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                  â”‚
â”‚  EXPLICIT LOADING (Manual control)                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚                                                                  â”‚
â”‚  const user = await User.findById(1);                          â”‚
â”‚  // Later, explicitly load if needed:                          â”‚
â”‚  if (needOrders) {                                             â”‚
â”‚    await user.loadRelation('orders');                          â”‚
â”‚  }                                                              â”‚
â”‚                                                                  â”‚
â”‚  âœ“ Pros: Full control                                          â”‚
â”‚  âœ— Cons: More code, easy to forget                             â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### When to Use Each Strategy

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EAGER LOADING: Use when you KNOW you'll need related data
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// âœ… Good: Always display user with their orders on dashboard
async function getUserDashboard(userId: string) {
  return await prisma.user.findUnique({
    where: { id: userId },
    include: {
      orders: {
        take: 10,
        orderBy: { createdAt: 'desc' }
      },
      profile: true
    }
  });
}

// âœ… Good: API returns user with related data
app.get('/api/users/:id', async (req, res) => {
  const user = await prisma.user.findUnique({
    where: { id: req.params.id },
    include: {
      orders: true,
      addresses: true
    }
  });
  res.json(user);
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// LAZY LOADING: Use when related data is conditional
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// âœ… Good: Only load orders if user clicks "View Orders"
async function getUser(userId: string) {
  return await prisma.user.findUnique({
    where: { id: userId }
  });
}

async function getUserOrders(userId: string) {
  return await prisma.order.findMany({
    where: { userId }
  });
}

// âœ… Good: GraphQL - client requests what it needs
const resolvers = {
  User: {
    // Only runs if client requests 'orders' field
    orders: (user) => prisma.order.findMany({ 
      where: { userId: user.id } 
    })
  }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// HYBRID: Different strategies for different use cases
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// List view: minimal data (lazy/no relations)
async function getUserList() {
  return await prisma.user.findMany({
    select: {
      id: true,
      name: true,
      email: true
      // No relations!
    }
  });
}

// Detail view: full data (eager relations)
async function getUserDetail(id: string) {
  return await prisma.user.findUnique({
    where: { id },
    include: {
      orders: true,
      profile: true,
      addresses: true
    }
  });
}
```

### ORM-Specific Eager Loading

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// PRISMA: include and select
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Include related models
const user = await prisma.user.findUnique({
  where: { id: 1 },
  include: {
    orders: true,                    // All orders
    orders: { take: 5 },             // Limited
    orders: {                        // Nested
      include: { items: true }
    }
  }
});

// Select specific fields only
const user = await prisma.user.findUnique({
  where: { id: 1 },
  select: {
    id: true,
    name: true,
    orders: {
      select: {
        id: true,
        total: true
      }
    }
  }
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TYPEORM: relations and query builder
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Using relations option
const user = await userRepository.findOne({
  where: { id: 1 },
  relations: ['orders', 'orders.items', 'profile']
});

// Using query builder (more control)
const user = await userRepository
  .createQueryBuilder('user')
  .leftJoinAndSelect('user.orders', 'order')
  .leftJoinAndSelect('order.items', 'item')
  .where('user.id = :id', { id: 1 })
  .getOne();

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SEQUELIZE: include option
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const user = await User.findByPk(1, {
  include: [
    { model: Order, as: 'orders' },
    { 
      model: Order, 
      as: 'orders',
      include: [{ model: Item, as: 'items' }]  // Nested
    }
  ]
});

// Eager loading for findAll
const users = await User.findAll({
  include: [{ model: Order }]
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// DRIZZLE: with() for relations
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const user = await db.query.users.findFirst({
  where: eq(users.id, 1),
  with: {
    orders: true,
    profile: true
  }
});
```

---

## 4. Query Patterns & Anti-Patterns

### Anti-Pattern: SELECT *

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ANTI-PATTERN: SELECT *
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- âŒ BAD: Fetches all 50 columns including large TEXT/BLOB
SELECT * FROM products WHERE category_id = 5;
-- Returns: id, name, description (10KB), specs (5KB), images (JSON)...
-- Network: 15KB Ã— 1000 rows = 15MB transfer

-- âœ… GOOD: Only columns you need
SELECT id, name, price, thumbnail_url 
FROM products 
WHERE category_id = 5;
-- Network: 200 bytes Ã— 1000 rows = 200KB transfer
-- 75x less data!

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- WHY SELECT * IS PROBLEMATIC
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- 1. More data transfer (network bandwidth)
-- 2. More memory usage (application RAM)
-- 3. Prevents covering index optimization
-- 4. Breaks if columns are added/renamed
-- 5. Exposes sensitive columns accidentally
```

### Anti-Pattern: Correlated Subquery

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ANTI-PATTERN: Correlated Subquery (runs for EACH row)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- âŒ BAD: Subquery executes once per order (N+1 in SQL!)
SELECT 
    o.id,
    o.total,
    (SELECT COUNT(*) FROM items i WHERE i.order_id = o.id) as item_count,
    (SELECT SUM(i.price) FROM items i WHERE i.order_id = o.id) as items_total
FROM orders o
WHERE o.user_id = 123;
-- For 100 orders: 1 + 100Ã—2 = 201 subquery executions!

-- âœ… GOOD: Use JOIN with aggregation
SELECT 
    o.id,
    o.total,
    COUNT(i.id) as item_count,
    COALESCE(SUM(i.price), 0) as items_total
FROM orders o
LEFT JOIN items i ON o.id = i.order_id
WHERE o.user_id = 123
GROUP BY o.id, o.total;
-- Single pass through both tables!

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ANTI-PATTERN: Subquery in WHERE for existence check
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- âŒ BAD: Subquery for each user
SELECT * FROM users u
WHERE (SELECT COUNT(*) FROM orders o WHERE o.user_id = u.id) > 0;

-- âœ… GOOD: Use EXISTS (stops at first match)
SELECT * FROM users u
WHERE EXISTS (SELECT 1 FROM orders o WHERE o.user_id = u.id);

-- âœ… ALSO GOOD: Use JOIN
SELECT DISTINCT u.* FROM users u
JOIN orders o ON u.id = o.user_id;
```

### Anti-Pattern: OR Conditions

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ANTI-PATTERN: OR conditions that prevent index use
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- âŒ BAD: OR on different columns - hard to optimize
SELECT * FROM users 
WHERE email = 'john@example.com' OR phone = '555-1234';
-- May require scanning both indexes and merging, or seq scan

-- âœ… GOOD: UNION of separate queries (each uses its index)
SELECT * FROM users WHERE email = 'john@example.com'
UNION
SELECT * FROM users WHERE phone = '555-1234';

-- âœ… ALTERNATIVE: Create combined index if this is common
CREATE INDEX idx_users_email_phone ON users(email, phone);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ANTI-PATTERN: OR with same column (usually okay)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- This is actually fine - can use index
SELECT * FROM users WHERE status = 'active' OR status = 'pending';

-- But better written as:
SELECT * FROM users WHERE status IN ('active', 'pending');
```

### Pattern: Pagination

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- PAGINATION STRATEGIES
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- âŒ BAD: OFFSET pagination (gets slower as offset increases)
SELECT * FROM orders ORDER BY created_at DESC LIMIT 20 OFFSET 10000;
-- Must scan and discard 10000 rows before returning 20!
-- Page 500 takes 500x longer than page 1

-- âœ… GOOD: Cursor-based pagination (consistent performance)
-- First page:
SELECT * FROM orders 
ORDER BY created_at DESC, id DESC 
LIMIT 20;

-- Next pages (use last row's values as cursor):
SELECT * FROM orders 
WHERE (created_at, id) < ('2024-01-15 10:30:00', 12345)
ORDER BY created_at DESC, id DESC 
LIMIT 20;
-- Uses index, no scanning of skipped rows!

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- CURSOR PAGINATION IMPLEMENTATION
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function getOrders(cursor?: string, limit = 20) {
  let query = db.select()
    .from(orders)
    .orderBy(desc(orders.createdAt), desc(orders.id))
    .limit(limit + 1);  // Fetch one extra to check if more
  
  if (cursor) {
    const [timestamp, id] = decodeCursor(cursor);
    query = query.where(
      or(
        lt(orders.createdAt, timestamp),
        and(
          eq(orders.createdAt, timestamp),
          lt(orders.id, id)
        )
      )
    );
  }
  
  const results = await query;
  const hasMore = results.length > limit;
  const items = hasMore ? results.slice(0, -1) : results;
  
  return {
    items,
    nextCursor: hasMore 
      ? encodeCursor(items[items.length - 1]) 
      : null
  };
}
```

### Pattern: Conditional Aggregation

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- CONDITIONAL AGGREGATION (avoid multiple queries)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- âŒ BAD: Multiple queries for dashboard stats
SELECT COUNT(*) FROM orders WHERE status = 'pending';
SELECT COUNT(*) FROM orders WHERE status = 'shipped';
SELECT COUNT(*) FROM orders WHERE status = 'delivered';
SELECT SUM(total) FROM orders WHERE status = 'delivered';

-- âœ… GOOD: Single query with conditional aggregation
SELECT 
    COUNT(*) FILTER (WHERE status = 'pending') as pending_count,
    COUNT(*) FILTER (WHERE status = 'shipped') as shipped_count,
    COUNT(*) FILTER (WHERE status = 'delivered') as delivered_count,
    SUM(total) FILTER (WHERE status = 'delivered') as delivered_total
FROM orders;

-- MySQL syntax (no FILTER):
SELECT 
    SUM(CASE WHEN status = 'pending' THEN 1 ELSE 0 END) as pending_count,
    SUM(CASE WHEN status = 'shipped' THEN 1 ELSE 0 END) as shipped_count,
    SUM(CASE WHEN status = 'delivered' THEN 1 ELSE 0 END) as delivered_count,
    SUM(CASE WHEN status = 'delivered' THEN total ELSE 0 END) as delivered_total
FROM orders;
```

---

## 5. ORM Optimization

### Prisma Optimization

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// PRISMA: Common optimizations
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// 1. Use select instead of include when possible
// âŒ Fetches all user fields
const users = await prisma.user.findMany({
  include: { orders: true }
});

// âœ… Fetches only needed fields
const users = await prisma.user.findMany({
  select: {
    id: true,
    name: true,
    orders: {
      select: { id: true, total: true }
    }
  }
});

// 2. Use findMany with where IN instead of loops
// âŒ N queries
for (const id of userIds) {
  await prisma.user.findUnique({ where: { id } });
}

// âœ… 1 query
await prisma.user.findMany({
  where: { id: { in: userIds } }
});

// 3. Use transactions for multiple operations
// âŒ Multiple round trips
await prisma.user.update({ where: { id: 1 }, data: { balance: 100 } });
await prisma.order.create({ data: { userId: 1, total: 50 } });

// âœ… Single transaction
await prisma.$transaction([
  prisma.user.update({ where: { id: 1 }, data: { balance: 100 } }),
  prisma.order.create({ data: { userId: 1, total: 50 } })
]);

// 4. Use raw queries for complex operations
const result = await prisma.$queryRaw`
  SELECT u.*, COUNT(o.id) as order_count
  FROM users u
  LEFT JOIN orders o ON u.id = o.user_id
  GROUP BY u.id
  HAVING COUNT(o.id) > 5
`;

// 5. Enable query logging for debugging
const prisma = new PrismaClient({
  log: [
    { level: 'query', emit: 'event' }
  ]
});

prisma.$on('query', (e) => {
  console.log(`Query: ${e.query}`);
  console.log(`Duration: ${e.duration}ms`);
});
```

### Query Builder Best Practices

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// KNEX/DRIZZLE: Building efficient queries
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// 1. Batch inserts
// âŒ N insert queries
for (const item of items) {
  await db.insert(items).values(item);
}

// âœ… Single batch insert
await db.insert(items).values(itemsArray);
// Or with chunking for large datasets
const chunks = chunkArray(itemsArray, 1000);
for (const chunk of chunks) {
  await db.insert(items).values(chunk);
}

// 2. Use specific columns, not *
// âŒ SELECT *
await db.select().from(users);

// âœ… SELECT specific columns
await db.select({
  id: users.id,
  name: users.name
}).from(users);

// 3. Efficient counting
// âŒ Fetches all rows then counts in JS
const allUsers = await db.select().from(users);
const count = allUsers.length;

// âœ… Count in database
const [{ count }] = await db
  .select({ count: sql`count(*)` })
  .from(users);

// 4. Upsert pattern
await db.insert(users)
  .values({ id: 1, name: 'John', email: 'john@ex.com' })
  .onConflictDoUpdate({
    target: users.id,
    set: { name: 'John', email: 'john@ex.com' }
  });
```

---

## 6. Query Analysis Tools

### PostgreSQL Tools

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- pg_stat_statements: Find slow queries
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- Enable extension
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- Find slowest queries by total time
SELECT 
    substring(query, 1, 100) as short_query,
    calls,
    round(total_exec_time::numeric, 2) as total_ms,
    round(mean_exec_time::numeric, 2) as avg_ms,
    rows
FROM pg_stat_statements
ORDER BY total_exec_time DESC
LIMIT 20;

-- Find queries by frequency (most called)
SELECT 
    substring(query, 1, 100) as short_query,
    calls,
    round(mean_exec_time::numeric, 2) as avg_ms
FROM pg_stat_statements
ORDER BY calls DESC
LIMIT 20;

-- Reset stats (after fixing issues)
SELECT pg_stat_statements_reset();

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- pg_stat_user_tables: Table statistics
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- Find tables with most sequential scans (missing indexes)
SELECT 
    relname as table_name,
    seq_scan,
    seq_tup_read,
    idx_scan,
    n_live_tup as row_count
FROM pg_stat_user_tables
WHERE seq_scan > 0
ORDER BY seq_scan DESC
LIMIT 10;

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- Auto-explain: Log slow query plans
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- In postgresql.conf:
-- shared_preload_libraries = 'auto_explain'
-- auto_explain.log_min_duration = '100ms'  -- Log plans for queries > 100ms
-- auto_explain.log_analyze = true
-- auto_explain.log_buffers = true
```

### Application-Level Monitoring

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// QUERY PERFORMANCE MONITORING
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Middleware to track slow queries
class QueryMonitor {
  private slowThreshold = 100; // ms
  
  async trackQuery<T>(
    name: string,
    queryFn: () => Promise<T>
  ): Promise<T> {
    const start = performance.now();
    
    try {
      const result = await queryFn();
      const duration = performance.now() - start;
      
      if (duration > this.slowThreshold) {
        console.warn(`ğŸ¢ Slow query: ${name} took ${duration.toFixed(2)}ms`);
        // Send to monitoring service
        metrics.recordSlowQuery(name, duration);
      }
      
      return result;
    } catch (error) {
      const duration = performance.now() - start;
      metrics.recordFailedQuery(name, duration, error);
      throw error;
    }
  }
}

// Usage
const monitor = new QueryMonitor();

const users = await monitor.trackQuery(
  'getActiveUsers',
  () => prisma.user.findMany({ where: { active: true } })
);

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// QUERY LOGGING WITH EXPLAIN (development only!)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Automatically EXPLAIN slow queries
async function queryWithExplain<T>(
  sql: string,
  params: any[]
): Promise<T> {
  const start = performance.now();
  const result = await db.query(sql, params);
  const duration = performance.now() - start;
  
  if (duration > 100 && process.env.NODE_ENV === 'development') {
    const explain = await db.query(`EXPLAIN ANALYZE ${sql}`, params);
    console.log('Slow query explain plan:', explain.rows);
  }
  
  return result;
}
```

---

## 7. Common Pitfalls

```
QUERY OPTIMIZATION PITFALLS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  1. PREMATURE OPTIMIZATION                                      â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚     Problem: Optimizing queries that aren't slow               â”‚
â”‚     Solution: Measure first! Use pg_stat_statements            â”‚
â”‚                                                                  â”‚
â”‚  2. OVER-EAGER LOADING                                          â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚     Problem: Always eager load "just in case"                  â”‚
â”‚     Solution: Profile actual usage, load only what's needed    â”‚
â”‚                                                                  â”‚
â”‚  3. NOT USING EXPLAIN                                           â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚     Problem: Guessing why query is slow                        â”‚
â”‚     Solution: EXPLAIN ANALYZE every suspect query              â”‚
â”‚                                                                  â”‚
â”‚  4. IGNORING STATISTICS                                         â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚     Problem: Optimizer makes bad choices                       â”‚
â”‚     Solution: Run ANALYZE after major data changes             â”‚
â”‚                                                                  â”‚
â”‚  5. N+1 IN BATCH JOBS                                          â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚     Problem: Loop queries in background jobs                   â”‚
â”‚     Solution: Use bulk operations, batch queries               â”‚
â”‚                                                                  â”‚
â”‚  6. FETCHING LARGE DATASETS TO APP                             â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚     Problem: Filter/aggregate in application code              â”‚
â”‚     Solution: Let database do filtering and aggregation        â”‚
â”‚                                                                  â”‚
â”‚  7. WRONG PAGINATION                                            â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚     Problem: OFFSET 10000 - very slow                          â”‚
â”‚     Solution: Cursor-based pagination                          â”‚
â”‚                                                                  â”‚
â”‚  8. UNBOUNDED QUERIES                                           â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚     Problem: SELECT without LIMIT on unknown data size         â”‚
â”‚     Solution: Always have LIMIT, even if high (10000)          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8. Interview Questions

### Conceptual Questions

**Q: "What is the N+1 problem and how do you solve it?"**
> "N+1 occurs when you fetch N items, then make N additional queries for related data. For 100 orders with items: 1 query for orders + 100 queries for items = 101 queries. 
>
> Solutions:
> 1. **Eager loading** - JOIN or include in ORM
> 2. **Batch loading** - WHERE id IN (...) for all IDs at once
> 3. **DataLoader** - for GraphQL, batches within event loop tick
>
> The fix usually takes 101 queries down to 1-2."

**Q: "When would you use lazy loading vs eager loading?"**
> "**Eager loading** when you know you'll need the related data - prevents N+1, fewer round trips. Good for list views that always show relations.
>
> **Lazy loading** when related data is conditional - might not need it. Good for detail views where user might not expand all sections.
>
> The key is understanding your access patterns. Wrong choice: eager = over-fetching, lazy = N+1."

**Q: "How do you read an EXPLAIN ANALYZE output?"**
> "I look for:
> 1. **Scan type** - Seq Scan on big table = red flag, need index
> 2. **Cost numbers** - Higher = more work
> 3. **Rows: estimated vs actual** - Big difference = stale statistics
> 4. **Loops** - High loop count in nested loop = potential issue
> 5. **Buffers** - shared read = disk I/O, shared hit = cache hit
>
> Then I identify the slowest node and optimize that first."

### Scenario Questions

**Q: "An API endpoint is slow. How do you debug it?"**
> "Step by step:
> 1. **Measure** - Add timing logs around DB calls
> 2. **Count queries** - Log query count per request (N+1?)
> 3. **EXPLAIN ANALYZE** - On slow queries
> 4. **Check pg_stat_statements** - Is this query pattern slow?
> 5. **Profile** - Is time in DB or application?
>
> Usually it's N+1 (fix with eager loading), missing index (add index), or fetching too much data (use SELECT specific columns)."

**Q: "Dashboard shows stats from multiple tables. How would you optimize?"**
> "Use conditional aggregation in a single query:
> ```sql
> SELECT 
>   COUNT(*) FILTER (WHERE status = 'active') as active,
>   COUNT(*) FILTER (WHERE status = 'pending') as pending,
>   SUM(amount) FILTER (WHERE status = 'paid') as revenue
> FROM orders;
> ```
> One query instead of 3+. If still slow, consider:
> - Materialized view refreshed periodically
> - Redis cache with TTL
> - Background job updating stats table"

**Q: "Query uses index but is still slow. What could be wrong?"**
> "Several possibilities:
> 1. **Index scan returning many rows** - selectivity too low
> 2. **Not a covering index** - many heap fetches
> 3. **Index bloat** - needs REINDEX
> 4. **Cold cache** - first run after restart
> 5. **Lock contention** - check pg_stat_activity
> 6. **Large result set** - add LIMIT or pagination
> 7. **Network latency** - many round trips (N+1)
>
> Check EXPLAIN ANALYZE buffers and actual vs estimated rows."

### Quick Fire

| Question | Answer |
|----------|--------|
| "N+1 with 100 items?" | "101 queries - 1 + N for relations" |
| "Fix for SELECT *?" | "Select only needed columns" |
| "Cursor vs offset pagination?" | "Cursor = consistent O(1), offset = O(n) as page increases" |
| "ORM causes N+1?" | "Enable query logging, use eager loading/includes" |
| "EXPLAIN shows seq scan?" | "Add index on WHERE columns, run ANALYZE" |

---

## Quick Reference

```
QUERY OPTIMIZATION CHEAT SHEET:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  N+1 PROBLEM:                                                   â”‚
â”‚  â€¢ Symptom: 101 queries for 100 items                          â”‚
â”‚  â€¢ Fix: Eager loading, JOIN, DataLoader                        â”‚
â”‚  â€¢ Detect: Query count logging, slow response                  â”‚
â”‚                                                                  â”‚
â”‚  LOADING STRATEGIES:                                            â”‚
â”‚  â€¢ Eager: Always need relations â†’ include/JOIN                 â”‚
â”‚  â€¢ Lazy: Might need relations â†’ load on access                 â”‚
â”‚  â€¢ Explicit: Full control â†’ manual load when needed            â”‚
â”‚                                                                  â”‚
â”‚  EXPLAIN ANALYSIS:                                              â”‚
â”‚  â€¢ Seq Scan (big table) = need index                           â”‚
â”‚  â€¢ High cost = expensive operation                             â”‚
â”‚  â€¢ Est vs actual rows differ = run ANALYZE                     â”‚
â”‚  â€¢ Nested loop + high loops = consider hash/merge join         â”‚
â”‚                                                                  â”‚
â”‚  ANTI-PATTERNS:                                                 â”‚
â”‚  â€¢ SELECT * â†’ Select specific columns                          â”‚
â”‚  â€¢ Correlated subquery â†’ JOIN with GROUP BY                    â”‚
â”‚  â€¢ OFFSET 10000 â†’ Cursor pagination                            â”‚
â”‚  â€¢ Loop queries â†’ Batch/bulk operations                        â”‚
â”‚  â€¢ OR on different columns â†’ UNION                             â”‚
â”‚                                                                  â”‚
â”‚  TOOLS:                                                         â”‚
â”‚  â€¢ EXPLAIN ANALYZE - see real execution                        â”‚
â”‚  â€¢ pg_stat_statements - find slow queries                      â”‚
â”‚  â€¢ Query logging - count queries per request                   â”‚
â”‚  â€¢ auto_explain - log plans for slow queries                   â”‚
â”‚                                                                  â”‚
â”‚  QUICK WINS:                                                    â”‚
â”‚  1. Fix N+1 (biggest impact usually)                           â”‚
â”‚  2. Add missing indexes                                        â”‚
â”‚  3. Limit result sets                                          â”‚
â”‚  4. Select only needed columns                                 â”‚
â”‚  5. Use pagination                                              â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

*Guide covers patterns applicable to PostgreSQL, MySQL, and common ORMs (Prisma, TypeORM, Sequelize, Drizzle).*


