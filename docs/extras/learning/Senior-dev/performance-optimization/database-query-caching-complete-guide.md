# ğŸ’¾ Database Query Caching - Complete Guide

> A comprehensive guide to database query caching - query result caching, materialized views, Redis caching, cache invalidation strategies, and patterns for high-performance data access.

---

## ğŸ§  MUST REMEMBER TO IMPRESS (Memorize This!)

### 1-Liner Definition
> "Query caching stores the results of database queries in faster storage (memory/Redis), reducing database load and latency from 50ms+ to <1ms - but the hard part is knowing when to invalidate the cache."

### The Query Caching Mental Model
```
WITHOUT CACHING:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  Request â†’ Application â†’ Database â†’ Query (50ms) â†’ Response    â”‚
â”‚  Request â†’ Application â†’ Database â†’ Query (50ms) â†’ Response    â”‚
â”‚  Request â†’ Application â†’ Database â†’ Query (50ms) â†’ Response    â”‚
â”‚                                                                  â”‚
â”‚  Same query executed 1000x = 1000 database hits               â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

WITH CACHING:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  Request 1 â†’ Check Cache (miss) â†’ DB Query (50ms) â†’ Cache it  â”‚
â”‚  Request 2 â†’ Check Cache (HIT) â†’ Return cached (<1ms)         â”‚
â”‚  Request 3 â†’ Check Cache (HIT) â†’ Return cached (<1ms)         â”‚
â”‚  ...                                                            â”‚
â”‚  Request 1000 â†’ Check Cache (HIT) â†’ Return cached (<1ms)      â”‚
â”‚                                                                  â”‚
â”‚  1 database hit instead of 1000!                               â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Numbers to Remember
| Metric | Value | Context |
|--------|-------|---------|
| Redis GET latency | **<1ms** | vs 5-50ms for database |
| Cache hit ratio goal | **>90%** | Below 80% = check strategy |
| TTL for user data | **5-60 seconds** | Balance freshness vs load |
| TTL for static data | **1-24 hours** | Product catalogs, configs |
| Materialized view refresh | **Seconds to minutes** | Depends on data size |

### The "Wow" Statement
> "Our product listing page was hitting the database 10,000 times per minute with the same query. I implemented a read-through cache with Redis - first request queries DB and caches for 60 seconds, subsequent requests get cached results in <1ms. Database load dropped 95%, page latency from 200ms to 15ms. The tricky part was cache invalidation: when a product updates, we invalidate that specific product's cache key plus any listing caches containing it. We use a pub/sub pattern where the product update event triggers cache invalidation across all app servers."

### Key Terms to Drop
| Term | Use It Like This |
|------|------------------|
| **"Cache-aside"** | "Using cache-aside pattern - app checks cache, falls back to DB, then populates cache" |
| **"Write-through"** | "Write-through cache ensures cache is always in sync with database" |
| **"TTL"** | "Set TTL to 60 seconds - balance between freshness and cache hit ratio" |
| **"Cache stampede"** | "Implemented locking to prevent cache stampede when TTL expires" |
| **"Materialized view"** | "Using materialized view for complex aggregations - refreshes every 5 minutes" |

---

## ğŸ“š Core Concepts

### Caching Patterns

```
CACHING PATTERNS OVERVIEW:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  CACHE-ASIDE (Lazy Loading)                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚
â”‚  1. App checks cache                                           â”‚
â”‚  2. Cache miss â†’ Query database                                â”‚
â”‚  3. Store result in cache                                      â”‚
â”‚  4. Return result                                              â”‚
â”‚                                                                  â”‚
â”‚  âœ“ Only caches what's needed                                   â”‚
â”‚  âœ— First request always slow (cache miss)                      â”‚
â”‚                                                                  â”‚
â”‚  READ-THROUGH                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                   â”‚
â”‚  1. App always reads from cache                                â”‚
â”‚  2. Cache handles DB fallback internally                       â”‚
â”‚                                                                  â”‚
â”‚  âœ“ Simple app code                                             â”‚
â”‚  âœ— Cache library must support DB integration                   â”‚
â”‚                                                                  â”‚
â”‚  WRITE-THROUGH                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚  1. App writes to cache                                        â”‚
â”‚  2. Cache writes to database synchronously                     â”‚
â”‚  3. Both updated before returning                              â”‚
â”‚                                                                  â”‚
â”‚  âœ“ Cache always consistent                                     â”‚
â”‚  âœ— Higher write latency                                        â”‚
â”‚                                                                  â”‚
â”‚  WRITE-BEHIND (Write-Back)                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  1. App writes to cache only                                   â”‚
â”‚  2. Cache async writes to database                             â”‚
â”‚                                                                  â”‚
â”‚  âœ“ Fast writes                                                 â”‚
â”‚  âœ— Risk of data loss if cache fails                           â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cache-Aside Implementation

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CACHE-ASIDE PATTERN WITH REDIS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import Redis from 'ioredis';

const redis = new Redis();
const CACHE_TTL = 60; // seconds

class ProductService {
    // Cache-aside: Check cache first, fallback to DB
    async getProduct(id: string): Promise<Product> {
        const cacheKey = `product:${id}`;
        
        // 1. Check cache
        const cached = await redis.get(cacheKey);
        if (cached) {
            return JSON.parse(cached);
        }
        
        // 2. Cache miss - query database
        const product = await db.query(
            'SELECT * FROM products WHERE id = $1',
            [id]
        );
        
        // 3. Store in cache with TTL
        await redis.setex(cacheKey, CACHE_TTL, JSON.stringify(product));
        
        // 4. Return result
        return product;
    }
    
    // Invalidate cache on update
    async updateProduct(id: string, data: Partial<Product>): Promise<void> {
        // Update database
        await db.query(
            'UPDATE products SET name = $1, price = $2 WHERE id = $3',
            [data.name, data.price, id]
        );
        
        // Invalidate cache
        await redis.del(`product:${id}`);
        
        // Also invalidate any listing caches that might contain this product
        await this.invalidateListingCaches(id);
    }
    
    private async invalidateListingCaches(productId: string): Promise<void> {
        // Pattern-based deletion for listing caches
        const keys = await redis.keys('products:list:*');
        if (keys.length > 0) {
            await redis.del(...keys);
        }
    }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CACHING WITH STAMPEDE PROTECTION
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function getWithLock(key: string, fetchFn: () => Promise<any>): Promise<any> {
    const cached = await redis.get(key);
    if (cached) return JSON.parse(cached);
    
    // Try to acquire lock
    const lockKey = `lock:${key}`;
    const acquired = await redis.set(lockKey, '1', 'EX', 10, 'NX');
    
    if (!acquired) {
        // Another process is fetching, wait and retry
        await sleep(100);
        return getWithLock(key, fetchFn);
    }
    
    try {
        // Double-check cache (another process might have populated it)
        const cached = await redis.get(key);
        if (cached) return JSON.parse(cached);
        
        // Fetch from source
        const data = await fetchFn();
        await redis.setex(key, CACHE_TTL, JSON.stringify(data));
        return data;
    } finally {
        await redis.del(lockKey);
    }
}
```

### Materialized Views

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- POSTGRESQL MATERIALIZED VIEWS
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- Complex aggregation that would be slow to compute on every request
CREATE MATERIALIZED VIEW product_stats AS
SELECT 
    p.category_id,
    COUNT(*) as product_count,
    AVG(p.price) as avg_price,
    SUM(oi.quantity) as total_sold,
    SUM(oi.quantity * oi.price) as total_revenue
FROM products p
LEFT JOIN order_items oi ON p.id = oi.product_id
LEFT JOIN orders o ON oi.order_id = o.id
WHERE o.created_at > NOW() - INTERVAL '30 days'
GROUP BY p.category_id;

-- Create index on materialized view for fast queries
CREATE INDEX idx_product_stats_category ON product_stats(category_id);

-- Query the materialized view (instant results)
SELECT * FROM product_stats WHERE category_id = 5;

-- Refresh the materialized view (run periodically)
REFRESH MATERIALIZED VIEW product_stats;

-- Refresh concurrently (doesn't lock reads, requires unique index)
CREATE UNIQUE INDEX idx_product_stats_unique ON product_stats(category_id);
REFRESH MATERIALIZED VIEW CONCURRENTLY product_stats;

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- AUTOMATIC REFRESH WITH PG_CRON
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- Install pg_cron extension
CREATE EXTENSION pg_cron;

-- Refresh every 5 minutes
SELECT cron.schedule('*/5 * * * *', 'REFRESH MATERIALIZED VIEW CONCURRENTLY product_stats');
```

### Application-Level Query Cache

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// QUERY RESULT CACHING WITH CACHE TAGS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class QueryCache {
    private redis: Redis;
    
    // Cache query result with tags for invalidation
    async cacheQuery<T>(
        key: string,
        tags: string[],
        ttl: number,
        queryFn: () => Promise<T>
    ): Promise<T> {
        // Check cache
        const cached = await this.redis.get(key);
        if (cached) return JSON.parse(cached);
        
        // Execute query
        const result = await queryFn();
        
        // Store result
        await this.redis.setex(key, ttl, JSON.stringify(result));
        
        // Store tag associations for invalidation
        for (const tag of tags) {
            await this.redis.sadd(`tag:${tag}`, key);
        }
        
        return result;
    }
    
    // Invalidate all caches with a specific tag
    async invalidateTag(tag: string): Promise<void> {
        const keys = await this.redis.smembers(`tag:${tag}`);
        if (keys.length > 0) {
            await this.redis.del(...keys);
        }
        await this.redis.del(`tag:${tag}`);
    }
}

// Usage
const cache = new QueryCache();

// Cache product listing with tags
const products = await cache.cacheQuery(
    'products:category:5:page:1',
    ['products', 'category:5'],  // Tags for invalidation
    60,
    () => db.query('SELECT * FROM products WHERE category_id = 5 LIMIT 20')
);

// When product in category 5 is updated, invalidate related caches
await cache.invalidateTag('category:5');
```

---

## Cache Invalidation Strategies

```
INVALIDATION STRATEGIES:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  1. TIME-BASED (TTL)                                            â”‚
â”‚     Simplest: cache expires after X seconds                    â”‚
â”‚     âœ“ Easy to implement                                        â”‚
â”‚     âœ— Data can be stale until TTL                              â”‚
â”‚                                                                  â”‚
â”‚  2. EVENT-BASED                                                 â”‚
â”‚     Invalidate when data changes (pub/sub)                     â”‚
â”‚     âœ“ Always fresh                                             â”‚
â”‚     âœ— Complex to track all dependencies                        â”‚
â”‚                                                                  â”‚
â”‚  3. VERSION-BASED                                               â”‚
â”‚     Include version in cache key, increment on change          â”‚
â”‚     âœ“ Simple invalidation                                      â”‚
â”‚     âœ— Old versions stay in cache (memory waste)               â”‚
â”‚                                                                  â”‚
â”‚  4. TAG-BASED                                                   â”‚
â”‚     Associate caches with tags, invalidate by tag              â”‚
â”‚     âœ“ Flexible grouping                                        â”‚
â”‚     âœ— Overhead of tracking tags                                â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Interview Questions

**Q: "How do you handle cache invalidation?"**
> "Depends on consistency requirements. For eventual consistency, TTL-based is simplest - cache expires after 60 seconds. For stronger consistency, event-based: when data changes, publish event that triggers cache deletion. I also use tag-based invalidation for related caches - updating a product invalidates all listing caches containing it."

**Q: "What is a cache stampede and how do you prevent it?"**
> "When cache expires, many concurrent requests all miss cache and hit database simultaneously - can overwhelm DB. Solutions: 1) Lock while fetching - only one request queries DB, others wait. 2) Probabilistic early expiration - some requests refresh before TTL. 3) Background refresh - refresh cache before expiration."

**Q: "When would you use a materialized view vs application caching?"**
> "Materialized view for complex aggregations that are expensive to compute - the database pre-computes and stores results. Application cache (Redis) for frequently accessed data that's already fast to query but accessed thousands of times. Often use both: materialized view simplifies the query, Redis caches the result."

---

## Quick Reference

```
QUERY CACHING CHEAT SHEET:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  PATTERNS:                                                      â”‚
â”‚  â€¢ Cache-aside: App manages cache + DB                         â”‚
â”‚  â€¢ Read-through: Cache handles DB fallback                     â”‚
â”‚  â€¢ Write-through: Sync write to cache + DB                     â”‚
â”‚  â€¢ Write-behind: Async write to DB                             â”‚
â”‚                                                                  â”‚
â”‚  INVALIDATION:                                                  â”‚
â”‚  â€¢ TTL: Simple, eventual consistency                           â”‚
â”‚  â€¢ Event-based: Immediate, complex                             â”‚
â”‚  â€¢ Tag-based: Group invalidation                               â”‚
â”‚                                                                  â”‚
â”‚  PITFALLS:                                                      â”‚
â”‚  â€¢ Cache stampede â†’ Use locking                                â”‚
â”‚  â€¢ Stale data â†’ Proper invalidation                            â”‚
â”‚  â€¢ Memory overflow â†’ Set TTL, max memory                       â”‚
â”‚                                                                  â”‚
â”‚  TOOLS:                                                         â”‚
â”‚  â€¢ Redis: Fast, versatile                                      â”‚
â”‚  â€¢ Memcached: Simple, fast                                     â”‚
â”‚  â€¢ Materialized Views: Complex aggregations                    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


