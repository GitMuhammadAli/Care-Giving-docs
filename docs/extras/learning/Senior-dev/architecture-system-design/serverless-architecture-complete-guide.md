# âš¡ Serverless Architecture Complete Guide

> A comprehensive guide to serverless computing - Lambda, edge functions, cold starts, patterns, limitations, and when to use (or avoid) serverless.

---

## ğŸ§  MUST REMEMBER TO IMPRESS (Memorize This!)

### 1-Liner Definition
> "Serverless is a cloud execution model where the provider manages infrastructure, scales automatically, and you pay only for actual compute time - no idle servers."

### The 5 Core Concepts (Memorize!)
```
1. FUNCTIONS AS A SERVICE (FaaS)  â†’ Code runs in stateless containers triggered by events
2. COLD START                      â†’ Delay when new container spins up (100ms - 10s)
3. EVENT-DRIVEN                    â†’ Functions triggered by HTTP, queues, schedules, etc.
4. PAY-PER-EXECUTION              â†’ Billed by invocations + duration, not uptime
5. AUTOMATIC SCALING              â†’ 0 to 1000s of instances without configuration
```

### Key Terms to Drop (Sound Smart!)
| Term | Use It Like This |
|------|------------------|
| **"Cold start"** | "We mitigate cold starts with provisioned concurrency for latency-critical endpoints" |
| **"Provisioned concurrency"** | "We keep 10 warm instances to eliminate cold starts for the API" |
| **"Event source mapping"** | "SQS triggers Lambda via event source mapping with batch size of 10" |
| **"Execution context"** | "We reuse database connections by storing them in the execution context" |
| **"Invocation payload"** | "Lambda has 6MB sync invocation payload limit, use S3 for larger data" |
| **"Edge function"** | "Auth runs at the edge with 0ms cold start using Cloudflare Workers" |
| **"Function composition"** | "We use Step Functions for orchestrating multi-step workflows" |

### Key Numbers to Remember
| Metric | AWS Lambda | Cloudflare Workers | Vercel Edge |
|--------|------------|-------------------|-------------|
| **Max execution time** | 15 min | 30 sec (free), 15 min (paid) | 30 sec |
| **Memory** | 128MB - 10GB | 128MB | 128MB |
| **Payload size** | 6MB sync, 256KB async | 100MB | 4MB |
| **Cold start** | 100ms - 10s | ~0ms (V8 isolates) | ~0ms |
| **Free tier** | 1M requests/month | 100K requests/day | 100K/month |

### Cold Start Times (Know These!)
| Runtime | Typical Cold Start |
|---------|-------------------|
| **Node.js** | 100-500ms |
| **Python** | 100-500ms |
| **Go** | 50-200ms |
| **Java** | 3-10 seconds |
| **C#/.NET** | 1-3 seconds |
| **Rust** | 50-200ms |
| **Edge (V8 isolates)** | ~0ms |

### The "Wow" Statement (Memorize This!)
> "Serverless flips the economics of computing. Traditional servers: you pay for 24/7 capacity even at 2% utilization. Serverless: you pay only for actual execution - 1 million requests at 100ms each costs about $0.20. But it's not magic - cold starts can add 500ms latency, 15-minute max execution limits functions, and no persistent connections means you need connection pooling. We use serverless for event-driven workloads and APIs with variable traffic, but keep long-running processes on containers."

### Quick Architecture Drawing (Draw This!)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SERVERLESS ARCHITECTURE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   EVENT SOURCES                     FUNCTIONS                   â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚ API Gateway â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Lambda A      â”‚          â”‚
â”‚   â”‚   (HTTP)    â”‚                  â”‚   (API Handler) â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                             â”‚                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚     SQS     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Lambda B      â”‚          â”‚
â”‚   â”‚   (Queue)   â”‚                  â”‚  (Background)   â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                             â”‚                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚     S3      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Lambda C      â”‚          â”‚
â”‚   â”‚  (Upload)   â”‚                  â”‚ (Image Process) â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                             â”‚                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚ CloudWatch  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Lambda D      â”‚          â”‚
â”‚   â”‚   (Cron)    â”‚                  â”‚   (Scheduled)   â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚    Edge     â”‚                  â”‚  Cloudflare     â”‚          â”‚
â”‚   â”‚  (Request)  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚    Workers      â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚  (Auth, A/B)    â”‚          â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Interview Rapid Fire (Practice These!)

**Q: "What is serverless?"**
> "Execution model where cloud provider manages infrastructure. Code runs in stateless containers, scales automatically, pay only for compute time used."

**Q: "What is a cold start?"**
> "Delay when a new container initializes - downloading code, starting runtime, running init code. Can be 100ms to 10s depending on runtime and dependencies."

**Q: "How do you mitigate cold starts?"**
> "Provisioned concurrency (keep warm instances), smaller packages, faster runtimes (Node/Go over Java), lazy loading, or edge functions with V8 isolates."

**Q: "What are the limitations of Lambda?"**
> "15 min max execution, 6MB payload, no persistent connections, cold starts, 10GB max memory, no GPU, vendor lock-in."

**Q: "When NOT to use serverless?"**
> "Long-running processes, WebSocket connections, high-performance computing, predictable high traffic (containers cheaper), GPU workloads."

---

## ğŸ¯ How to Explain Like a Senior Developer

### When Asked: "What is Serverless?"

**Junior Answer:**
> "It's where you don't manage servers. You just write functions."

**Senior Answer:**
> "Serverless is an **execution model** where the cloud provider dynamically manages infrastructure. There are two main types:

**1. Functions as a Service (FaaS)**
- Code runs in stateless, ephemeral containers
- Triggered by events (HTTP, queues, schedules, file uploads)
- Scales from 0 to thousands automatically
- Pay per invocation + duration (not uptime)

**2. Backend as a Service (BaaS)**
- Managed services for auth, database, storage
- Firebase, Supabase, Auth0

**Key tradeoffs:**
- âœ… No server management, automatic scaling, pay-per-use
- âŒ Cold starts (latency), execution limits (15 min), no persistent connections, vendor lock-in

I use serverless for APIs with variable traffic, event processing, and scheduled jobs. For long-running processes or consistent high traffic, containers are often better economically."

### Follow-up Questions to Expect:

| They Ask | You Answer |
|----------|------------|
| "How does scaling work?" | "Provider spins up new container instances automatically based on demand. Lambda can go from 0 to 1000+ concurrent executions. Each request gets its own container (or reuses warm one)." |
| "What causes cold starts?" | "Container provisioning, downloading code, starting runtime, running initialization code. Factors: package size, runtime (Java slow, Go fast), VPC (adds 1s), dependencies." |
| "How do you handle state?" | "Functions are stateless. Use external stores: DynamoDB, Redis, S3. Connection reuse via execution context. For workflows, use Step Functions." |
| "Serverless vs containers?" | "Serverless: variable traffic, event-driven, simple functions. Containers: steady traffic (cheaper), long-running, complex apps, predictable costs." |

---

## ğŸ“š Table of Contents

1. [Core Concepts](#1-core-concepts)
2. [Providers & Platforms](#2-providers--platforms)
3. [Cold Starts](#3-cold-starts)
4. [Event Sources & Triggers](#4-event-sources--triggers)
5. [Patterns & Best Practices](#5-patterns--best-practices)
6. [Limitations & Gotchas](#6-limitations--gotchas)
7. [Cost Analysis](#7-cost-analysis)
8. [When to Use / Not Use](#8-when-to-use--not-use)
9. [Interview Questions](#9-interview-questions)

---

## 1. Core Concepts

### How Serverless Works

```
REQUEST LIFECYCLE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  1. EVENT ARRIVES (HTTP request, SQS message, S3 upload)        â”‚
â”‚          â”‚                                                       â”‚
â”‚          â–¼                                                       â”‚
â”‚  2. PROVIDER CHECKS: Is there a warm container?                 â”‚
â”‚          â”‚                                                       â”‚
â”‚          â”œâ”€â”€ YES â”€â”€â–º Use existing container (WARM START ~1ms)   â”‚
â”‚          â”‚                                                       â”‚
â”‚          â””â”€â”€ NO â”€â”€â”€â–º Provision new container (COLD START)       â”‚
â”‚                            â”‚                                     â”‚
â”‚                            â–¼                                     â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                      â”‚ Download code â”‚ â”€â”€â”€â”€â”€â–º ~50-200ms         â”‚
â”‚                      â”‚ Start runtime â”‚ â”€â”€â”€â”€â”€â–º ~100-500ms        â”‚
â”‚                      â”‚ Run init code â”‚ â”€â”€â”€â”€â”€â–º Variable          â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                            â”‚                                     â”‚
â”‚                            â–¼                                     â”‚
â”‚  3. HANDLER EXECUTES                                            â”‚
â”‚          â”‚                                                       â”‚
â”‚          â–¼                                                       â”‚
â”‚  4. RESPONSE RETURNED                                           â”‚
â”‚          â”‚                                                       â”‚
â”‚          â–¼                                                       â”‚
â”‚  5. CONTAINER STAYS WARM (for ~5-15 minutes)                   â”‚
â”‚          â”‚                                                       â”‚
â”‚          â””â”€â”€ Next request reuses this container                â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Execution Context & Container Reuse

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXECUTION CONTEXT: Code outside handler runs ONCE per container
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// OUTSIDE HANDLER - Runs once when container starts
// Reused across invocations in same container
import { DynamoDB } from '@aws-sdk/client-dynamodb';

// This connection is REUSED across warm invocations
const dynamodb = new DynamoDB({});

// This variable persists between invocations
let requestCount = 0;

// INSIDE HANDLER - Runs on EVERY invocation
export const handler = async (event: APIGatewayEvent) => {
  requestCount++;  // Increments across warm invocations
  console.log(`Request #${requestCount} in this container`);

  // Reuses the connection established above
  await dynamodb.getItem({ /* ... */ });

  return { statusCode: 200, body: 'OK' };
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// BEST PRACTICE: Initialize expensive resources outside handler
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// âŒ BAD: Creates new connection on EVERY invocation
export const badHandler = async (event) => {
  const db = new DynamoDB({});  // New connection every time!
  await db.getItem({ /* ... */ });
};

// âœ… GOOD: Reuses connection across warm invocations
const db = new DynamoDB({});  // Created once per container

export const goodHandler = async (event) => {
  await db.getItem({ /* ... */ });  // Reuses connection
};
```

### Serverless vs Traditional vs Containers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COMPARISON: Serverless vs Containers vs VMs        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  ASPECT           â”‚ SERVERLESS   â”‚ CONTAINERS   â”‚ VMs          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Unit of deploy   â”‚ Function     â”‚ Image        â”‚ Machine      â”‚
â”‚  Scaling          â”‚ Automatic    â”‚ Orchestrated â”‚ Manual/Auto  â”‚
â”‚  Scale to zero    â”‚ Yes          â”‚ Possible     â”‚ No           â”‚
â”‚  Cold start       â”‚ 100ms-10s    â”‚ Seconds      â”‚ Minutes      â”‚
â”‚  Max runtime      â”‚ 15 min       â”‚ Unlimited    â”‚ Unlimited    â”‚
â”‚  Pricing model    â”‚ Per executionâ”‚ Per uptime   â”‚ Per uptime   â”‚
â”‚  State            â”‚ Stateless    â”‚ Can be any   â”‚ Stateful     â”‚
â”‚  Ops overhead     â”‚ None         â”‚ Medium       â”‚ High         â”‚
â”‚  Vendor lock-in   â”‚ High         â”‚ Low          â”‚ Low          â”‚
â”‚  Use case         â”‚ Events, APIs â”‚ Services     â”‚ Legacy       â”‚
â”‚                                                                  â”‚
â”‚  WHEN TO USE:                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Serverless: Variable traffic, event-driven, simple functions  â”‚
â”‚  Containers: Consistent traffic, microservices, complex apps   â”‚
â”‚  VMs: Legacy apps, specific OS needs, lift-and-shift          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Providers & Platforms

### AWS Lambda

The original and most feature-rich serverless platform.

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// AWS LAMBDA: Basic Handler
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import { APIGatewayProxyEvent, APIGatewayProxyResult, Context } from 'aws-lambda';

export const handler = async (
  event: APIGatewayProxyEvent,
  context: Context
): Promise<APIGatewayProxyResult> => {
  // event: Contains request data (path, method, body, headers)
  // context: Contains runtime info (requestId, remainingTime, etc.)

  console.log('Request ID:', context.awsRequestId);
  console.log('Remaining time:', context.getRemainingTimeInMillis(), 'ms');

  const body = JSON.parse(event.body || '{}');

  return {
    statusCode: 200,
    headers: {
      'Content-Type': 'application/json',
      'Access-Control-Allow-Origin': '*'
    },
    body: JSON.stringify({
      message: 'Hello from Lambda!',
      input: body
    })
  };
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// AWS LAMBDA: Different Event Sources
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// SQS Trigger
import { SQSEvent, SQSRecord } from 'aws-lambda';

export const sqsHandler = async (event: SQSEvent): Promise<void> => {
  for (const record of event.Records) {
    const message = JSON.parse(record.body);
    console.log('Processing message:', message);
    // Process each message
  }
  // If no error thrown, messages are deleted from queue
};

// S3 Trigger
import { S3Event } from 'aws-lambda';

export const s3Handler = async (event: S3Event): Promise<void> => {
  for (const record of event.Records) {
    const bucket = record.s3.bucket.name;
    const key = record.s3.object.key;
    console.log(`File uploaded: s3://${bucket}/${key}`);
    // Process the uploaded file
  }
};

// Scheduled (CloudWatch Events)
import { ScheduledEvent } from 'aws-lambda';

export const cronHandler = async (event: ScheduledEvent): Promise<void> => {
  console.log('Scheduled execution at:', event.time);
  // Run scheduled task (cleanup, reports, etc.)
};

// DynamoDB Streams
import { DynamoDBStreamEvent } from 'aws-lambda';

export const dynamoHandler = async (event: DynamoDBStreamEvent): Promise<void> => {
  for (const record of event.Records) {
    if (record.eventName === 'INSERT') {
      const newItem = record.dynamodb?.NewImage;
      console.log('New item:', newItem);
    }
  }
};
```

### Lambda Configuration

```yaml
# serverless.yml (Serverless Framework)
service: my-api

provider:
  name: aws
  runtime: nodejs18.x
  region: us-east-1
  memorySize: 256        # MB (128-10240)
  timeout: 30            # seconds (max 900)
  
  # Environment variables
  environment:
    DATABASE_URL: ${env:DATABASE_URL}
    NODE_ENV: production

functions:
  api:
    handler: src/handlers/api.handler
    events:
      - http:
          path: /users
          method: get
      - http:
          path: /users
          method: post
    
    # Provisioned concurrency (eliminates cold starts)
    provisionedConcurrency: 5
    
    # Reserved concurrency (limit max instances)
    reservedConcurrency: 100
    
    # VPC configuration (adds ~1s cold start)
    vpc:
      securityGroupIds:
        - sg-xxxx
      subnetIds:
        - subnet-xxxx

  processQueue:
    handler: src/handlers/queue.handler
    events:
      - sqs:
          arn: !GetAtt MyQueue.Arn
          batchSize: 10
          maximumBatchingWindow: 5
    
  scheduledTask:
    handler: src/handlers/cron.handler
    events:
      - schedule: rate(1 hour)    # or cron(0 * * * ? *)
```

### Cloudflare Workers (Edge Functions)

Near-zero cold starts using V8 isolates instead of containers.

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CLOUDFLARE WORKERS: Edge computing with ~0ms cold start
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// wrangler.toml
// name = "my-worker"
// main = "src/index.ts"
// compatibility_date = "2024-01-01"

export default {
  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {
    const url = new URL(request.url);

    // Simple routing
    if (url.pathname === '/api/hello') {
      return new Response(JSON.stringify({ message: 'Hello from the edge!' }), {
        headers: { 'Content-Type': 'application/json' }
      });
    }

    if (url.pathname === '/api/user') {
      // Access KV storage (Cloudflare's key-value store)
      const user = await env.USERS_KV.get('user:123', 'json');
      return Response.json(user);
    }

    // Use Durable Objects for stateful edge computing
    if (url.pathname.startsWith('/api/counter')) {
      const id = env.COUNTER.idFromName('global');
      const counter = env.COUNTER.get(id);
      return counter.fetch(request);
    }

    return new Response('Not Found', { status: 404 });
  }
};

// Environment bindings
interface Env {
  USERS_KV: KVNamespace;
  COUNTER: DurableObjectNamespace;
  DATABASE: D1Database;  // Cloudflare's SQL database
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// DURABLE OBJECTS: Stateful edge computing
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export class Counter {
  private state: DurableObjectState;
  private count: number = 0;

  constructor(state: DurableObjectState) {
    this.state = state;
    // Load persisted state
    this.state.blockConcurrencyWhile(async () => {
      this.count = await this.state.storage.get('count') || 0;
    });
  }

  async fetch(request: Request): Promise<Response> {
    const url = new URL(request.url);

    if (url.pathname.endsWith('/increment')) {
      this.count++;
      await this.state.storage.put('count', this.count);
    }

    return Response.json({ count: this.count });
  }
}
```

### Vercel Functions / Edge Functions

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// VERCEL SERVERLESS FUNCTION (Node.js runtime)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// api/users.ts
import type { VercelRequest, VercelResponse } from '@vercel/node';

export default async function handler(
  req: VercelRequest,
  res: VercelResponse
) {
  if (req.method === 'GET') {
    const users = await fetchUsers();
    return res.status(200).json(users);
  }

  if (req.method === 'POST') {
    const user = await createUser(req.body);
    return res.status(201).json(user);
  }

  return res.status(405).json({ error: 'Method not allowed' });
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// VERCEL EDGE FUNCTION (~0ms cold start)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// api/edge-hello.ts
export const config = {
  runtime: 'edge',  // Use edge runtime
};

export default async function handler(request: Request) {
  const { searchParams } = new URL(request.url);
  const name = searchParams.get('name') || 'World';

  return new Response(
    JSON.stringify({ message: `Hello, ${name}!` }),
    {
      status: 200,
      headers: { 'Content-Type': 'application/json' }
    }
  );
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// NEXT.JS MIDDLEWARE (Edge Function)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// middleware.ts (runs on every request at the edge)
import { NextResponse } from 'next/server';
import type { NextRequest } from 'next/server';

export function middleware(request: NextRequest) {
  // Authentication check
  const token = request.cookies.get('auth-token');
  
  if (!token && request.nextUrl.pathname.startsWith('/dashboard')) {
    return NextResponse.redirect(new URL('/login', request.url));
  }

  // A/B testing
  const bucket = Math.random() < 0.5 ? 'a' : 'b';
  const response = NextResponse.next();
  response.cookies.set('ab-bucket', bucket);

  // Geolocation-based routing
  const country = request.geo?.country || 'US';
  if (country === 'DE') {
    return NextResponse.rewrite(new URL('/de' + request.nextUrl.pathname, request.url));
  }

  return response;
}

export const config = {
  matcher: ['/((?!api|_next/static|favicon.ico).*)'],
};
```

### Provider Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SERVERLESS PROVIDER COMPARISON                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  FEATURE          â”‚ AWS Lambda  â”‚ Cloudflare  â”‚ Vercel      â”‚ GCP       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  Cold start       â”‚ 100ms-10s   â”‚ ~0ms        â”‚ ~0ms (edge) â”‚ 100ms-10s â”‚
â”‚  Max duration     â”‚ 15 min      â”‚ 30s/15min   â”‚ 30s edge    â”‚ 60 min    â”‚
â”‚  Max memory       â”‚ 10 GB       â”‚ 128 MB      â”‚ 1 GB        â”‚ 32 GB     â”‚
â”‚  Languages        â”‚ Many        â”‚ JS/TS/Wasm  â”‚ JS/TS       â”‚ Many      â”‚
â”‚  Edge locations   â”‚ Limited     â”‚ 300+        â”‚ Many        â”‚ Limited   â”‚
â”‚  Database         â”‚ DynamoDB    â”‚ D1, KV, DO  â”‚ Edge Config â”‚ Firestore â”‚
â”‚  Pricing          â”‚ Per ms      â”‚ Per request â”‚ Per request â”‚ Per ms    â”‚
â”‚                                                                           â”‚
â”‚  BEST FOR:                                                               â”‚
â”‚  AWS Lambda    â†’ Complex backends, AWS ecosystem, long-running tasks    â”‚
â”‚  Cloudflare    â†’ Edge computing, global low latency, simple APIs        â”‚
â”‚  Vercel        â†’ Next.js apps, frontend teams, simple APIs             â”‚
â”‚  GCP Functions â†’ GCP ecosystem, Firebase integration                    â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Cold Starts

### What Causes Cold Starts?

```
COLD START BREAKDOWN:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  PHASE                    â”‚ TIME IMPACT    â”‚ YOU CONTROL?       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  1. Container provision   â”‚ ~50-100ms      â”‚ No                â”‚
â”‚  2. Download code         â”‚ ~50-200ms      â”‚ Yes (package size)â”‚
â”‚  3. Start runtime         â”‚ ~100ms-3s      â”‚ Yes (runtime)     â”‚
â”‚  4. VPC ENI attach        â”‚ ~1-2s          â”‚ Yes (avoid VPC)   â”‚
â”‚  5. Init code execution   â”‚ Variable       â”‚ Yes (lazy load)   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  TOTAL                    â”‚ 100ms - 10s+   â”‚                   â”‚
â”‚                                                                  â”‚
â”‚  RUNTIME IMPACT:                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Node.js / Python    â”‚ ~200-500ms  â”‚ Lightweight runtime       â”‚
â”‚  Go / Rust           â”‚ ~50-200ms   â”‚ Compiled, fast startup    â”‚
â”‚  Java                â”‚ ~3-10s      â”‚ JVM startup overhead      â”‚
â”‚  .NET                â”‚ ~1-3s       â”‚ CLR startup overhead      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cold Start Mitigation Strategies

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// STRATEGY 1: Provisioned Concurrency (AWS Lambda)
// Keep warm instances always ready
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// serverless.yml
// functions:
//   api:
//     handler: src/api.handler
//     provisionedConcurrency: 5  # Always 5 warm instances

// Cost: ~$15/month per provisioned instance (varies by memory)
// Best for: User-facing APIs where latency matters

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// STRATEGY 2: Keep Functions Warm (Ping)
// Scheduled invocation to prevent container shutdown
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// warmer.ts
export const handler = async (event: any) => {
  // Check if this is a warming request
  if (event.source === 'serverless-plugin-warmup') {
    console.log('Warming function...');
    return { statusCode: 200, body: 'Warmed!' };
  }

  // Normal request handling
  return handleRequest(event);
};

// serverless.yml with warmup plugin
// plugins:
//   - serverless-plugin-warmup
// custom:
//   warmup:
//     default:
//       enabled: true
//       events:
//         - schedule: rate(5 minutes)
//       concurrency: 3

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// STRATEGY 3: Smaller Packages
// Less code to download = faster cold starts
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// âŒ BAD: Huge package with everything
// package size: 50MB
import AWS from 'aws-sdk';  // Imports entire SDK

// âœ… GOOD: Import only what you need
// package size: 5MB
import { DynamoDB } from '@aws-sdk/client-dynamodb';

// âœ… BETTER: Use esbuild bundling with tree-shaking
// serverless.yml:
// package:
//   individually: true
// plugins:
//   - serverless-esbuild
// custom:
//   esbuild:
//     bundle: true
//     minify: true
//     exclude:
//       - '@aws-sdk/*'  # Exclude SDK (available in Lambda runtime)

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// STRATEGY 4: Lazy Loading
// Defer expensive initialization until needed
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// âŒ BAD: Load everything at startup
import { S3Client } from '@aws-sdk/client-s3';
import { DynamoDBClient } from '@aws-sdk/client-dynamodb';
import { SESClient } from '@aws-sdk/client-ses';
import Stripe from 'stripe';
import { PrismaClient } from '@prisma/client';

// All initialized at cold start!
const s3 = new S3Client({});
const dynamodb = new DynamoDBClient({});
const ses = new SESClient({});
const stripe = new Stripe(process.env.STRIPE_KEY!);
const prisma = new PrismaClient();

// âœ… GOOD: Lazy load only when needed
let s3Client: S3Client | null = null;
let stripeClient: Stripe | null = null;

function getS3(): S3Client {
  if (!s3Client) {
    s3Client = new S3Client({});
  }
  return s3Client;
}

function getStripe(): Stripe {
  if (!stripeClient) {
    stripeClient = new Stripe(process.env.STRIPE_KEY!);
  }
  return stripeClient;
}

export const handler = async (event: any) => {
  // Only loads S3 client if this code path is taken
  if (event.path === '/upload') {
    const s3 = getS3();
    // ...
  }
  
  // Stripe only loaded for payment routes
  if (event.path === '/checkout') {
    const stripe = getStripe();
    // ...
  }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// STRATEGY 5: Use Faster Runtimes
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Cold start comparison:
// Java:    3-10 seconds
// .NET:    1-3 seconds
// Node.js: 200-500ms
// Python:  200-500ms
// Go:      50-200ms
// Rust:    50-150ms

// For latency-critical functions, consider Go or Rust
// For most web APIs, Node.js or Python are good tradeoffs

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// STRATEGY 6: Avoid VPC (or Use VPC with Hyperplane)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// VPC adds ~1-2s to cold start for ENI (Elastic Network Interface) creation
// AWS now uses Hyperplane for VPC, reducing this significantly

// If you MUST use VPC:
// - Use VPC endpoints for AWS services (avoid NAT Gateway latency)
// - Enable Hyperplane (automatic in newer accounts)
// - Use provisioned concurrency

// If you DON'T need VPC:
// - Access AWS services directly (they have public endpoints)
// - Use IAM roles instead of VPC for security

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// STRATEGY 7: Use Edge Functions (V8 Isolates)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Edge functions use V8 isolates, not containers
// Result: Near-zero cold starts (~0ms)

// Cloudflare Workers, Vercel Edge, Deno Deploy
// Trade-off: More limited runtime (no Node.js APIs, limited libraries)

// Good for: Auth, redirects, A/B testing, geo-routing
// Not good for: Database queries, complex processing
```

### Cold Start Measurement

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MEASURE COLD STARTS: Track init time vs execution time
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const initStart = Date.now();

// Expensive initialization
import { DynamoDB } from '@aws-sdk/client-dynamodb';
const dynamodb = new DynamoDB({});

const initDuration = Date.now() - initStart;
console.log(`INIT_DURATION: ${initDuration}ms`);

let isWarm = false;

export const handler = async (event: any, context: any) => {
  const handlerStart = Date.now();
  
  // Log whether this is a cold or warm start
  console.log(`COLD_START: ${!isWarm}`);
  isWarm = true;

  // Your logic here
  await dynamodb.getItem({ /* ... */ });

  const handlerDuration = Date.now() - handlerStart;
  console.log(`HANDLER_DURATION: ${handlerDuration}ms`);

  // Total time for cold start = INIT_DURATION + HANDLER_DURATION
  // Warm start = only HANDLER_DURATION
  
  return { statusCode: 200, body: 'OK' };
};

// CloudWatch Insights query to analyze cold starts:
// fields @timestamp, @message
// | filter @message like /COLD_START: true/
// | stats count() as coldStarts by bin(1h)
```

### Cold Start vs Warm Start Visualization

```
TIMELINE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  COLD START (First request to new container):                  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Container â”‚ Download â”‚ Runtime â”‚  Init  â”‚    Handler    â”‚  â”‚
â”‚  â”‚  Provisionâ”‚  Code    â”‚  Start  â”‚  Code  â”‚   Execution   â”‚  â”‚
â”‚  â”‚   ~100ms  â”‚  ~100ms  â”‚ ~200ms  â”‚ ~200ms â”‚    ~50ms      â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚                    TOTAL: ~650ms                         â”‚  â”‚
â”‚                                                                  â”‚
â”‚  WARM START (Subsequent request to same container):            â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                    â”‚
â”‚  â”‚    Handler Execution   â”‚                                    â”‚
â”‚  â”‚         ~50ms          â”‚                                    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                    â”‚
â”‚  â”‚     TOTAL: ~50ms       â”‚                                    â”‚
â”‚                                                                  â”‚
â”‚  PROVISIONED CONCURRENCY (Pre-warmed):                         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                    â”‚
â”‚  â”‚    Handler Execution   â”‚  (Container already warm)         â”‚
â”‚  â”‚         ~50ms          â”‚                                    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                    â”‚
â”‚  â”‚     TOTAL: ~50ms       â”‚  (No cold start ever)             â”‚
â”‚                                                                  â”‚
â”‚  EDGE FUNCTION (V8 Isolate):                                   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                    â”‚
â”‚  â”‚       Execution        â”‚  (Isolate spins up in ~5ms)       â”‚
â”‚  â”‚         ~55ms          â”‚                                    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                    â”‚
â”‚  â”‚     TOTAL: ~55ms       â”‚  (Near-zero cold start)           â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Event Sources & Triggers

### Common Event Sources

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LAMBDA EVENT SOURCES                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  SYNCHRONOUS (Request-Response):                                â”‚
â”‚  â”œâ”€â”€ API Gateway         â†’ REST/HTTP APIs                      â”‚
â”‚  â”œâ”€â”€ Application LB      â†’ Load-balanced web apps              â”‚
â”‚  â”œâ”€â”€ Lambda Function URL â†’ Direct HTTP invocation              â”‚
â”‚  â””â”€â”€ SDK Invoke          â†’ From other services/functions       â”‚
â”‚                                                                  â”‚
â”‚  ASYNCHRONOUS (Fire-and-Forget):                               â”‚
â”‚  â”œâ”€â”€ S3                  â†’ File uploads/deletions              â”‚
â”‚  â”œâ”€â”€ SNS                 â†’ Pub/sub notifications               â”‚
â”‚  â”œâ”€â”€ EventBridge         â†’ Event bus patterns                  â”‚
â”‚  â”œâ”€â”€ IoT                 â†’ Device events                       â”‚
â”‚  â””â”€â”€ SDK InvokeAsync     â†’ Background processing               â”‚
â”‚                                                                  â”‚
â”‚  POLLING (Lambda pulls from source):                           â”‚
â”‚  â”œâ”€â”€ SQS                 â†’ Queue processing                    â”‚
â”‚  â”œâ”€â”€ Kinesis             â†’ Stream processing                   â”‚
â”‚  â”œâ”€â”€ DynamoDB Streams    â†’ Change data capture                 â”‚
â”‚  â””â”€â”€ Kafka (MSK)         â†’ Kafka consumers                     â”‚
â”‚                                                                  â”‚
â”‚  SCHEDULED:                                                     â”‚
â”‚  â””â”€â”€ CloudWatch Events   â†’ Cron jobs, rate-based              â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Event Source Patterns

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// PATTERN 1: API Gateway + Lambda (REST API)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// GET /users/{id}
export const getUser = async (event: APIGatewayProxyEvent) => {
  const userId = event.pathParameters?.id;
  const user = await userService.getById(userId);
  
  if (!user) {
    return { statusCode: 404, body: JSON.stringify({ error: 'Not found' }) };
  }
  
  return { statusCode: 200, body: JSON.stringify(user) };
};

// POST /users
export const createUser = async (event: APIGatewayProxyEvent) => {
  const body = JSON.parse(event.body || '{}');
  
  // Validate input
  if (!body.email) {
    return { statusCode: 400, body: JSON.stringify({ error: 'Email required' }) };
  }
  
  const user = await userService.create(body);
  return { statusCode: 201, body: JSON.stringify(user) };
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// PATTERN 2: SQS + Lambda (Queue Processing with Backpressure)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import { SQSEvent, SQSBatchResponse, SQSBatchItemFailure } from 'aws-lambda';

export const processQueue = async (event: SQSEvent): Promise<SQSBatchResponse> => {
  const batchItemFailures: SQSBatchItemFailure[] = [];

  // Process each message, track failures individually
  for (const record of event.Records) {
    try {
      const message = JSON.parse(record.body);
      await processMessage(message);
    } catch (error) {
      console.error(`Failed to process message ${record.messageId}:`, error);
      // Report this specific message as failed
      batchItemFailures.push({ itemIdentifier: record.messageId });
    }
  }

  // Return partial batch response
  // Only failed messages will return to queue
  return { batchItemFailures };
};

// serverless.yml configuration for backpressure:
// functions:
//   processQueue:
//     handler: src/queue.handler
//     reservedConcurrency: 10   # Limit concurrent executions (BACKPRESSURE!)
//     events:
//       - sqs:
//           arn: !GetAtt OrderQueue.Arn
//           batchSize: 10
//           maximumBatchingWindow: 5  # Wait up to 5s to batch
//           functionResponseType: ReportBatchItemFailures

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// PATTERN 3: S3 + Lambda (File Processing)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import { S3Event } from 'aws-lambda';
import { S3Client, GetObjectCommand, PutObjectCommand } from '@aws-sdk/client-s3';

const s3 = new S3Client({});

export const processImage = async (event: S3Event): Promise<void> => {
  for (const record of event.Records) {
    const bucket = record.s3.bucket.name;
    const key = decodeURIComponent(record.s3.object.key);

    // Don't process our own output (prevent infinite loop!)
    if (key.startsWith('thumbnails/')) {
      return;
    }

    // Get the uploaded image
    const getCommand = new GetObjectCommand({ Bucket: bucket, Key: key });
    const response = await s3.send(getCommand);
    const imageBuffer = await response.Body?.transformToByteArray();

    // Process image (resize, compress, etc.)
    const thumbnail = await createThumbnail(imageBuffer);

    // Save thumbnail
    const putCommand = new PutObjectCommand({
      Bucket: bucket,
      Key: `thumbnails/${key}`,
      Body: thumbnail,
      ContentType: 'image/jpeg'
    });
    await s3.send(putCommand);
  }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// PATTERN 4: EventBridge + Lambda (Event-Driven)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

interface OrderEvent {
  'detail-type': 'OrderPlaced' | 'OrderShipped' | 'OrderCancelled';
  source: 'orders-service';
  detail: {
    orderId: string;
    customerId: string;
    total: number;
  };
}

// Publish event
import { EventBridgeClient, PutEventsCommand } from '@aws-sdk/client-eventbridge';

const eventBridge = new EventBridgeClient({});

export const publishOrderPlaced = async (order: Order) => {
  await eventBridge.send(new PutEventsCommand({
    Entries: [{
      EventBusName: 'orders',
      Source: 'orders-service',
      DetailType: 'OrderPlaced',
      Detail: JSON.stringify({
        orderId: order.id,
        customerId: order.customerId,
        total: order.total
      })
    }]
  }));
};

// Subscribe to event
export const handleOrderPlaced = async (event: OrderEvent) => {
  const { orderId, customerId } = event.detail;
  
  // Send confirmation email
  await emailService.sendOrderConfirmation(customerId, orderId);
  
  // Start inventory reservation
  await inventoryService.reserve(orderId);
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// PATTERN 5: Step Functions (Workflow Orchestration)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// State machine definition (serverless.yml)
// stepFunctions:
//   stateMachines:
//     orderWorkflow:
//       definition:
//         StartAt: ValidateOrder
//         States:
//           ValidateOrder:
//             Type: Task
//             Resource: !GetAtt ValidateOrderFunction.Arn
//             Next: ProcessPayment
//             Catch:
//               - ErrorEquals: [ValidationError]
//                 Next: OrderFailed
//           ProcessPayment:
//             Type: Task
//             Resource: !GetAtt ProcessPaymentFunction.Arn
//             Next: ReserveInventory
//             Catch:
//               - ErrorEquals: [PaymentError]
//                 Next: OrderFailed
//           ReserveInventory:
//             Type: Task
//             Resource: !GetAtt ReserveInventoryFunction.Arn
//             Next: OrderComplete
//           OrderComplete:
//             Type: Succeed
//           OrderFailed:
//             Type: Fail

// Individual step functions
export const validateOrder = async (event: { orderId: string }) => {
  const order = await orderRepo.findById(event.orderId);
  
  if (!order || order.items.length === 0) {
    throw new ValidationError('Invalid order');
  }
  
  return { orderId: event.orderId, validated: true };
};

export const processPayment = async (event: { orderId: string }) => {
  const order = await orderRepo.findById(event.orderId);
  const result = await paymentService.charge(order.customerId, order.total);
  
  if (!result.success) {
    throw new PaymentError('Payment failed');
  }
  
  return { orderId: event.orderId, paymentId: result.paymentId };
};
```

---

## 5. Patterns & Best Practices

### Database Connections

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// PROBLEM: Too many database connections
// Each Lambda instance creates new connection
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// âŒ BAD: New connection per invocation
export const handler = async () => {
  const pool = new Pool({ connectionString: process.env.DATABASE_URL });
  const result = await pool.query('SELECT * FROM users');
  await pool.end();  // Connection closed, wasted!
  return result.rows;
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SOLUTION 1: Reuse connections in execution context
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import { Pool } from 'pg';

// Connection created once per container
let pool: Pool | null = null;

function getPool(): Pool {
  if (!pool) {
    pool = new Pool({
      connectionString: process.env.DATABASE_URL,
      max: 1,  // Single connection per Lambda instance
      idleTimeoutMillis: 120000,  // Keep alive during warm period
    });
  }
  return pool;
}

export const handler = async () => {
  const db = getPool();
  const result = await db.query('SELECT * FROM users');
  return result.rows;
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SOLUTION 2: Use RDS Proxy (Connection pooling)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// RDS Proxy sits between Lambda and database
// Manages connection pool, handles surges
// Connect to proxy endpoint instead of database directly

const pool = new Pool({
  host: 'my-proxy.proxy-xxxxx.us-east-1.rds.amazonaws.com',
  // Lambda connects to proxy, proxy manages DB connections
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SOLUTION 3: Use HTTP-based databases
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// PlanetScale, Neon, Turso - HTTP/WebSocket protocols
// No persistent connections needed, better for serverless

import { neon } from '@neondatabase/serverless';

const sql = neon(process.env.DATABASE_URL!);

export const handler = async () => {
  // HTTP-based query, no connection pool needed
  const users = await sql`SELECT * FROM users`;
  return users;
};
```

### Error Handling & Retries

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// IDEMPOTENCY: Same request produces same result
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import { DynamoDB } from '@aws-sdk/client-dynamodb';

const dynamodb = new DynamoDB({});

export const processPayment = async (event: any) => {
  const { orderId, amount, idempotencyKey } = event;

  // Check if already processed
  const existing = await dynamodb.getItem({
    TableName: 'IdempotencyTable',
    Key: { pk: { S: idempotencyKey } }
  });

  if (existing.Item) {
    console.log('Already processed, returning cached result');
    return JSON.parse(existing.Item.result.S!);
  }

  // Process payment
  const result = await paymentService.charge(orderId, amount);

  // Store result for idempotency
  await dynamodb.putItem({
    TableName: 'IdempotencyTable',
    Key: { pk: { S: idempotencyKey } },
    Item: {
      pk: { S: idempotencyKey },
      result: { S: JSON.stringify(result) },
      ttl: { N: String(Math.floor(Date.now() / 1000) + 86400) }  // 24h TTL
    }
  });

  return result;
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// DEAD LETTER QUEUE: Handle failed messages
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// serverless.yml
// resources:
//   Resources:
//     MyQueue:
//       Type: AWS::SQS::Queue
//       Properties:
//         QueueName: my-queue
//         RedrivePolicy:
//           deadLetterTargetArn: !GetAtt DeadLetterQueue.Arn
//           maxReceiveCount: 3  # Move to DLQ after 3 failures
//     DeadLetterQueue:
//       Type: AWS::SQS::Queue
//       Properties:
//         QueueName: my-queue-dlq

// Handle DLQ separately
export const processDLQ = async (event: SQSEvent) => {
  for (const record of event.Records) {
    // Log failed message for investigation
    console.error('Failed message:', record.body);
    
    // Alert operations team
    await alertService.notify({
      type: 'DLQ_MESSAGE',
      queue: 'my-queue',
      message: record.body
    });
  }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CIRCUIT BREAKER: Prevent cascade failures
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class CircuitBreaker {
  private failures = 0;
  private lastFailure: number = 0;
  private readonly threshold = 5;
  private readonly resetTimeout = 30000;  // 30 seconds

  async execute<T>(fn: () => Promise<T>): Promise<T> {
    // Check if circuit is open
    if (this.isOpen()) {
      throw new Error('Circuit breaker is open');
    }

    try {
      const result = await fn();
      this.failures = 0;  // Reset on success
      return result;
    } catch (error) {
      this.failures++;
      this.lastFailure = Date.now();
      throw error;
    }
  }

  private isOpen(): boolean {
    if (this.failures >= this.threshold) {
      // Check if reset timeout has passed
      if (Date.now() - this.lastFailure > this.resetTimeout) {
        this.failures = 0;
        return false;
      }
      return true;
    }
    return false;
  }
}

const paymentCircuit = new CircuitBreaker();

export const handler = async (event: any) => {
  try {
    return await paymentCircuit.execute(() => 
      paymentService.charge(event.amount)
    );
  } catch (error) {
    if (error.message === 'Circuit breaker is open') {
      // Return cached/fallback response
      return { status: 'pending', message: 'Payment service temporarily unavailable' };
    }
    throw error;
  }
};
```

### Observability

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// STRUCTURED LOGGING
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import { Logger } from '@aws-lambda-powertools/logger';

const logger = new Logger({
  serviceName: 'orders-api',
  logLevel: 'INFO'
});

export const handler = async (event: any, context: any) => {
  // Add request context
  logger.addContext(context);
  
  logger.info('Processing order', {
    orderId: event.orderId,
    customerId: event.customerId
  });

  try {
    const result = await processOrder(event);
    logger.info('Order processed successfully', { result });
    return result;
  } catch (error) {
    logger.error('Order processing failed', { error, event });
    throw error;
  }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// DISTRIBUTED TRACING (X-Ray)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import { Tracer } from '@aws-lambda-powertools/tracer';

const tracer = new Tracer({ serviceName: 'orders-api' });

export const handler = async (event: any) => {
  const segment = tracer.getSegment();
  
  // Create subsegment for database call
  const dbSegment = segment?.addNewSubsegment('DynamoDB');
  try {
    const result = await dynamodb.getItem({ /* ... */ });
    dbSegment?.close();
    return result;
  } catch (error) {
    dbSegment?.addError(error);
    dbSegment?.close();
    throw error;
  }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CUSTOM METRICS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import { Metrics, MetricUnits } from '@aws-lambda-powertools/metrics';

const metrics = new Metrics({ serviceName: 'orders-api' });

export const handler = async (event: any) => {
  const startTime = Date.now();
  
  try {
    const result = await processOrder(event);
    
    // Track success
    metrics.addMetric('OrderProcessed', MetricUnits.Count, 1);
    metrics.addMetric('OrderValue', MetricUnits.Count, result.total);
    
    return result;
  } catch (error) {
    // Track failure
    metrics.addMetric('OrderFailed', MetricUnits.Count, 1);
    throw error;
  } finally {
    // Track duration
    metrics.addMetric('ProcessingTime', MetricUnits.Milliseconds, Date.now() - startTime);
    metrics.publishStoredMetrics();
  }
};
```

---

## 6. Limitations & Gotchas

### Hard Limits (AWS Lambda)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AWS LAMBDA LIMITS                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  EXECUTION:                                                     â”‚
â”‚  â”œâ”€â”€ Max duration           â”‚ 15 minutes (900 seconds)         â”‚
â”‚  â”œâ”€â”€ Memory                 â”‚ 128 MB - 10,240 MB               â”‚
â”‚  â”œâ”€â”€ vCPUs                  â”‚ Proportional to memory           â”‚
â”‚  â”œâ”€â”€ /tmp storage           â”‚ 512 MB - 10,240 MB               â”‚
â”‚  â””â”€â”€ Environment vars       â”‚ 4 KB total                       â”‚
â”‚                                                                  â”‚
â”‚  PAYLOAD:                                                       â”‚
â”‚  â”œâ”€â”€ Sync invocation        â”‚ 6 MB (request + response)        â”‚
â”‚  â”œâ”€â”€ Async invocation       â”‚ 256 KB                           â”‚
â”‚  â””â”€â”€ Streamed response      â”‚ 20 MB                            â”‚
â”‚                                                                  â”‚
â”‚  CONCURRENCY:                                                   â”‚
â”‚  â”œâ”€â”€ Account default        â”‚ 1,000 concurrent executions      â”‚
â”‚  â”œâ”€â”€ Per-function reserved  â”‚ Up to account limit              â”‚
â”‚  â””â”€â”€ Provisioned            â”‚ Costs extra, keeps warm          â”‚
â”‚                                                                  â”‚
â”‚  DEPLOYMENT:                                                    â”‚
â”‚  â”œâ”€â”€ Package size (zipped)  â”‚ 50 MB                            â”‚
â”‚  â”œâ”€â”€ Package size (unzipped)â”‚ 250 MB                           â”‚
â”‚  â””â”€â”€ Container image        â”‚ 10 GB                            â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Common Gotchas

```typescript
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// GOTCHA 1: Function timeout during processing
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// âŒ BAD: Processing all items in one invocation
export const handler = async (event: any) => {
  const items = await db.query('SELECT * FROM huge_table');  // 1M rows
  
  for (const item of items) {
    await processItem(item);  // Times out after 15 minutes!
  }
};

// âœ… GOOD: Chunk processing with SQS
export const handler = async (event: any) => {
  const { offset, limit } = event;
  const items = await db.query(`SELECT * FROM huge_table LIMIT ${limit} OFFSET ${offset}`);
  
  for (const item of items) {
    await processItem(item);
  }
  
  // Queue next batch
  if (items.length === limit) {
    await sqs.sendMessage({
      QueueUrl: process.env.SELF_QUEUE_URL,
      MessageBody: JSON.stringify({ offset: offset + limit, limit })
    });
  }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// GOTCHA 2: Payload size limits
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// âŒ BAD: Returning large data directly
export const handler = async (event: any) => {
  const report = await generateLargeReport();  // 10MB
  return {
    statusCode: 200,
    body: JSON.stringify(report)  // FAILS: > 6MB limit
  };
};

// âœ… GOOD: Use S3 for large payloads
export const handler = async (event: any) => {
  const report = await generateLargeReport();
  
  // Upload to S3
  const key = `reports/${Date.now()}.json`;
  await s3.putObject({
    Bucket: 'my-reports-bucket',
    Key: key,
    Body: JSON.stringify(report)
  });
  
  // Return presigned URL
  const url = await getSignedUrl(s3, new GetObjectCommand({
    Bucket: 'my-reports-bucket',
    Key: key
  }), { expiresIn: 3600 });
  
  return {
    statusCode: 200,
    body: JSON.stringify({ downloadUrl: url })
  };
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// GOTCHA 3: Cold start + VPC = Slow
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// VPC attachment adds ~1-2s to cold starts
// Use VPC only when necessary (RDS, ElastiCache, etc.)

// Alternative: Use VPC endpoints to avoid NAT Gateway
// serverless.yml:
// provider:
//   vpc:
//     securityGroupIds: [!Ref LambdaSG]
//     subnetIds: [!Ref PrivateSubnet1, !Ref PrivateSubnet2]
//   vpcEndpointIds:
//     - !Ref DynamoDBEndpoint  # Access DynamoDB without internet

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// GOTCHA 4: Statelessness - No persistent connections
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// âŒ BAD: WebSocket connections
// Lambda can't maintain persistent WebSocket connections

// âœ… GOOD: Use API Gateway WebSocket APIs
// API Gateway manages connections, Lambda handles messages

// âŒ BAD: In-memory caching between requests
let cache = {};  // Lost when container recycles!

// âœ… GOOD: External cache (Redis, DynamoDB)
const redis = new Redis(process.env.REDIS_URL);

export const handler = async (event: any) => {
  let data = await redis.get('my-key');
  if (!data) {
    data = await expensiveOperation();
    await redis.set('my-key', data, 'EX', 3600);
  }
  return data;
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// GOTCHA 5: Concurrent execution limits (Thundering Herd)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Problem: Traffic spike exhausts concurrent execution limit
// All additional requests fail with 429 (throttled)

// Solutions:
// 1. Request limit increase from AWS (up to 10,000+)
// 2. Use reserved concurrency to guarantee capacity
// 3. Use SQS to smooth traffic (queue absorbs spikes)
// 4. Implement backoff in clients

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// GOTCHA 6: No GPU support
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Lambda doesn't support GPU workloads
// For ML inference, use:
// - SageMaker endpoints (managed ML)
// - EC2 with GPU instances
// - AWS Inferentia chips
// - Bedrock for LLMs

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// GOTCHA 7: Time-based triggers aren't precise
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// CloudWatch Events can have up to 1 minute delay
// For precise timing, use Step Functions wait states
// or EC2/ECS with cron
```

---

## 7. Cost Analysis

### Lambda Pricing Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LAMBDA PRICING (US-EAST-1)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  WHAT YOU PAY FOR:                                              â”‚
â”‚  â”œâ”€â”€ Requests: $0.20 per 1 million requests                    â”‚
â”‚  â”œâ”€â”€ Duration: $0.0000166667 per GB-second                     â”‚
â”‚  â””â”€â”€ Provisioned: $0.000004646 per GB-second (always on)       â”‚
â”‚                                                                  â”‚
â”‚  FREE TIER (Monthly):                                           â”‚
â”‚  â”œâ”€â”€ 1 million requests                                        â”‚
â”‚  â””â”€â”€ 400,000 GB-seconds                                        â”‚
â”‚                                                                  â”‚
â”‚  EXAMPLE CALCULATION:                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Requests: 10 million/month                                    â”‚
â”‚  Memory: 512 MB (0.5 GB)                                       â”‚
â”‚  Duration: 200ms average                                       â”‚
â”‚                                                                  â”‚
â”‚  GB-seconds = 10M Ã— 0.5 GB Ã— 0.2s = 1,000,000 GB-s            â”‚
â”‚                                                                  â”‚
â”‚  Cost breakdown:                                                â”‚
â”‚  Requests: 10M Ã— $0.20/M = $2.00                              â”‚
â”‚  Duration: 1M GB-s Ã— $0.0000166667 = $16.67                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  TOTAL: ~$18.67/month for 10M requests                        â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Serverless vs Containers Cost Comparison

```
COST COMPARISON: When does serverless become expensive?

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  SCENARIO 1: Low, Variable Traffic (Serverless wins!)          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Traffic: 100K requests/month, 200ms avg                       â”‚
â”‚                                                                  â”‚
â”‚  Lambda (512MB):                                                â”‚
â”‚  â””â”€â”€ Requests: 100K Ã— $0.20/M = $0.02                         â”‚
â”‚  â””â”€â”€ Duration: 100K Ã— 0.5GB Ã— 0.2s Ã— $0.0000166667 = $0.17    â”‚
â”‚  â””â”€â”€ TOTAL: ~$0.19/month                                       â”‚
â”‚                                                                  â”‚
â”‚  Fargate (0.5 vCPU, 1GB):                                      â”‚
â”‚  â””â”€â”€ 24/7 uptime: ~$30/month minimum                           â”‚
â”‚                                                                  â”‚
â”‚  VERDICT: Serverless is 150x cheaper                           â”‚
â”‚                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  SCENARIO 2: High, Steady Traffic (Containers win!)            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Traffic: 100M requests/month, 200ms avg, 24/7 steady          â”‚
â”‚                                                                  â”‚
â”‚  Lambda (512MB):                                                â”‚
â”‚  â””â”€â”€ Requests: 100M Ã— $0.20/M = $20                           â”‚
â”‚  â””â”€â”€ Duration: 100M Ã— 0.5GB Ã— 0.2s Ã— $0.0000166667 = $166.67  â”‚
â”‚  â””â”€â”€ TOTAL: ~$186.67/month                                     â”‚
â”‚                                                                  â”‚
â”‚  Fargate (1 vCPU, 2GB, 3 instances):                           â”‚
â”‚  â””â”€â”€ 3 Ã— $35/month = $105/month                                â”‚
â”‚  â””â”€â”€ Handles same load with headroom                           â”‚
â”‚                                                                  â”‚
â”‚  VERDICT: Containers are ~44% cheaper                          â”‚
â”‚                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  CROSSOVER POINT:                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Generally, serverless is cheaper until:                       â”‚
â”‚  â””â”€â”€ ~30-50% utilization of container equivalent               â”‚
â”‚  â””â”€â”€ Or ~5-10M requests/month for typical APIs                 â”‚
â”‚                                                                  â”‚
â”‚  But consider:                                                  â”‚
â”‚  â””â”€â”€ Serverless: No ops overhead ($$$ saved)                  â”‚
â”‚  â””â”€â”€ Serverless: Auto-scaling included                        â”‚
â”‚  â””â”€â”€ Containers: Predictable costs                            â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8. When to Use / Not Use

### When TO Use Serverless

```
âœ… USE SERVERLESS WHEN:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  1. VARIABLE/UNPREDICTABLE TRAFFIC                             â”‚
â”‚     â””â”€â”€ Spiky traffic patterns                                 â”‚
â”‚     â””â”€â”€ Scale to zero when idle                                â”‚
â”‚     â””â”€â”€ Handle traffic bursts automatically                    â”‚
â”‚                                                                  â”‚
â”‚  2. EVENT-DRIVEN WORKLOADS                                      â”‚
â”‚     â””â”€â”€ File processing (S3 uploads)                           â”‚
â”‚     â””â”€â”€ Queue consumers (SQS, Kinesis)                         â”‚
â”‚     â””â”€â”€ Webhooks                                               â”‚
â”‚     â””â”€â”€ IoT data processing                                    â”‚
â”‚                                                                  â”‚
â”‚  3. SCHEDULED TASKS                                             â”‚
â”‚     â””â”€â”€ Cron jobs that run periodically                        â”‚
â”‚     â””â”€â”€ Report generation                                      â”‚
â”‚     â””â”€â”€ Data cleanup                                           â”‚
â”‚                                                                  â”‚
â”‚  4. APIs WITH VARIABLE LOAD                                     â”‚
â”‚     â””â”€â”€ MVPs and prototypes                                    â”‚
â”‚     â””â”€â”€ Internal tools                                         â”‚
â”‚     â””â”€â”€ Low-traffic production APIs                           â”‚
â”‚                                                                  â”‚
â”‚  5. MICROSERVICES / FUNCTIONS                                   â”‚
â”‚     â””â”€â”€ Small, single-purpose functions                        â”‚
â”‚     â””â”€â”€ Decoupled services                                     â”‚
â”‚                                                                  â”‚
â”‚  6. NO OPS CAPACITY                                             â”‚
â”‚     â””â”€â”€ Small teams                                            â”‚
â”‚     â””â”€â”€ Focus on product, not infrastructure                   â”‚
â”‚                                                                  â”‚
â”‚  GOOD EXAMPLES:                                                 â”‚
â”‚  â””â”€â”€ Image/video processing triggers                          â”‚
â”‚  â””â”€â”€ Notification systems                                      â”‚
â”‚  â””â”€â”€ Chatbots and webhooks                                    â”‚
â”‚  â””â”€â”€ Data transformation pipelines                            â”‚
â”‚  â””â”€â”€ Scheduled reports and cleanups                           â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### When NOT to Use Serverless

```
âŒ DON'T USE SERVERLESS WHEN:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  1. LONG-RUNNING PROCESSES                                      â”‚
â”‚     â””â”€â”€ Tasks > 15 minutes                                     â”‚
â”‚     â””â”€â”€ Video transcoding (use MediaConvert)                   â”‚
â”‚     â””â”€â”€ Large data processing (use EMR, Glue)                 â”‚
â”‚     â””â”€â”€ Training ML models (use SageMaker)                    â”‚
â”‚                                                                  â”‚
â”‚  2. PERSISTENT CONNECTIONS                                      â”‚
â”‚     â””â”€â”€ WebSocket servers (Lambda can't hold connections)     â”‚
â”‚     â””â”€â”€ Long-polling                                           â”‚
â”‚     â””â”€â”€ Game servers                                           â”‚
â”‚                                                                  â”‚
â”‚  3. HIGH, STEADY TRAFFIC                                        â”‚
â”‚     â””â”€â”€ Predictable 24/7 load                                  â”‚
â”‚     â””â”€â”€ Containers become cheaper                              â”‚
â”‚     â””â”€â”€ Reserved instances even cheaper                       â”‚
â”‚                                                                  â”‚
â”‚  4. LATENCY-CRITICAL (<50ms)                                   â”‚
â”‚     â””â”€â”€ Cold starts add 100ms-10s                              â”‚
â”‚     â””â”€â”€ Use containers or provisioned concurrency             â”‚
â”‚                                                                  â”‚
â”‚  5. GPU/SPECIALIZED HARDWARE                                    â”‚
â”‚     â””â”€â”€ ML inference (use SageMaker)                          â”‚
â”‚     â””â”€â”€ Graphics processing                                    â”‚
â”‚     â””â”€â”€ Scientific computing                                   â”‚
â”‚                                                                  â”‚
â”‚  6. COMPLEX STATEFUL APPLICATIONS                               â”‚
â”‚     â””â”€â”€ Applications requiring in-memory state                â”‚
â”‚     â””â”€â”€ Databases (obviously)                                  â”‚
â”‚                                                                  â”‚
â”‚  7. LARGE MONOLITHS                                             â”‚
â”‚     â””â”€â”€ Cold start for 500MB package is painful               â”‚
â”‚     â””â”€â”€ Exceeds 250MB unzipped limit                          â”‚
â”‚                                                                  â”‚
â”‚  BETTER ALTERNATIVES:                                          â”‚
â”‚  â””â”€â”€ ECS/Fargate for long-running services                    â”‚
â”‚  â””â”€â”€ EC2 for GPU workloads                                    â”‚
â”‚  â””â”€â”€ AppRunner for simple containers                          â”‚
â”‚  â””â”€â”€ EKS for complex orchestration                            â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 9. Interview Questions & Answers

### Basic Questions

**Q1: What is serverless computing?**
> **A:** Serverless is a cloud execution model where the provider manages all infrastructure. Code runs in stateless, ephemeral containers triggered by events. Key characteristics:
> - **Auto-scaling**: From 0 to thousands of instances automatically
> - **Pay-per-execution**: Billed only for actual compute time
> - **No server management**: Provider handles provisioning, patching, scaling
> - **Event-driven**: Functions triggered by HTTP, queues, file uploads, schedules

**Q2: What is a cold start?**
> **A:** The latency when a new container must be initialized to handle a request. It includes:
> - Container provisioning (~50-100ms)
> - Code download (~50-200ms)
> - Runtime startup (~100ms-3s depending on language)
> - Init code execution (variable)
>
> Total: 100ms (Go) to 10+ seconds (Java with VPC). Warm starts reuse existing containers and take only a few milliseconds.

**Q3: How do you mitigate cold starts?**
> **A:** Several strategies:
> 1. **Provisioned concurrency** - Keep warm instances always ready ($$$)
> 2. **Smaller packages** - Less code to download (tree-shaking, esbuild)
> 3. **Faster runtimes** - Node.js/Go over Java
> 4. **Lazy loading** - Defer expensive initialization until needed
> 5. **Avoid VPC** - VPC adds ~1-2s for ENI creation
> 6. **Edge functions** - V8 isolates have near-zero cold starts
> 7. **Warming pings** - Scheduled invocations to keep containers hot

**Q4: What are the limitations of AWS Lambda?**
> **A:** Key limits:
> - **15 minute max duration** - Long processes need other solutions
> - **6MB sync payload** - Use S3 for larger data
> - **10GB max memory** - Can limit compute-heavy workloads
> - **No persistent connections** - Can't hold WebSocket connections
> - **Cold starts** - Latency for new containers
> - **No GPU** - ML workloads need SageMaker/EC2
> - **Vendor lock-in** - AWS-specific APIs

### Intermediate Questions

**Q5: How do you handle database connections in serverless?**
> **A:** Three approaches:
> 1. **Connection reuse** - Create connection outside handler, reuse in warm invocations
> 2. **Connection pooling (RDS Proxy)** - Proxy sits between Lambda and DB, manages pool
> 3. **HTTP-based databases** - PlanetScale, Neon use HTTP protocols, no persistent connections
>
> Key: Set `max: 1` connection per Lambda instance to avoid exhausting database connections during spikes.

**Q6: What is the difference between sync and async Lambda invocation?**
> **A:** 
> - **Synchronous**: Caller waits for response. API Gateway uses this. 6MB payload limit.
> - **Asynchronous**: Fire-and-forget. S3, SNS use this. 256KB payload limit. Built-in retries (2 attempts).
> - **Polling**: Lambda polls event source. SQS, Kinesis, DynamoDB Streams. Lambda controls batch size and concurrency.

**Q7: How do you handle errors and retries?**
> **A:** Depends on invocation type:
> - **Sync**: Return error to caller, they retry
> - **Async**: Automatic 2 retries, then to Dead Letter Queue (DLQ)
> - **Stream/Queue**: Message returns to queue after visibility timeout
>
> Best practices:
> - Make handlers **idempotent** (same input = same result)
> - Use **DLQ** for failed messages
> - Implement **circuit breaker** for external services
> - Use **SQS partial batch response** to report individual failures

**Q8: What is the execution context?**
> **A:** The runtime environment that persists between invocations in the same container:
> - Code outside the handler runs once per container
> - Variables, connections, cached data persist
> - Reused for 5-15 minutes of inactivity
>
> Use it to: Initialize SDK clients, database connections, load configuration. Don't use it for: Request-specific state.

### Advanced Questions

**Q9: Compare Lambda vs Containers. When would you choose each?**
> **A:**
> **Lambda**:
> - Variable/unpredictable traffic
> - Event-driven workloads
> - Short-running tasks (<15 min)
> - No ops capacity
> - Pay-per-execution economics
>
> **Containers**:
> - Steady, predictable traffic (cheaper at scale)
> - Long-running processes
> - Persistent connections (WebSocket)
> - Latency-critical (<50ms)
> - Large applications (>250MB)
>
> Crossover point: ~30-50% container utilization, or ~5-10M Lambda requests/month.

**Q10: How do you implement backpressure in serverless?**
> **A:** Several mechanisms:
> 1. **Reserved concurrency** - Limit max concurrent executions per function
> 2. **SQS with maxConcurrency** - Control polling rate
> 3. **API Gateway throttling** - Rate limit at API level
> 4. **Circuit breaker** - Stop calling failing services
> 5. **Partial batch failures** - Report failed messages individually, don't retry all
>
> Example: Set `reservedConcurrency: 10` to limit function to 10 parallel executions, protecting downstream databases.

**Q11: What are edge functions? When would you use them?**
> **A:** Functions that run at CDN edge locations (Cloudflare Workers, Vercel Edge):
> - **V8 isolates** instead of containers = ~0ms cold start
> - **Limited runtime** - No Node.js APIs, smaller libraries
> - **Low latency** - Run close to users globally
>
> Use for: Auth checks, redirects, A/B testing, geolocation, header manipulation
> Not for: Database queries, complex processing

**Q12: How do you design for observability in serverless?**
> **A:** Three pillars:
> 1. **Structured logging** - JSON logs with correlation IDs, request context
> 2. **Distributed tracing** - X-Ray to trace requests across functions
> 3. **Custom metrics** - Business metrics (orders processed, errors by type)
>
> Tools: CloudWatch Logs Insights, X-Ray, Lambda Powertools (structured logging, tracing, metrics in one package).

### Scenario Questions

**Q13: Design a serverless image processing pipeline**
> **A:** 
> ```
> User uploads to S3 â†’ S3 triggers Lambda â†’ Lambda processes image â†’ 
> Lambda saves thumbnail to S3 â†’ S3 triggers notification Lambda â†’ 
> Lambda updates DB and notifies user
> ```
>
> Considerations:
> - Handle large images: Stream from S3, don't load entire file
> - Prevent infinite loops: Check prefix before processing
> - Timeout: 15 min max, use Step Functions for long processing
> - Error handling: DLQ for failed images, retry logic
> - Scaling: Lambda scales automatically, but limit concurrency if DB is bottleneck

**Q14: You're getting cold starts of 3-5 seconds. How do you debug and fix?**
> **A:** Debug:
> 1. Check runtime (Java = slow)
> 2. Check VPC (adds 1-2s)
> 3. Check package size (large = slow download)
> 4. Check init code (what runs outside handler?)
>
> Fix:
> 1. Switch to Node.js/Go if possible
> 2. Remove VPC if not needed, or use Hyperplane
> 3. Use esbuild for tree-shaking, smaller packages
> 4. Lazy-load dependencies
> 5. Use provisioned concurrency for critical paths
> 6. Consider edge functions for latency-critical endpoints

---

## ğŸ“ Key Takeaways

1. **Serverless = no server management** + auto-scaling + pay-per-execution
2. **Cold starts** are the main latency concern - 100ms to 10s
3. **Mitigate cold starts** with provisioned concurrency, smaller packages, faster runtimes
4. **Execution context** persists between invocations - reuse connections
5. **Limits**: 15 min duration, 6MB payload, no persistent connections
6. **Database connections**: Use pooling (RDS Proxy) or HTTP-based DBs
7. **Edge functions** have ~0ms cold start but limited runtime
8. **Cost crossover**: Serverless cheaper for variable traffic, containers for steady load
9. **Make handlers idempotent** - same input = same result
10. **Backpressure**: Reserved concurrency, SQS throttling, circuit breakers

---

## ğŸ“š Resources

### Documentation
- [AWS Lambda Developer Guide](https://docs.aws.amazon.com/lambda/)
- [Cloudflare Workers Docs](https://developers.cloudflare.com/workers/)
- [Vercel Edge Functions](https://vercel.com/docs/functions/edge-functions)

### Tools
- [Serverless Framework](https://www.serverless.com/)
- [AWS SAM](https://aws.amazon.com/serverless/sam/)
- [SST (Serverless Stack)](https://sst.dev/)
- [Lambda Powertools](https://docs.powertools.aws.dev/lambda/typescript/latest/)

### Books & Courses
- "Serverless Architectures on AWS" by Peter Sbarski
- AWS Certified Solutions Architect (covers Lambda patterns)
- freeCodeCamp Serverless tutorials


